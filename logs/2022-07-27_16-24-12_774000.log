2022-07-27 16:24:12.776 | INFO     | config:print_args:50 - K = 1600
2022-07-27 16:24:12.777 | INFO     | config:print_args:50 - T = 0.07
2022-07-27 16:24:12.777 | INFO     | config:print_args:50 - adam_epsilon = 1e-08
2022-07-27 16:24:12.777 | INFO     | config:print_args:50 - alpha = 5
2022-07-27 16:24:12.777 | INFO     | config:print_args:50 - bart_lr = 0.0001
2022-07-27 16:24:12.777 | INFO     | config:print_args:50 - batch_size = 64
2022-07-27 16:24:12.777 | INFO     | config:print_args:50 - checkpoint_path = checkpoints/
2022-07-27 16:24:12.777 | INFO     | config:print_args:50 - chunk_nums = 30
2022-07-27 16:24:12.778 | INFO     | config:print_args:50 - content_max_len = 152
2022-07-27 16:24:12.778 | INFO     | config:print_args:50 - data_dir = data/
2022-07-27 16:24:12.778 | INFO     | config:print_args:50 - epochs = 3
2022-07-27 16:24:12.778 | INFO     | config:print_args:50 - eval_interval = 2000
2022-07-27 16:24:12.778 | INFO     | config:print_args:50 - generate_max_len = 70
2022-07-27 16:24:12.778 | INFO     | config:print_args:50 - gradient_accumulation_steps = 1
2022-07-27 16:24:12.778 | INFO     | config:print_args:50 - json_path = bart-base-chinese//config.json
2022-07-27 16:24:12.778 | INFO     | config:print_args:50 - log_interval = 50
2022-07-27 16:24:12.778 | INFO     | config:print_args:50 - log_path = logs/
2022-07-27 16:24:12.779 | INFO     | config:print_args:50 - m = 0.999
2022-07-27 16:24:12.779 | INFO     | config:print_args:50 - max_clip_norm = 1.0
2022-07-27 16:24:12.779 | INFO     | config:print_args:50 - max_len = 184
2022-07-27 16:24:12.779 | INFO     | config:print_args:50 - mlp = False
2022-07-27 16:24:12.779 | INFO     | config:print_args:50 - pooling = last-avg
2022-07-27 16:24:12.779 | INFO     | config:print_args:50 - pretrained_model_path = bart-base-chinese/
2022-07-27 16:24:12.779 | INFO     | config:print_args:50 - repetition_penalty = 1.2
2022-07-27 16:24:12.779 | INFO     | config:print_args:50 - save_settings = <bound method Args.save_settings of {'data_dir': 'data/', 'pretrained_model_path': 'bart-base-chinese/', 'vocab_path': 'bart-base-chinese/', 'json_path': 'bart-base-chinese//config.json', 'checkpoint_path': 'checkpoints/', 'log_path': 'logs/', 'seed': 42, 'batch_size': 64, 'max_len': 184, 'content_max_len': 152, 'summary_max_len': 32, 'epochs': 3, 'bart_lr': 0.0001, 'warmup_steps': 10000, 'weight_decay': 0.01, 'adam_epsilon': 1e-08, 'max_clip_norm': 1.0, 'gradient_accumulation_steps': 1, 'eval_interval': 2000, 'log_interval': 50, 'alpha': 5, 'K': 1600, 'm': 0.999, 'T': 0.07, 'mlp': False, 'pooling': 'last-avg', 'chunk_nums': 30, 'generate_max_len': 70, 'repetition_penalty': 1.2, 'top_k': 5, 'top_p': 0.95}>
2022-07-27 16:24:12.779 | INFO     | config:print_args:50 - seed = 42
2022-07-27 16:24:12.780 | INFO     | config:print_args:50 - summary_max_len = 32
2022-07-27 16:24:12.780 | INFO     | config:print_args:50 - top_k = 5
2022-07-27 16:24:12.780 | INFO     | config:print_args:50 - top_p = 0.95
2022-07-27 16:24:12.780 | INFO     | config:print_args:50 - vocab_path = bart-base-chinese/
2022-07-27 16:24:12.780 | INFO     | config:print_args:50 - warmup_steps = 10000
2022-07-27 16:24:12.780 | INFO     | config:print_args:50 - weight_decay = 0.01
2022-07-27 16:24:27.388 | INFO     | __main__:train:65 - 

2022-07-27 16:24:27.389 | INFO     | __main__:train:66 - ***** Running training *****
2022-07-27 16:24:27.389 | INFO     | __main__:train:67 -   Num Epochs = 3
2022-07-27 16:24:27.389 | INFO     | __main__:train:68 -   Total train batch size (w. parallel, distributed & accumulation) = 64
2022-07-27 16:24:27.389 | INFO     | __main__:train:70 -   Type of optimizer = AdamW
2022-07-27 16:24:27.389 | INFO     | __main__:train:72 -   Learning rate = 0.0001
2022-07-27 16:24:27.389 | INFO     | __main__:train:73 - 

2022-07-27 16:24:27.391 | INFO     | processing.dataset:_load_and_cache_examples:43 - Loading examples from cache file data/cache/train_set/train_0.pkl
2022-07-27 16:24:29.027 | INFO     | __main__:train:118 - Epoch:  0 | Chunk:  0 | step:    0 | mle_loss: 11.035949 | cl_loss: 6.102090 | loss: 41.546402
2022-07-27 16:24:46.949 | INFO     | __main__:train:118 - Epoch:  0 | Chunk:  0 | step:   50 | mle_loss: 10.395664 | cl_loss: 6.359272 | loss: 42.192024
2022-07-27 16:25:04.902 | INFO     | __main__:train:118 - Epoch:  0 | Chunk:  0 | step:  100 | mle_loss: 9.342111 | cl_loss: 6.291235 | loss: 40.798286
2022-07-27 16:25:22.707 | INFO     | __main__:train:118 - Epoch:  0 | Chunk:  0 | step:  150 | mle_loss: 8.254549 | cl_loss: 6.031783 | loss: 38.413464
2022-07-27 16:25:40.650 | INFO     | __main__:train:118 - Epoch:  0 | Chunk:  0 | step:  200 | mle_loss: 7.419613 | cl_loss: 5.647943 | loss: 35.659325
2022-07-27 16:25:58.721 | INFO     | __main__:train:118 - Epoch:  0 | Chunk:  0 | step:  250 | mle_loss: 6.771869 | cl_loss: 5.141479 | loss: 32.479263
2022-07-27 16:26:16.599 | INFO     | __main__:train:118 - Epoch:  0 | Chunk:  0 | step:  300 | mle_loss: 6.026468 | cl_loss: 4.775651 | loss: 29.904728
2022-07-27 16:26:34.601 | INFO     | __main__:train:118 - Epoch:  0 | Chunk:  0 | step:  350 | mle_loss: 5.462718 | cl_loss: 4.481181 | loss: 27.868628
2022-07-27 16:26:52.740 | INFO     | __main__:train:118 - Epoch:  0 | Chunk:  0 | step:  400 | mle_loss: 4.913999 | cl_loss: 4.241532 | loss: 26.121656
2022-07-27 16:27:10.590 | INFO     | __main__:train:118 - Epoch:  0 | Chunk:  0 | step:  450 | mle_loss: 4.283103 | cl_loss: 4.040470 | loss: 24.485449
2022-07-27 16:27:28.508 | INFO     | __main__:train:118 - Epoch:  0 | Chunk:  0 | step:  500 | mle_loss: 3.956646 | cl_loss: 3.827189 | loss: 23.092585
2022-07-27 16:27:46.585 | INFO     | __main__:train:118 - Epoch:  0 | Chunk:  0 | step:  550 | mle_loss: 3.690439 | cl_loss: 3.647053 | loss: 21.925705
2022-07-27 16:28:04.342 | INFO     | __main__:train:118 - Epoch:  0 | Chunk:  0 | step:  600 | mle_loss: 3.567002 | cl_loss: 3.491748 | loss: 21.025743
2022-07-27 16:28:22.210 | INFO     | __main__:train:118 - Epoch:  0 | Chunk:  0 | step:  650 | mle_loss: 3.471650 | cl_loss: 3.335854 | loss: 20.150913
2022-07-27 16:28:39.900 | INFO     | __main__:train:118 - Epoch:  0 | Chunk:  0 | step:  700 | mle_loss: 3.440507 | cl_loss: 3.197783 | loss: 19.429420
2022-07-27 16:28:57.818 | INFO     | __main__:train:118 - Epoch:  0 | Chunk:  0 | step:  750 | mle_loss: 3.286757 | cl_loss: 3.043742 | loss: 18.505466
2022-07-27 16:29:15.714 | INFO     | __main__:train:118 - Epoch:  0 | Chunk:  0 | step:  800 | mle_loss: 3.263208 | cl_loss: 2.931909 | loss: 17.922750
2022-07-27 16:29:33.563 | INFO     | __main__:train:118 - Epoch:  0 | Chunk:  0 | step:  850 | mle_loss: 3.185643 | cl_loss: 2.830347 | loss: 17.337383
2022-07-27 16:29:51.539 | INFO     | __main__:train:118 - Epoch:  0 | Chunk:  0 | step:  900 | mle_loss: 3.134081 | cl_loss: 2.731625 | loss: 16.792204
2022-07-27 16:30:09.328 | INFO     | __main__:train:118 - Epoch:  0 | Chunk:  0 | step:  950 | mle_loss: 3.079403 | cl_loss: 2.622588 | loss: 16.192350
2022-07-27 16:30:27.255 | INFO     | __main__:train:118 - Epoch:  0 | Chunk:  0 | step: 1000 | mle_loss: 3.003890 | cl_loss: 2.549549 | loss: 15.751643
2022-07-27 16:30:44.783 | INFO     | __main__:train:118 - Epoch:  0 | Chunk:  0 | step: 1050 | mle_loss: 2.970303 | cl_loss: 2.455336 | loss: 15.246981
2022-07-27 16:31:02.665 | INFO     | __main__:train:118 - Epoch:  0 | Chunk:  0 | step: 1100 | mle_loss: 2.938985 | cl_loss: 2.371814 | loss: 14.798059
2022-07-27 16:31:20.564 | INFO     | __main__:train:118 - Epoch:  0 | Chunk:  0 | step: 1150 | mle_loss: 2.882972 | cl_loss: 2.288025 | loss: 14.323098
2022-07-27 16:31:38.444 | INFO     | __main__:train:118 - Epoch:  0 | Chunk:  0 | step: 1200 | mle_loss: 2.768723 | cl_loss: 2.226848 | loss: 13.902961
2022-07-27 16:31:55.923 | INFO     | processing.dataset:_load_and_cache_examples:43 - Loading examples from cache file data/cache/train_set/train_1.pkl
2022-07-27 16:31:57.868 | INFO     | __main__:train:118 - Epoch:  0 | Chunk:  1 | step:    0 | mle_loss: 2.748046 | cl_loss: 2.137906 | loss: 13.437572
2022-07-27 16:32:15.491 | INFO     | __main__:train:118 - Epoch:  0 | Chunk:  1 | step:   50 | mle_loss: 2.850858 | cl_loss: 2.140443 | loss: 13.553071
2022-07-27 16:32:33.051 | INFO     | __main__:train:118 - Epoch:  0 | Chunk:  1 | step:  100 | mle_loss: 2.801131 | cl_loss: 2.086883 | loss: 13.235544
2022-07-27 16:32:50.486 | INFO     | __main__:train:118 - Epoch:  0 | Chunk:  1 | step:  150 | mle_loss: 2.749859 | cl_loss: 2.030026 | loss: 12.899987
2022-07-27 16:33:07.839 | INFO     | __main__:train:118 - Epoch:  0 | Chunk:  1 | step:  200 | mle_loss: 2.714704 | cl_loss: 1.949503 | loss: 12.462223
2022-07-27 16:33:25.402 | INFO     | __main__:train:118 - Epoch:  0 | Chunk:  1 | step:  250 | mle_loss: 2.699017 | cl_loss: 1.852586 | loss: 11.961949
2022-07-27 16:33:43.226 | INFO     | __main__:train:118 - Epoch:  0 | Chunk:  1 | step:  300 | mle_loss: 2.633620 | cl_loss: 1.805355 | loss: 11.660394
2022-07-27 16:34:00.743 | INFO     | __main__:train:118 - Epoch:  0 | Chunk:  1 | step:  350 | mle_loss: 2.663347 | cl_loss: 1.727787 | loss: 11.302283
2022-07-27 16:34:18.289 | INFO     | __main__:train:118 - Epoch:  0 | Chunk:  1 | step:  400 | mle_loss: 2.617506 | cl_loss: 1.675339 | loss: 10.994202
2022-07-27 16:34:35.857 | INFO     | __main__:train:118 - Epoch:  0 | Chunk:  1 | step:  450 | mle_loss: 2.559421 | cl_loss: 1.604272 | loss: 10.580781
2022-07-27 16:34:53.471 | INFO     | __main__:train:118 - Epoch:  0 | Chunk:  1 | step:  500 | mle_loss: 2.515337 | cl_loss: 1.545817 | loss: 10.244421
2022-07-27 16:35:11.022 | INFO     | __main__:train:118 - Epoch:  0 | Chunk:  1 | step:  550 | mle_loss: 2.492505 | cl_loss: 1.490410 | loss: 9.944552
2022-07-27 16:35:28.833 | INFO     | __main__:train:118 - Epoch:  0 | Chunk:  1 | step:  600 | mle_loss: 2.474052 | cl_loss: 1.427567 | loss: 9.611891
2022-07-27 16:35:46.200 | INFO     | __main__:train:118 - Epoch:  0 | Chunk:  1 | step:  650 | mle_loss: 2.486705 | cl_loss: 1.375708 | loss: 9.365241
2022-07-27 16:36:03.996 | INFO     | __main__:train:118 - Epoch:  0 | Chunk:  1 | step:  700 | mle_loss: 2.429039 | cl_loss: 1.323558 | loss: 9.046828
2022-07-27 16:36:21.318 | INFO     | __main__:evaluate:178 - Generating...
2022-07-27 16:37:36.067 | INFO     | __main__:evaluate:188 - Generation finished.
2022-07-27 16:37:36.068 | INFO     | __main__:evaluate:195 - Rouge scores: {'rouge-1': 0.2989, 'rouge-2': 0.1617, 'rouge-l': 0.2663}
2022-07-27 16:37:36.068 | INFO     | __main__:train:137 - Eval loss: 0.0, the best loss: {'loss': 0.0, 'epoch': 0, 'step': 749}
2022-07-27 16:37:36.068 | INFO     | __main__:train:138 - Rouge scores: {'rouge-1': 0.2989, 'rouge-2': 0.1617, 'rouge-l': 0.2663, 'epoch': 0, 'step': 749}, the best scores: {'rouge-1': 0.2989, 'rouge-2': 0.1617, 'rouge-l': 0.2663, 'epoch': 0, 'step': 749}
2022-07-27 16:37:36.068 | INFO     | __main__:train:143 - Saving model checkpoint to checkpoints/MoCoBart-0-1-749
2022-07-27 16:37:38.189 | INFO     | __main__:train:118 - Epoch:  0 | Chunk:  1 | step:  750 | mle_loss: 2.362306 | cl_loss: 1.261123 | loss: 8.667920
2022-07-27 16:37:55.501 | INFO     | __main__:train:118 - Epoch:  0 | Chunk:  1 | step:  800 | mle_loss: 2.411597 | cl_loss: 1.215513 | loss: 8.489163
2022-07-27 16:38:13.049 | INFO     | __main__:train:118 - Epoch:  0 | Chunk:  1 | step:  850 | mle_loss: 2.349588 | cl_loss: 1.171504 | loss: 8.207107
2022-07-27 16:38:30.613 | INFO     | __main__:train:118 - Epoch:  0 | Chunk:  1 | step:  900 | mle_loss: 2.342599 | cl_loss: 1.107010 | loss: 7.877647
2022-07-27 16:38:48.172 | INFO     | __main__:train:118 - Epoch:  0 | Chunk:  1 | step:  950 | mle_loss: 2.340957 | cl_loss: 1.071607 | loss: 7.698993
2022-07-27 16:39:05.594 | INFO     | __main__:train:118 - Epoch:  0 | Chunk:  1 | step: 1000 | mle_loss: 2.287900 | cl_loss: 1.025738 | loss: 7.416590
2022-07-27 16:39:23.111 | INFO     | __main__:train:118 - Epoch:  0 | Chunk:  1 | step: 1050 | mle_loss: 2.233269 | cl_loss: 0.968739 | loss: 7.076962
2022-07-27 16:39:40.702 | INFO     | __main__:train:118 - Epoch:  0 | Chunk:  1 | step: 1100 | mle_loss: 2.284454 | cl_loss: 0.932378 | loss: 6.946346
2022-07-27 16:39:58.367 | INFO     | __main__:train:118 - Epoch:  0 | Chunk:  1 | step: 1150 | mle_loss: 2.227052 | cl_loss: 0.895998 | loss: 6.707045
2022-07-27 16:40:16.030 | INFO     | __main__:train:118 - Epoch:  0 | Chunk:  1 | step: 1200 | mle_loss: 2.224392 | cl_loss: 0.841733 | loss: 6.433060
2022-07-27 16:40:33.449 | INFO     | processing.dataset:_load_and_cache_examples:43 - Loading examples from cache file data/cache/train_set/train_2.pkl
2022-07-27 16:40:35.737 | INFO     | __main__:train:118 - Epoch:  0 | Chunk:  2 | step:    0 | mle_loss: 2.196651 | cl_loss: 0.807087 | loss: 6.232089
2022-07-27 16:40:53.596 | INFO     | __main__:train:118 - Epoch:  0 | Chunk:  2 | step:   50 | mle_loss: 2.209632 | cl_loss: 0.765509 | loss: 6.037177
2022-07-27 16:41:11.390 | INFO     | __main__:train:118 - Epoch:  0 | Chunk:  2 | step:  100 | mle_loss: 2.237604 | cl_loss: 0.728614 | loss: 5.880671
2022-07-27 16:41:29.322 | INFO     | __main__:train:118 - Epoch:  0 | Chunk:  2 | step:  150 | mle_loss: 2.157722 | cl_loss: 0.692754 | loss: 5.621493
2022-07-27 16:41:47.039 | INFO     | __main__:train:118 - Epoch:  0 | Chunk:  2 | step:  200 | mle_loss: 2.100220 | cl_loss: 0.655622 | loss: 5.378333
2022-07-27 16:42:04.773 | INFO     | __main__:train:118 - Epoch:  0 | Chunk:  2 | step:  250 | mle_loss: 2.103780 | cl_loss: 0.624612 | loss: 5.226840
2022-07-27 16:42:22.640 | INFO     | __main__:train:118 - Epoch:  0 | Chunk:  2 | step:  300 | mle_loss: 2.034483 | cl_loss: 0.595786 | loss: 5.013413
2022-07-27 16:42:40.241 | INFO     | __main__:train:118 - Epoch:  0 | Chunk:  2 | step:  350 | mle_loss: 2.059511 | cl_loss: 0.564135 | loss: 4.880186
2022-07-27 16:42:58.083 | INFO     | __main__:train:118 - Epoch:  0 | Chunk:  2 | step:  400 | mle_loss: 2.048782 | cl_loss: 0.545141 | loss: 4.774487
2022-07-27 16:43:16.103 | INFO     | __main__:train:118 - Epoch:  0 | Chunk:  2 | step:  450 | mle_loss: 2.029748 | cl_loss: 0.511530 | loss: 4.587397
2022-07-27 16:43:33.730 | INFO     | __main__:train:118 - Epoch:  0 | Chunk:  2 | step:  500 | mle_loss: 2.045990 | cl_loss: 0.489500 | loss: 4.493490
2022-07-27 16:43:51.603 | INFO     | __main__:train:118 - Epoch:  0 | Chunk:  2 | step:  550 | mle_loss: 1.974050 | cl_loss: 0.459714 | loss: 4.272620
2022-07-27 16:44:09.359 | INFO     | __main__:train:118 - Epoch:  0 | Chunk:  2 | step:  600 | mle_loss: 1.987671 | cl_loss: 0.442081 | loss: 4.198074
2022-07-27 16:44:27.005 | INFO     | __main__:train:118 - Epoch:  0 | Chunk:  2 | step:  650 | mle_loss: 1.975853 | cl_loss: 0.422301 | loss: 4.087358
2022-07-27 16:44:44.736 | INFO     | __main__:train:118 - Epoch:  0 | Chunk:  2 | step:  700 | mle_loss: 1.916799 | cl_loss: 0.402599 | loss: 3.929792
2022-07-27 16:45:02.348 | INFO     | __main__:train:118 - Epoch:  0 | Chunk:  2 | step:  750 | mle_loss: 1.897936 | cl_loss: 0.383402 | loss: 3.814945
2022-07-27 16:45:19.990 | INFO     | __main__:train:118 - Epoch:  0 | Chunk:  2 | step:  800 | mle_loss: 1.895314 | cl_loss: 0.365576 | loss: 3.723192
2022-07-27 16:45:37.894 | INFO     | __main__:train:118 - Epoch:  0 | Chunk:  2 | step:  850 | mle_loss: 1.910264 | cl_loss: 0.344305 | loss: 3.631788
2022-07-27 16:45:55.402 | INFO     | __main__:train:118 - Epoch:  0 | Chunk:  2 | step:  900 | mle_loss: 1.920867 | cl_loss: 0.339630 | loss: 3.619019
2022-07-27 16:46:13.095 | INFO     | __main__:train:118 - Epoch:  0 | Chunk:  2 | step:  950 | mle_loss: 1.867854 | cl_loss: 0.319836 | loss: 3.467035
2022-07-27 16:46:30.915 | INFO     | __main__:train:118 - Epoch:  0 | Chunk:  2 | step: 1000 | mle_loss: 1.862475 | cl_loss: 0.305314 | loss: 3.389044
2022-07-27 16:46:48.668 | INFO     | __main__:train:118 - Epoch:  0 | Chunk:  2 | step: 1050 | mle_loss: 1.850052 | cl_loss: 0.292708 | loss: 3.313595
2022-07-27 16:47:06.265 | INFO     | __main__:train:118 - Epoch:  0 | Chunk:  2 | step: 1100 | mle_loss: 1.818589 | cl_loss: 0.276991 | loss: 3.203543
2022-07-27 16:47:24.168 | INFO     | __main__:train:118 - Epoch:  0 | Chunk:  2 | step: 1150 | mle_loss: 1.766889 | cl_loss: 0.267102 | loss: 3.102397
2022-07-27 16:47:41.846 | INFO     | __main__:train:118 - Epoch:  0 | Chunk:  2 | step: 1200 | mle_loss: 1.792950 | cl_loss: 0.257416 | loss: 3.080028
2022-07-27 16:47:59.390 | INFO     | processing.dataset:_load_and_cache_examples:43 - Loading examples from cache file data/cache/train_set/train_3.pkl
2022-07-27 16:48:01.294 | INFO     | __main__:train:118 - Epoch:  0 | Chunk:  3 | step:    0 | mle_loss: 1.805995 | cl_loss: 0.241827 | loss: 3.015128
2022-07-27 16:48:19.205 | INFO     | __main__:train:118 - Epoch:  0 | Chunk:  3 | step:   50 | mle_loss: 1.821575 | cl_loss: 0.254667 | loss: 3.094908
2022-07-27 16:48:37.323 | INFO     | __main__:train:118 - Epoch:  0 | Chunk:  3 | step:  100 | mle_loss: 1.751852 | cl_loss: 0.240933 | loss: 2.956516
2022-07-27 16:48:55.343 | INFO     | __main__:train:118 - Epoch:  0 | Chunk:  3 | step:  150 | mle_loss: 1.787597 | cl_loss: 0.232841 | loss: 2.951802
2022-07-27 16:49:13.123 | INFO     | __main__:train:118 - Epoch:  0 | Chunk:  3 | step:  200 | mle_loss: 1.754542 | cl_loss: 0.222338 | loss: 2.866233
2022-07-27 16:49:30.562 | INFO     | __main__:evaluate:178 - Generating...
2022-07-27 16:50:51.093 | INFO     | __main__:evaluate:188 - Generation finished.
2022-07-27 16:50:51.094 | INFO     | __main__:evaluate:195 - Rouge scores: {'rouge-1': 0.3484, 'rouge-2': 0.1998, 'rouge-l': 0.309}
2022-07-27 16:50:51.094 | INFO     | __main__:train:137 - Eval loss: 0.0, the best loss: {'loss': 0.0, 'epoch': 0, 'step': 749}
2022-07-27 16:50:51.094 | INFO     | __main__:train:138 - Rouge scores: {'rouge-1': 0.3484, 'rouge-2': 0.1998, 'rouge-l': 0.309, 'epoch': 0, 'step': 249}, the best scores: {'rouge-1': 0.3484, 'rouge-2': 0.1998, 'rouge-l': 0.309, 'epoch': 0, 'step': 249}
2022-07-27 16:50:51.094 | INFO     | __main__:train:143 - Saving model checkpoint to checkpoints/MoCoBart-0-3-249
2022-07-27 16:50:53.236 | INFO     | __main__:train:118 - Epoch:  0 | Chunk:  3 | step:  250 | mle_loss: 1.713464 | cl_loss: 0.215057 | loss: 2.788747
2022-07-27 16:51:10.969 | INFO     | __main__:train:118 - Epoch:  0 | Chunk:  3 | step:  300 | mle_loss: 1.675699 | cl_loss: 0.198163 | loss: 2.666513
2022-07-27 16:51:28.897 | INFO     | __main__:train:118 - Epoch:  0 | Chunk:  3 | step:  350 | mle_loss: 1.686408 | cl_loss: 0.192242 | loss: 2.647617
2022-07-27 16:51:46.696 | INFO     | __main__:train:118 - Epoch:  0 | Chunk:  3 | step:  400 | mle_loss: 1.711494 | cl_loss: 0.183710 | loss: 2.630042
2022-07-27 16:52:04.723 | INFO     | __main__:train:118 - Epoch:  0 | Chunk:  3 | step:  450 | mle_loss: 1.674987 | cl_loss: 0.175870 | loss: 2.554340
2022-07-27 16:52:22.628 | INFO     | __main__:train:118 - Epoch:  0 | Chunk:  3 | step:  500 | mle_loss: 1.689044 | cl_loss: 0.172745 | loss: 2.552769
2022-07-27 16:52:40.793 | INFO     | __main__:train:118 - Epoch:  0 | Chunk:  3 | step:  550 | mle_loss: 1.655057 | cl_loss: 0.164900 | loss: 2.479557
2022-07-27 16:52:58.793 | INFO     | __main__:train:118 - Epoch:  0 | Chunk:  3 | step:  600 | mle_loss: 1.678432 | cl_loss: 0.162288 | loss: 2.489872
2022-07-27 16:53:16.840 | INFO     | __main__:train:118 - Epoch:  0 | Chunk:  3 | step:  650 | mle_loss: 1.687852 | cl_loss: 0.155054 | loss: 2.463121
2022-07-27 16:53:34.879 | INFO     | __main__:train:118 - Epoch:  0 | Chunk:  3 | step:  700 | mle_loss: 1.603594 | cl_loss: 0.148544 | loss: 2.346315
2022-07-27 16:53:52.641 | INFO     | __main__:train:118 - Epoch:  0 | Chunk:  3 | step:  750 | mle_loss: 1.637399 | cl_loss: 0.143407 | loss: 2.354434
2022-07-27 16:54:10.619 | INFO     | __main__:train:118 - Epoch:  0 | Chunk:  3 | step:  800 | mle_loss: 1.596165 | cl_loss: 0.138655 | loss: 2.289442
2022-07-27 16:54:28.852 | INFO     | __main__:train:118 - Epoch:  0 | Chunk:  3 | step:  850 | mle_loss: 1.614658 | cl_loss: 0.136350 | loss: 2.296410
2022-07-27 16:54:46.944 | INFO     | __main__:train:118 - Epoch:  0 | Chunk:  3 | step:  900 | mle_loss: 1.607173 | cl_loss: 0.134056 | loss: 2.277456
2022-07-27 16:55:04.861 | INFO     | __main__:train:118 - Epoch:  0 | Chunk:  3 | step:  950 | mle_loss: 1.587898 | cl_loss: 0.130156 | loss: 2.238680
2022-07-27 16:55:23.207 | INFO     | __main__:train:118 - Epoch:  0 | Chunk:  3 | step: 1000 | mle_loss: 1.581022 | cl_loss: 0.124394 | loss: 2.202989
2022-07-27 16:55:41.334 | INFO     | __main__:train:118 - Epoch:  0 | Chunk:  3 | step: 1050 | mle_loss: 1.592832 | cl_loss: 0.121856 | loss: 2.202114
2022-07-27 16:55:59.549 | INFO     | __main__:train:118 - Epoch:  0 | Chunk:  3 | step: 1100 | mle_loss: 1.560660 | cl_loss: 0.117124 | loss: 2.146280
2022-07-27 16:56:17.560 | INFO     | __main__:train:118 - Epoch:  0 | Chunk:  3 | step: 1150 | mle_loss: 1.574095 | cl_loss: 0.115932 | loss: 2.153753
2022-07-27 16:56:35.455 | INFO     | __main__:train:118 - Epoch:  0 | Chunk:  3 | step: 1200 | mle_loss: 1.610027 | cl_loss: 0.112465 | loss: 2.172355
2022-07-27 16:56:53.331 | INFO     | processing.dataset:_load_and_cache_examples:43 - Loading examples from cache file data/cache/train_set/train_4.pkl
2022-07-27 16:56:55.103 | INFO     | __main__:train:118 - Epoch:  0 | Chunk:  4 | step:    0 | mle_loss: 1.549184 | cl_loss: 0.109499 | loss: 2.096678
2022-07-27 16:57:12.787 | INFO     | __main__:train:118 - Epoch:  0 | Chunk:  4 | step:   50 | mle_loss: 1.602535 | cl_loss: 0.107423 | loss: 2.139650
2022-07-27 16:57:30.820 | INFO     | __main__:train:118 - Epoch:  0 | Chunk:  4 | step:  100 | mle_loss: 1.551442 | cl_loss: 0.106765 | loss: 2.085269
2022-07-27 16:57:48.601 | INFO     | __main__:train:118 - Epoch:  0 | Chunk:  4 | step:  150 | mle_loss: 1.565156 | cl_loss: 0.104249 | loss: 2.086401
2022-07-27 16:58:06.471 | INFO     | __main__:train:118 - Epoch:  0 | Chunk:  4 | step:  200 | mle_loss: 1.535876 | cl_loss: 0.102915 | loss: 2.050451
2022-07-27 16:58:24.402 | INFO     | __main__:train:118 - Epoch:  0 | Chunk:  4 | step:  250 | mle_loss: 1.550978 | cl_loss: 0.101632 | loss: 2.059136
2022-07-27 16:58:42.137 | INFO     | __main__:train:118 - Epoch:  0 | Chunk:  4 | step:  300 | mle_loss: 1.543627 | cl_loss: 0.098353 | loss: 2.035390
2022-07-27 16:58:59.876 | INFO     | __main__:train:118 - Epoch:  0 | Chunk:  4 | step:  350 | mle_loss: 1.545130 | cl_loss: 0.093498 | loss: 2.012621
2022-07-27 16:59:17.516 | INFO     | __main__:train:118 - Epoch:  0 | Chunk:  4 | step:  400 | mle_loss: 1.519183 | cl_loss: 0.092946 | loss: 1.983912
2022-07-27 16:59:35.615 | INFO     | __main__:train:118 - Epoch:  0 | Chunk:  4 | step:  450 | mle_loss: 1.501964 | cl_loss: 0.092932 | loss: 1.966623
2022-07-27 16:59:53.491 | INFO     | __main__:train:118 - Epoch:  0 | Chunk:  4 | step:  500 | mle_loss: 1.550687 | cl_loss: 0.091358 | loss: 2.007477
2022-07-27 17:00:11.372 | INFO     | __main__:train:118 - Epoch:  0 | Chunk:  4 | step:  550 | mle_loss: 1.485576 | cl_loss: 0.087463 | loss: 1.922891
2022-07-27 17:00:28.911 | INFO     | __main__:train:118 - Epoch:  0 | Chunk:  4 | step:  600 | mle_loss: 1.501450 | cl_loss: 0.088000 | loss: 1.941451
2022-07-27 17:00:46.511 | INFO     | __main__:train:118 - Epoch:  0 | Chunk:  4 | step:  650 | mle_loss: 1.547668 | cl_loss: 0.084922 | loss: 1.972276
2022-07-27 17:01:04.211 | INFO     | __main__:train:118 - Epoch:  0 | Chunk:  4 | step:  700 | mle_loss: 1.463781 | cl_loss: 0.085059 | loss: 1.889077
2022-07-27 17:01:21.925 | INFO     | __main__:train:118 - Epoch:  0 | Chunk:  4 | step:  750 | mle_loss: 1.490881 | cl_loss: 0.084887 | loss: 1.915313
2022-07-27 17:01:39.670 | INFO     | __main__:train:118 - Epoch:  0 | Chunk:  4 | step:  800 | mle_loss: 1.511189 | cl_loss: 0.082714 | loss: 1.924760
2022-07-27 17:01:57.467 | INFO     | __main__:train:118 - Epoch:  0 | Chunk:  4 | step:  850 | mle_loss: 1.483138 | cl_loss: 0.080958 | loss: 1.887928
2022-07-27 17:02:15.150 | INFO     | __main__:train:118 - Epoch:  0 | Chunk:  4 | step:  900 | mle_loss: 1.475115 | cl_loss: 0.081609 | loss: 1.883160
2022-07-27 17:02:32.736 | INFO     | __main__:train:118 - Epoch:  0 | Chunk:  4 | step:  950 | mle_loss: 1.458155 | cl_loss: 0.078850 | loss: 1.852406
2022-07-27 17:02:50.247 | INFO     | __main__:evaluate:178 - Generating...
2022-07-27 17:04:14.292 | INFO     | __main__:evaluate:188 - Generation finished.
2022-07-27 17:04:14.292 | INFO     | __main__:evaluate:195 - Rouge scores: {'rouge-1': 0.3703, 'rouge-2': 0.2174, 'rouge-l': 0.3263}
2022-07-27 17:04:14.292 | INFO     | __main__:train:137 - Eval loss: 0.0, the best loss: {'loss': 0.0, 'epoch': 0, 'step': 749}
2022-07-27 17:04:14.293 | INFO     | __main__:train:138 - Rouge scores: {'rouge-1': 0.3703, 'rouge-2': 0.2174, 'rouge-l': 0.3263, 'epoch': 0, 'step': 999}, the best scores: {'rouge-1': 0.3703, 'rouge-2': 0.2174, 'rouge-l': 0.3263, 'epoch': 0, 'step': 999}
2022-07-27 17:04:14.293 | INFO     | __main__:train:143 - Saving model checkpoint to checkpoints/MoCoBart-0-4-999
2022-07-27 17:04:16.780 | INFO     | __main__:train:118 - Epoch:  0 | Chunk:  4 | step: 1000 | mle_loss: 1.474815 | cl_loss: 0.076273 | loss: 1.856180
2022-07-27 17:04:34.499 | INFO     | __main__:train:118 - Epoch:  0 | Chunk:  4 | step: 1050 | mle_loss: 1.488944 | cl_loss: 0.075617 | loss: 1.867026
2022-07-27 17:04:52.248 | INFO     | __main__:train:118 - Epoch:  0 | Chunk:  4 | step: 1100 | mle_loss: 1.465877 | cl_loss: 0.075980 | loss: 1.845777
2022-07-27 17:05:09.948 | INFO     | __main__:train:118 - Epoch:  0 | Chunk:  4 | step: 1150 | mle_loss: 1.490157 | cl_loss: 0.073794 | loss: 1.859128
2022-07-27 17:05:27.807 | INFO     | __main__:train:118 - Epoch:  0 | Chunk:  4 | step: 1200 | mle_loss: 1.437319 | cl_loss: 0.070923 | loss: 1.791931
2022-07-27 17:05:45.342 | INFO     | processing.dataset:_load_and_cache_examples:43 - Loading examples from cache file data/cache/train_set/train_5.pkl
2022-07-27 17:05:47.274 | INFO     | __main__:train:118 - Epoch:  0 | Chunk:  5 | step:    0 | mle_loss: 1.424434 | cl_loss: 0.071419 | loss: 1.781527
2022-07-27 17:06:05.228 | INFO     | __main__:train:118 - Epoch:  0 | Chunk:  5 | step:   50 | mle_loss: 1.627688 | cl_loss: 0.072404 | loss: 1.989710
2022-07-27 17:06:23.127 | INFO     | __main__:train:118 - Epoch:  0 | Chunk:  5 | step:  100 | mle_loss: 1.569108 | cl_loss: 0.071542 | loss: 1.926817
2022-07-27 17:06:40.814 | INFO     | __main__:train:118 - Epoch:  0 | Chunk:  5 | step:  150 | mle_loss: 1.606249 | cl_loss: 0.073718 | loss: 1.974839
2022-07-27 17:06:58.806 | INFO     | __main__:train:118 - Epoch:  0 | Chunk:  5 | step:  200 | mle_loss: 1.569090 | cl_loss: 0.074308 | loss: 1.940629
2022-07-27 17:07:16.767 | INFO     | __main__:train:118 - Epoch:  0 | Chunk:  5 | step:  250 | mle_loss: 1.557884 | cl_loss: 0.071279 | loss: 1.914278
2022-07-27 17:07:34.502 | INFO     | __main__:train:118 - Epoch:  0 | Chunk:  5 | step:  300 | mle_loss: 1.557590 | cl_loss: 0.068861 | loss: 1.901897
2022-07-27 17:07:52.428 | INFO     | __main__:train:118 - Epoch:  0 | Chunk:  5 | step:  350 | mle_loss: 1.552329 | cl_loss: 0.068873 | loss: 1.896693
2022-07-27 17:08:10.369 | INFO     | __main__:train:118 - Epoch:  0 | Chunk:  5 | step:  400 | mle_loss: 1.534382 | cl_loss: 0.068745 | loss: 1.878108
2022-07-27 17:08:28.255 | INFO     | __main__:train:118 - Epoch:  0 | Chunk:  5 | step:  450 | mle_loss: 1.523113 | cl_loss: 0.068191 | loss: 1.864070
2022-07-27 17:08:46.266 | INFO     | __main__:train:118 - Epoch:  0 | Chunk:  5 | step:  500 | mle_loss: 1.530966 | cl_loss: 0.066514 | loss: 1.863537
2022-07-27 17:09:03.809 | INFO     | __main__:train:118 - Epoch:  0 | Chunk:  5 | step:  550 | mle_loss: 1.584482 | cl_loss: 0.066501 | loss: 1.916988
2022-07-27 17:09:21.548 | INFO     | __main__:train:118 - Epoch:  0 | Chunk:  5 | step:  600 | mle_loss: 1.516134 | cl_loss: 0.066118 | loss: 1.846725
2022-07-27 17:09:39.473 | INFO     | __main__:train:118 - Epoch:  0 | Chunk:  5 | step:  650 | mle_loss: 1.520563 | cl_loss: 0.069091 | loss: 1.866016
2022-07-27 17:09:57.232 | INFO     | __main__:train:118 - Epoch:  0 | Chunk:  5 | step:  700 | mle_loss: 1.528294 | cl_loss: 0.065371 | loss: 1.855148
2022-07-27 17:10:15.180 | INFO     | __main__:train:118 - Epoch:  0 | Chunk:  5 | step:  750 | mle_loss: 1.523866 | cl_loss: 0.064492 | loss: 1.846326
2022-07-27 17:10:33.127 | INFO     | __main__:train:118 - Epoch:  0 | Chunk:  5 | step:  800 | mle_loss: 1.547062 | cl_loss: 0.064633 | loss: 1.870227
2022-07-27 17:10:50.915 | INFO     | __main__:train:118 - Epoch:  0 | Chunk:  5 | step:  850 | mle_loss: 1.505223 | cl_loss: 0.065403 | loss: 1.832237
2022-07-27 17:11:08.761 | INFO     | __main__:train:118 - Epoch:  0 | Chunk:  5 | step:  900 | mle_loss: 1.526432 | cl_loss: 0.066885 | loss: 1.860859
2022-07-27 17:11:26.698 | INFO     | __main__:train:118 - Epoch:  0 | Chunk:  5 | step:  950 | mle_loss: 1.535452 | cl_loss: 0.066077 | loss: 1.865839
2022-07-27 17:11:44.481 | INFO     | __main__:train:118 - Epoch:  0 | Chunk:  5 | step: 1000 | mle_loss: 1.549745 | cl_loss: 0.065176 | loss: 1.875626
2022-07-27 17:12:02.167 | INFO     | __main__:train:118 - Epoch:  0 | Chunk:  5 | step: 1050 | mle_loss: 1.507152 | cl_loss: 0.063907 | loss: 1.826687
2022-07-27 17:12:20.107 | INFO     | __main__:train:118 - Epoch:  0 | Chunk:  5 | step: 1100 | mle_loss: 1.486744 | cl_loss: 0.062537 | loss: 1.799428
2022-07-27 17:12:38.273 | INFO     | __main__:train:118 - Epoch:  0 | Chunk:  5 | step: 1150 | mle_loss: 1.548224 | cl_loss: 0.062720 | loss: 1.861826
2022-07-27 17:12:56.142 | INFO     | __main__:train:118 - Epoch:  0 | Chunk:  5 | step: 1200 | mle_loss: 1.525728 | cl_loss: 0.062273 | loss: 1.837094
2022-07-27 17:13:13.562 | INFO     | processing.dataset:_load_and_cache_examples:43 - Loading examples from cache file data/cache/train_set/train_6.pkl
2022-07-27 17:13:15.674 | INFO     | __main__:train:118 - Epoch:  0 | Chunk:  6 | step:    0 | mle_loss: 1.512941 | cl_loss: 0.062577 | loss: 1.825828
2022-07-27 17:13:33.511 | INFO     | __main__:train:118 - Epoch:  0 | Chunk:  6 | step:   50 | mle_loss: 1.554009 | cl_loss: 0.064947 | loss: 1.878744
2022-07-27 17:13:51.431 | INFO     | __main__:train:118 - Epoch:  0 | Chunk:  6 | step:  100 | mle_loss: 1.541249 | cl_loss: 0.064954 | loss: 1.866017
2022-07-27 17:14:09.543 | INFO     | __main__:train:118 - Epoch:  0 | Chunk:  6 | step:  150 | mle_loss: 1.509349 | cl_loss: 0.063354 | loss: 1.826121
2022-07-27 17:14:27.583 | INFO     | __main__:train:118 - Epoch:  0 | Chunk:  6 | step:  200 | mle_loss: 1.523828 | cl_loss: 0.065704 | loss: 1.852350
2022-07-27 17:14:45.323 | INFO     | __main__:train:118 - Epoch:  0 | Chunk:  6 | step:  250 | mle_loss: 1.509289 | cl_loss: 0.063236 | loss: 1.825468
2022-07-27 17:15:03.143 | INFO     | __main__:train:118 - Epoch:  0 | Chunk:  6 | step:  300 | mle_loss: 1.517040 | cl_loss: 0.062962 | loss: 1.831850
2022-07-27 17:15:20.900 | INFO     | __main__:train:118 - Epoch:  0 | Chunk:  6 | step:  350 | mle_loss: 1.497803 | cl_loss: 0.065291 | loss: 1.824258
2022-07-27 17:15:38.783 | INFO     | __main__:train:118 - Epoch:  0 | Chunk:  6 | step:  400 | mle_loss: 1.465320 | cl_loss: 0.062607 | loss: 1.778355
2022-07-27 17:15:56.842 | INFO     | __main__:train:118 - Epoch:  0 | Chunk:  6 | step:  450 | mle_loss: 1.524672 | cl_loss: 0.062571 | loss: 1.837527
2022-07-27 17:16:14.247 | INFO     | __main__:evaluate:178 - Generating...
2022-07-27 17:17:35.719 | INFO     | __main__:evaluate:188 - Generation finished.
2022-07-27 17:17:35.720 | INFO     | __main__:evaluate:195 - Rouge scores: {'rouge-1': 0.3697, 'rouge-2': 0.2146, 'rouge-l': 0.3265}
2022-07-27 17:17:35.720 | INFO     | __main__:train:137 - Eval loss: 0.0, the best loss: {'loss': 0.0, 'epoch': 0, 'step': 749}
2022-07-27 17:17:35.720 | INFO     | __main__:train:138 - Rouge scores: {'rouge-1': 0.3697, 'rouge-2': 0.2146, 'rouge-l': 0.3265}, the best scores: {'rouge-1': 0.3703, 'rouge-2': 0.2174, 'rouge-l': 0.3263, 'epoch': 0, 'step': 999}
2022-07-27 17:17:35.720 | INFO     | __main__:train:143 - Saving model checkpoint to checkpoints/MoCoBart-0-6-499
2022-07-27 17:17:37.898 | INFO     | __main__:train:118 - Epoch:  0 | Chunk:  6 | step:  500 | mle_loss: 1.508247 | cl_loss: 0.061480 | loss: 1.815647
2022-07-27 17:17:55.475 | INFO     | __main__:train:118 - Epoch:  0 | Chunk:  6 | step:  550 | mle_loss: 1.593338 | cl_loss: 0.063719 | loss: 1.911934
2022-07-27 17:18:13.433 | INFO     | __main__:train:118 - Epoch:  0 | Chunk:  6 | step:  600 | mle_loss: 1.463444 | cl_loss: 0.061701 | loss: 1.771951
2022-07-27 17:18:31.115 | INFO     | __main__:train:118 - Epoch:  0 | Chunk:  6 | step:  650 | mle_loss: 1.477395 | cl_loss: 0.063475 | loss: 1.794770
2022-07-27 17:18:48.954 | INFO     | __main__:train:118 - Epoch:  0 | Chunk:  6 | step:  700 | mle_loss: 1.498195 | cl_loss: 0.061753 | loss: 1.806961
2022-07-27 17:19:06.940 | INFO     | __main__:train:118 - Epoch:  0 | Chunk:  6 | step:  750 | mle_loss: 1.487768 | cl_loss: 0.062707 | loss: 1.801301
2022-07-27 17:19:24.990 | INFO     | __main__:train:118 - Epoch:  0 | Chunk:  6 | step:  800 | mle_loss: 1.505242 | cl_loss: 0.063345 | loss: 1.821969
2022-07-27 17:19:42.766 | INFO     | __main__:train:118 - Epoch:  0 | Chunk:  6 | step:  850 | mle_loss: 1.492217 | cl_loss: 0.060648 | loss: 1.795454
2022-07-27 17:20:00.534 | INFO     | __main__:train:118 - Epoch:  0 | Chunk:  6 | step:  900 | mle_loss: 1.459121 | cl_loss: 0.058857 | loss: 1.753406
2022-07-27 17:20:18.285 | INFO     | __main__:train:118 - Epoch:  0 | Chunk:  6 | step:  950 | mle_loss: 1.464505 | cl_loss: 0.062669 | loss: 1.777851
2022-07-27 17:20:35.968 | INFO     | __main__:train:118 - Epoch:  0 | Chunk:  6 | step: 1000 | mle_loss: 1.464612 | cl_loss: 0.062174 | loss: 1.775483
2022-07-27 17:20:53.719 | INFO     | __main__:train:118 - Epoch:  0 | Chunk:  6 | step: 1050 | mle_loss: 1.455178 | cl_loss: 0.060340 | loss: 1.756879
2022-07-27 17:21:11.422 | INFO     | __main__:train:118 - Epoch:  0 | Chunk:  6 | step: 1100 | mle_loss: 1.478357 | cl_loss: 0.059233 | loss: 1.774520
2022-07-27 17:21:29.313 | INFO     | __main__:train:118 - Epoch:  0 | Chunk:  6 | step: 1150 | mle_loss: 1.477936 | cl_loss: 0.059881 | loss: 1.777340
2022-07-27 17:21:47.237 | INFO     | __main__:train:118 - Epoch:  0 | Chunk:  6 | step: 1200 | mle_loss: 1.447232 | cl_loss: 0.061618 | loss: 1.755324
2022-07-27 17:22:04.828 | INFO     | processing.dataset:_load_and_cache_examples:43 - Loading examples from cache file data/cache/train_set/train_7.pkl
2022-07-27 17:22:06.220 | INFO     | __main__:train:118 - Epoch:  0 | Chunk:  7 | step:    0 | mle_loss: 1.433858 | cl_loss: 0.059297 | loss: 1.730344
2022-07-27 17:22:24.230 | INFO     | __main__:train:118 - Epoch:  0 | Chunk:  7 | step:   50 | mle_loss: 1.694222 | cl_loss: 0.073826 | loss: 2.063350
2022-07-27 17:22:42.198 | INFO     | __main__:train:118 - Epoch:  0 | Chunk:  7 | step:  100 | mle_loss: 1.639621 | cl_loss: 0.072863 | loss: 2.003935
2022-07-27 17:23:00.030 | INFO     | __main__:train:118 - Epoch:  0 | Chunk:  7 | step:  150 | mle_loss: 1.631536 | cl_loss: 0.070590 | loss: 1.984486
2022-07-27 17:23:17.983 | INFO     | __main__:train:118 - Epoch:  0 | Chunk:  7 | step:  200 | mle_loss: 1.605522 | cl_loss: 0.069944 | loss: 1.955245
2022-07-27 17:23:35.989 | INFO     | __main__:train:118 - Epoch:  0 | Chunk:  7 | step:  250 | mle_loss: 1.615275 | cl_loss: 0.069066 | loss: 1.960606
2022-07-27 17:23:53.784 | INFO     | __main__:train:118 - Epoch:  0 | Chunk:  7 | step:  300 | mle_loss: 1.602350 | cl_loss: 0.068702 | loss: 1.945860
2022-07-27 17:24:11.533 | INFO     | __main__:train:118 - Epoch:  0 | Chunk:  7 | step:  350 | mle_loss: 1.610345 | cl_loss: 0.069112 | loss: 1.955906
2022-07-27 17:24:29.231 | INFO     | __main__:train:118 - Epoch:  0 | Chunk:  7 | step:  400 | mle_loss: 1.634183 | cl_loss: 0.068686 | loss: 1.977614
2022-07-27 17:24:47.093 | INFO     | __main__:train:118 - Epoch:  0 | Chunk:  7 | step:  450 | mle_loss: 1.571173 | cl_loss: 0.066041 | loss: 1.901377
2022-07-27 17:25:04.890 | INFO     | __main__:train:118 - Epoch:  0 | Chunk:  7 | step:  500 | mle_loss: 1.608571 | cl_loss: 0.065727 | loss: 1.937205
2022-07-27 17:25:22.518 | INFO     | __main__:train:118 - Epoch:  0 | Chunk:  7 | step:  550 | mle_loss: 1.646573 | cl_loss: 0.064956 | loss: 1.971356
2022-07-27 17:25:40.315 | INFO     | __main__:train:118 - Epoch:  0 | Chunk:  7 | step:  600 | mle_loss: 1.578294 | cl_loss: 0.064851 | loss: 1.902550
2022-07-27 17:25:58.404 | INFO     | __main__:train:118 - Epoch:  0 | Chunk:  7 | step:  650 | mle_loss: 1.577058 | cl_loss: 0.064957 | loss: 1.901842
2022-07-27 17:26:16.434 | INFO     | __main__:train:118 - Epoch:  0 | Chunk:  7 | step:  700 | mle_loss: 1.553697 | cl_loss: 0.062077 | loss: 1.864080
2022-07-27 17:26:34.362 | INFO     | __main__:train:118 - Epoch:  0 | Chunk:  7 | step:  750 | mle_loss: 1.600388 | cl_loss: 0.061370 | loss: 1.907240
2022-07-27 17:26:52.239 | INFO     | __main__:train:118 - Epoch:  0 | Chunk:  7 | step:  800 | mle_loss: 1.571267 | cl_loss: 0.061716 | loss: 1.879845
2022-07-27 17:27:09.869 | INFO     | __main__:train:118 - Epoch:  0 | Chunk:  7 | step:  850 | mle_loss: 1.581056 | cl_loss: 0.061977 | loss: 1.890942
2022-07-27 17:27:27.632 | INFO     | __main__:train:118 - Epoch:  0 | Chunk:  7 | step:  900 | mle_loss: 1.563632 | cl_loss: 0.063300 | loss: 1.880134
2022-07-27 17:27:45.321 | INFO     | __main__:train:118 - Epoch:  0 | Chunk:  7 | step:  950 | mle_loss: 1.604522 | cl_loss: 0.061688 | loss: 1.912961
2022-07-27 17:28:02.986 | INFO     | __main__:train:118 - Epoch:  0 | Chunk:  7 | step: 1000 | mle_loss: 1.592842 | cl_loss: 0.059182 | loss: 1.888753
2022-07-27 17:28:20.970 | INFO     | __main__:train:118 - Epoch:  0 | Chunk:  7 | step: 1050 | mle_loss: 1.524174 | cl_loss: 0.060909 | loss: 1.828719
2022-07-27 17:28:38.847 | INFO     | __main__:train:118 - Epoch:  0 | Chunk:  7 | step: 1100 | mle_loss: 1.583736 | cl_loss: 0.062841 | loss: 1.897943
2022-07-27 17:28:56.766 | INFO     | __main__:train:118 - Epoch:  0 | Chunk:  7 | step: 1150 | mle_loss: 1.565521 | cl_loss: 0.060111 | loss: 1.866074
2022-07-27 17:29:14.491 | INFO     | __main__:train:118 - Epoch:  0 | Chunk:  7 | step: 1200 | mle_loss: 1.558334 | cl_loss: 0.061806 | loss: 1.867362
2022-07-27 17:29:32.094 | INFO     | __main__:evaluate:178 - Generating...
2022-07-27 17:30:53.655 | INFO     | __main__:evaluate:188 - Generation finished.
2022-07-27 17:30:53.656 | INFO     | __main__:evaluate:195 - Rouge scores: {'rouge-1': 0.3722, 'rouge-2': 0.22, 'rouge-l': 0.3356}
2022-07-27 17:30:53.656 | INFO     | __main__:train:137 - Eval loss: 0.0, the best loss: {'loss': 0.0, 'epoch': 0, 'step': 749}
2022-07-27 17:30:53.656 | INFO     | __main__:train:138 - Rouge scores: {'rouge-1': 0.3722, 'rouge-2': 0.22, 'rouge-l': 0.3356, 'epoch': 0, 'step': 1249}, the best scores: {'rouge-1': 0.3722, 'rouge-2': 0.22, 'rouge-l': 0.3356, 'epoch': 0, 'step': 1249}
2022-07-27 17:30:53.656 | INFO     | __main__:train:143 - Saving model checkpoint to checkpoints/MoCoBart-0-7-1249
2022-07-27 17:30:55.479 | INFO     | processing.dataset:_load_and_cache_examples:43 - Loading examples from cache file data/cache/train_set/train_8.pkl
2022-07-27 17:30:57.162 | INFO     | __main__:train:118 - Epoch:  0 | Chunk:  8 | step:    0 | mle_loss: 1.569704 | cl_loss: 0.063983 | loss: 1.889621
2022-07-27 17:31:14.689 | INFO     | __main__:train:118 - Epoch:  0 | Chunk:  8 | step:   50 | mle_loss: 1.572488 | cl_loss: 0.056877 | loss: 1.856874
2022-07-27 17:31:32.364 | INFO     | __main__:train:118 - Epoch:  0 | Chunk:  8 | step:  100 | mle_loss: 1.592176 | cl_loss: 0.057002 | loss: 1.877186
2022-07-27 17:31:50.035 | INFO     | __main__:train:118 - Epoch:  0 | Chunk:  8 | step:  150 | mle_loss: 1.563003 | cl_loss: 0.054672 | loss: 1.836361
2022-07-27 17:32:07.496 | INFO     | __main__:train:118 - Epoch:  0 | Chunk:  8 | step:  200 | mle_loss: 1.604241 | cl_loss: 0.055652 | loss: 1.882502
2022-07-27 17:32:25.286 | INFO     | __main__:train:118 - Epoch:  0 | Chunk:  8 | step:  250 | mle_loss: 1.570828 | cl_loss: 0.056431 | loss: 1.852982
2022-07-27 17:32:43.023 | INFO     | __main__:train:118 - Epoch:  0 | Chunk:  8 | step:  300 | mle_loss: 1.574471 | cl_loss: 0.054394 | loss: 1.846439
2022-07-27 17:33:00.822 | INFO     | __main__:train:118 - Epoch:  0 | Chunk:  8 | step:  350 | mle_loss: 1.583513 | cl_loss: 0.055664 | loss: 1.861832
2022-07-27 17:33:18.793 | INFO     | __main__:train:118 - Epoch:  0 | Chunk:  8 | step:  400 | mle_loss: 1.580004 | cl_loss: 0.055039 | loss: 1.855198
2022-07-27 17:33:36.175 | INFO     | __main__:train:118 - Epoch:  0 | Chunk:  8 | step:  450 | mle_loss: 1.570991 | cl_loss: 0.054835 | loss: 1.845166
2022-07-27 17:33:53.412 | INFO     | __main__:train:118 - Epoch:  0 | Chunk:  8 | step:  500 | mle_loss: 1.537638 | cl_loss: 0.054641 | loss: 1.810843
2022-07-27 17:34:11.203 | INFO     | __main__:train:118 - Epoch:  0 | Chunk:  8 | step:  550 | mle_loss: 1.555436 | cl_loss: 0.052215 | loss: 1.816511
2022-07-27 17:34:29.123 | INFO     | __main__:train:118 - Epoch:  0 | Chunk:  8 | step:  600 | mle_loss: 1.537612 | cl_loss: 0.054433 | loss: 1.809777
2022-07-27 17:34:46.764 | INFO     | __main__:train:118 - Epoch:  0 | Chunk:  8 | step:  650 | mle_loss: 1.548801 | cl_loss: 0.055714 | loss: 1.827373
2022-07-27 17:35:04.465 | INFO     | __main__:train:118 - Epoch:  0 | Chunk:  8 | step:  700 | mle_loss: 1.565785 | cl_loss: 0.054672 | loss: 1.839146
2022-07-27 17:35:22.442 | INFO     | __main__:train:118 - Epoch:  0 | Chunk:  8 | step:  750 | mle_loss: 1.516911 | cl_loss: 0.056132 | loss: 1.797570
2022-07-27 17:35:40.268 | INFO     | __main__:train:118 - Epoch:  0 | Chunk:  8 | step:  800 | mle_loss: 1.557753 | cl_loss: 0.054512 | loss: 1.830312
2022-07-27 17:35:58.008 | INFO     | __main__:train:118 - Epoch:  0 | Chunk:  8 | step:  850 | mle_loss: 1.571992 | cl_loss: 0.053459 | loss: 1.839285
2022-07-27 17:36:15.938 | INFO     | __main__:train:118 - Epoch:  0 | Chunk:  8 | step:  900 | mle_loss: 1.549391 | cl_loss: 0.052714 | loss: 1.812960
2022-07-27 17:36:33.948 | INFO     | __main__:train:118 - Epoch:  0 | Chunk:  8 | step:  950 | mle_loss: 1.520961 | cl_loss: 0.053218 | loss: 1.787049
2022-07-27 17:36:51.937 | INFO     | __main__:train:118 - Epoch:  0 | Chunk:  8 | step: 1000 | mle_loss: 1.537436 | cl_loss: 0.053646 | loss: 1.805667
2022-07-27 17:37:09.645 | INFO     | __main__:train:118 - Epoch:  0 | Chunk:  8 | step: 1050 | mle_loss: 1.548130 | cl_loss: 0.052766 | loss: 1.811958
2022-07-27 17:37:27.432 | INFO     | __main__:train:118 - Epoch:  0 | Chunk:  8 | step: 1100 | mle_loss: 1.550446 | cl_loss: 0.052546 | loss: 1.813178
2022-07-27 17:37:45.000 | INFO     | __main__:train:118 - Epoch:  0 | Chunk:  8 | step: 1150 | mle_loss: 1.548903 | cl_loss: 0.051214 | loss: 1.804976
2022-07-27 17:38:02.834 | INFO     | __main__:train:118 - Epoch:  0 | Chunk:  8 | step: 1200 | mle_loss: 1.548181 | cl_loss: 0.053615 | loss: 1.816258
2022-07-27 17:38:20.390 | INFO     | processing.dataset:_load_and_cache_examples:43 - Loading examples from cache file data/cache/train_set/train_9.pkl
2022-07-27 17:38:22.542 | INFO     | __main__:train:118 - Epoch:  0 | Chunk:  9 | step:    0 | mle_loss: 1.540440 | cl_loss: 0.053764 | loss: 1.809261
2022-07-27 17:38:40.242 | INFO     | __main__:train:118 - Epoch:  0 | Chunk:  9 | step:   50 | mle_loss: 1.555985 | cl_loss: 0.057417 | loss: 1.843070
2022-07-27 17:38:57.914 | INFO     | __main__:train:118 - Epoch:  0 | Chunk:  9 | step:  100 | mle_loss: 1.543246 | cl_loss: 0.055726 | loss: 1.821876
2022-07-27 17:39:15.750 | INFO     | __main__:train:118 - Epoch:  0 | Chunk:  9 | step:  150 | mle_loss: 1.514292 | cl_loss: 0.056226 | loss: 1.795425
2022-07-27 17:39:33.565 | INFO     | __main__:train:118 - Epoch:  0 | Chunk:  9 | step:  200 | mle_loss: 1.522424 | cl_loss: 0.055573 | loss: 1.800289
2022-07-27 17:39:51.362 | INFO     | __main__:train:118 - Epoch:  0 | Chunk:  9 | step:  250 | mle_loss: 1.534860 | cl_loss: 0.057592 | loss: 1.822822
2022-07-27 17:40:09.218 | INFO     | __main__:train:118 - Epoch:  0 | Chunk:  9 | step:  300 | mle_loss: 1.548705 | cl_loss: 0.057981 | loss: 1.838612
2022-07-27 17:40:27.136 | INFO     | __main__:train:118 - Epoch:  0 | Chunk:  9 | step:  350 | mle_loss: 1.517288 | cl_loss: 0.056058 | loss: 1.797580
2022-07-27 17:40:44.762 | INFO     | __main__:train:118 - Epoch:  0 | Chunk:  9 | step:  400 | mle_loss: 1.516731 | cl_loss: 0.055754 | loss: 1.795500
2022-07-27 17:41:02.515 | INFO     | __main__:train:118 - Epoch:  0 | Chunk:  9 | step:  450 | mle_loss: 1.532043 | cl_loss: 0.053637 | loss: 1.800226
2022-07-27 17:41:20.204 | INFO     | __main__:train:118 - Epoch:  0 | Chunk:  9 | step:  500 | mle_loss: 1.508752 | cl_loss: 0.055121 | loss: 1.784359
2022-07-27 17:41:38.063 | INFO     | __main__:train:118 - Epoch:  0 | Chunk:  9 | step:  550 | mle_loss: 1.471017 | cl_loss: 0.051662 | loss: 1.729327
2022-07-27 17:41:55.846 | INFO     | __main__:train:118 - Epoch:  0 | Chunk:  9 | step:  600 | mle_loss: 1.510783 | cl_loss: 0.053484 | loss: 1.778202
2022-07-27 17:42:13.404 | INFO     | __main__:train:118 - Epoch:  0 | Chunk:  9 | step:  650 | mle_loss: 1.502355 | cl_loss: 0.051451 | loss: 1.759610
2022-07-27 17:42:31.158 | INFO     | __main__:train:118 - Epoch:  0 | Chunk:  9 | step:  700 | mle_loss: 1.518772 | cl_loss: 0.053347 | loss: 1.785505
2022-07-27 17:42:48.601 | INFO     | __main__:evaluate:178 - Generating...
2022-07-27 17:44:09.487 | INFO     | __main__:evaluate:188 - Generation finished.
2022-07-27 17:44:09.487 | INFO     | __main__:evaluate:195 - Rouge scores: {'rouge-1': 0.3769, 'rouge-2': 0.2194, 'rouge-l': 0.3348}
2022-07-27 17:44:09.488 | INFO     | __main__:train:137 - Eval loss: 0.0, the best loss: {'loss': 0.0, 'epoch': 0, 'step': 749}
2022-07-27 17:44:09.488 | INFO     | __main__:train:138 - Rouge scores: {'rouge-1': 0.3769, 'rouge-2': 0.2194, 'rouge-l': 0.3348, 'epoch': 0, 'step': 749}, the best scores: {'rouge-1': 0.3769, 'rouge-2': 0.2194, 'rouge-l': 0.3348, 'epoch': 0, 'step': 749}
2022-07-27 17:44:09.488 | INFO     | __main__:train:143 - Saving model checkpoint to checkpoints/MoCoBart-0-9-749
2022-07-27 17:44:12.347 | INFO     | __main__:train:118 - Epoch:  0 | Chunk:  9 | step:  750 | mle_loss: 1.509376 | cl_loss: 0.052964 | loss: 1.774194
2022-07-27 17:44:29.836 | INFO     | __main__:train:118 - Epoch:  0 | Chunk:  9 | step:  800 | mle_loss: 1.544025 | cl_loss: 0.052856 | loss: 1.808306
2022-07-27 17:44:47.276 | INFO     | __main__:train:118 - Epoch:  0 | Chunk:  9 | step:  850 | mle_loss: 1.491370 | cl_loss: 0.051640 | loss: 1.749569
2022-07-27 17:45:04.900 | INFO     | __main__:train:118 - Epoch:  0 | Chunk:  9 | step:  900 | mle_loss: 1.496106 | cl_loss: 0.053875 | loss: 1.765479
2022-07-27 17:45:22.668 | INFO     | __main__:train:118 - Epoch:  0 | Chunk:  9 | step:  950 | mle_loss: 1.493549 | cl_loss: 0.053725 | loss: 1.762175
2022-07-27 17:45:40.326 | INFO     | __main__:train:118 - Epoch:  0 | Chunk:  9 | step: 1000 | mle_loss: 1.493812 | cl_loss: 0.051550 | loss: 1.751561
2022-07-27 17:45:57.983 | INFO     | __main__:train:118 - Epoch:  0 | Chunk:  9 | step: 1050 | mle_loss: 1.508929 | cl_loss: 0.053969 | loss: 1.778773
2022-07-27 17:46:15.767 | INFO     | __main__:train:118 - Epoch:  0 | Chunk:  9 | step: 1100 | mle_loss: 1.467006 | cl_loss: 0.049047 | loss: 1.712241
2022-07-27 17:46:33.536 | INFO     | __main__:train:118 - Epoch:  0 | Chunk:  9 | step: 1150 | mle_loss: 1.486302 | cl_loss: 0.050500 | loss: 1.738801
2022-07-27 17:46:51.221 | INFO     | __main__:train:118 - Epoch:  0 | Chunk:  9 | step: 1200 | mle_loss: 1.499949 | cl_loss: 0.051709 | loss: 1.758495
2022-07-27 17:47:08.745 | INFO     | processing.dataset:_load_and_cache_examples:43 - Loading examples from cache file data/cache/train_set/train_10.pkl
2022-07-27 17:47:10.987 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 10 | step:    0 | mle_loss: 1.489973 | cl_loss: 0.049719 | loss: 1.738567
2022-07-27 17:47:28.755 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 10 | step:   50 | mle_loss: 1.473478 | cl_loss: 0.058500 | loss: 1.765976
2022-07-27 17:47:46.383 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 10 | step:  100 | mle_loss: 1.470076 | cl_loss: 0.055804 | loss: 1.749098
2022-07-27 17:48:03.984 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 10 | step:  150 | mle_loss: 1.458955 | cl_loss: 0.057625 | loss: 1.747079
2022-07-27 17:48:21.429 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 10 | step:  200 | mle_loss: 1.492177 | cl_loss: 0.057060 | loss: 1.777479
2022-07-27 17:48:39.447 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 10 | step:  250 | mle_loss: 1.414902 | cl_loss: 0.059435 | loss: 1.712076
2022-07-27 17:48:57.487 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 10 | step:  300 | mle_loss: 1.443360 | cl_loss: 0.056190 | loss: 1.724309
2022-07-27 17:49:15.314 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 10 | step:  350 | mle_loss: 1.450761 | cl_loss: 0.055338 | loss: 1.727449
2022-07-27 17:49:32.941 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 10 | step:  400 | mle_loss: 1.445803 | cl_loss: 0.055729 | loss: 1.724450
2022-07-27 17:49:50.711 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 10 | step:  450 | mle_loss: 1.434278 | cl_loss: 0.056804 | loss: 1.718299
2022-07-27 17:50:08.451 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 10 | step:  500 | mle_loss: 1.435607 | cl_loss: 0.057461 | loss: 1.722911
2022-07-27 17:50:26.218 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 10 | step:  550 | mle_loss: 1.439596 | cl_loss: 0.058878 | loss: 1.733986
2022-07-27 17:50:44.119 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 10 | step:  600 | mle_loss: 1.421264 | cl_loss: 0.055597 | loss: 1.699247
2022-07-27 17:51:01.687 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 10 | step:  650 | mle_loss: 1.438551 | cl_loss: 0.056635 | loss: 1.721725
2022-07-27 17:51:19.460 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 10 | step:  700 | mle_loss: 1.455181 | cl_loss: 0.055354 | loss: 1.731952
2022-07-27 17:51:37.472 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 10 | step:  750 | mle_loss: 1.432465 | cl_loss: 0.056462 | loss: 1.714775
2022-07-27 17:51:55.574 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 10 | step:  800 | mle_loss: 1.433673 | cl_loss: 0.051616 | loss: 1.691755
2022-07-27 17:52:13.472 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 10 | step:  850 | mle_loss: 1.413782 | cl_loss: 0.058535 | loss: 1.706455
2022-07-27 17:52:31.163 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 10 | step:  900 | mle_loss: 1.457965 | cl_loss: 0.051990 | loss: 1.717915
2022-07-27 17:52:48.852 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 10 | step:  950 | mle_loss: 1.443529 | cl_loss: 0.055572 | loss: 1.721387
2022-07-27 17:53:06.827 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 10 | step: 1000 | mle_loss: 1.418785 | cl_loss: 0.052917 | loss: 1.683370
2022-07-27 17:53:24.334 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 10 | step: 1050 | mle_loss: 1.449557 | cl_loss: 0.055967 | loss: 1.729392
2022-07-27 17:53:42.105 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 10 | step: 1100 | mle_loss: 1.445599 | cl_loss: 0.053676 | loss: 1.713978
2022-07-27 17:53:59.852 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 10 | step: 1150 | mle_loss: 1.438920 | cl_loss: 0.054736 | loss: 1.712599
2022-07-27 17:54:17.681 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 10 | step: 1200 | mle_loss: 1.399598 | cl_loss: 0.055878 | loss: 1.678987
2022-07-27 17:54:34.979 | INFO     | processing.dataset:_load_and_cache_examples:43 - Loading examples from cache file data/cache/train_set/train_11.pkl
2022-07-27 17:54:37.068 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 11 | step:    0 | mle_loss: 1.440223 | cl_loss: 0.053856 | loss: 1.709501
2022-07-27 17:54:54.809 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 11 | step:   50 | mle_loss: 1.458530 | cl_loss: 0.051111 | loss: 1.714086
2022-07-27 17:55:12.533 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 11 | step:  100 | mle_loss: 1.479764 | cl_loss: 0.051579 | loss: 1.737660
2022-07-27 17:55:30.642 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 11 | step:  150 | mle_loss: 1.418497 | cl_loss: 0.051665 | loss: 1.676823
2022-07-27 17:55:48.634 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 11 | step:  200 | mle_loss: 1.420334 | cl_loss: 0.049203 | loss: 1.666348
2022-07-27 17:56:06.589 | INFO     | __main__:evaluate:178 - Generating...
2022-07-27 17:57:25.002 | INFO     | __main__:evaluate:188 - Generation finished.
2022-07-27 17:57:25.003 | INFO     | __main__:evaluate:195 - Rouge scores: {'rouge-1': 0.3815, 'rouge-2': 0.2255, 'rouge-l': 0.339}
2022-07-27 17:57:25.003 | INFO     | __main__:train:137 - Eval loss: 0.0, the best loss: {'loss': 0.0, 'epoch': 0, 'step': 749}
2022-07-27 17:57:25.003 | INFO     | __main__:train:138 - Rouge scores: {'rouge-1': 0.3815, 'rouge-2': 0.2255, 'rouge-l': 0.339, 'epoch': 0, 'step': 249}, the best scores: {'rouge-1': 0.3815, 'rouge-2': 0.2255, 'rouge-l': 0.339, 'epoch': 0, 'step': 249}
2022-07-27 17:57:25.003 | INFO     | __main__:train:143 - Saving model checkpoint to checkpoints/MoCoBart-0-11-249
2022-07-27 17:57:27.075 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 11 | step:  250 | mle_loss: 1.385236 | cl_loss: 0.050648 | loss: 1.638478
2022-07-27 17:57:45.050 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 11 | step:  300 | mle_loss: 1.418945 | cl_loss: 0.051229 | loss: 1.675092
2022-07-27 17:58:02.889 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 11 | step:  350 | mle_loss: 1.434080 | cl_loss: 0.049580 | loss: 1.681981
2022-07-27 17:58:20.520 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 11 | step:  400 | mle_loss: 1.435041 | cl_loss: 0.050275 | loss: 1.686417
2022-07-27 17:58:38.515 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 11 | step:  450 | mle_loss: 1.426731 | cl_loss: 0.050801 | loss: 1.680737
2022-07-27 17:58:56.135 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 11 | step:  500 | mle_loss: 1.432268 | cl_loss: 0.049417 | loss: 1.679352
2022-07-27 17:59:13.779 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 11 | step:  550 | mle_loss: 1.464021 | cl_loss: 0.049433 | loss: 1.711189
2022-07-27 17:59:31.686 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 11 | step:  600 | mle_loss: 1.427866 | cl_loss: 0.051625 | loss: 1.685991
2022-07-27 17:59:49.461 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 11 | step:  650 | mle_loss: 1.396910 | cl_loss: 0.048665 | loss: 1.640233
2022-07-27 18:00:07.433 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 11 | step:  700 | mle_loss: 1.429320 | cl_loss: 0.049058 | loss: 1.674612
2022-07-27 18:00:25.543 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 11 | step:  750 | mle_loss: 1.401127 | cl_loss: 0.047571 | loss: 1.638981
2022-07-27 18:00:43.393 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 11 | step:  800 | mle_loss: 1.403966 | cl_loss: 0.047661 | loss: 1.642272
2022-07-27 18:01:01.294 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 11 | step:  850 | mle_loss: 1.418680 | cl_loss: 0.050551 | loss: 1.671438
2022-07-27 18:01:19.261 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 11 | step:  900 | mle_loss: 1.415416 | cl_loss: 0.051325 | loss: 1.672039
2022-07-27 18:01:37.135 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 11 | step:  950 | mle_loss: 1.420521 | cl_loss: 0.045017 | loss: 1.645608
2022-07-27 18:01:54.948 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 11 | step: 1000 | mle_loss: 1.394408 | cl_loss: 0.045470 | loss: 1.621757
2022-07-27 18:02:13.296 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 11 | step: 1050 | mle_loss: 1.392414 | cl_loss: 0.049993 | loss: 1.642381
2022-07-27 18:02:31.442 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 11 | step: 1100 | mle_loss: 1.417027 | cl_loss: 0.046708 | loss: 1.650566
2022-07-27 18:02:48.982 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 11 | step: 1150 | mle_loss: 1.410537 | cl_loss: 0.047809 | loss: 1.649580
2022-07-27 18:03:07.014 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 11 | step: 1200 | mle_loss: 1.385757 | cl_loss: 0.047693 | loss: 1.624221
2022-07-27 18:03:24.588 | INFO     | processing.dataset:_load_and_cache_examples:43 - Loading examples from cache file data/cache/train_set/train_12.pkl
2022-07-27 18:03:26.270 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 12 | step:    0 | mle_loss: 1.393047 | cl_loss: 0.046573 | loss: 1.625910
2022-07-27 18:03:43.781 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 12 | step:   50 | mle_loss: 1.489314 | cl_loss: 0.056595 | loss: 1.772287
2022-07-27 18:04:01.575 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 12 | step:  100 | mle_loss: 1.505809 | cl_loss: 0.059187 | loss: 1.801743
2022-07-27 18:04:19.501 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 12 | step:  150 | mle_loss: 1.473861 | cl_loss: 0.059028 | loss: 1.769002
2022-07-27 18:04:37.179 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 12 | step:  200 | mle_loss: 1.455842 | cl_loss: 0.057347 | loss: 1.742578
2022-07-27 18:04:55.149 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 12 | step:  250 | mle_loss: 1.425131 | cl_loss: 0.057261 | loss: 1.711438
2022-07-27 18:05:13.084 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 12 | step:  300 | mle_loss: 1.444717 | cl_loss: 0.054123 | loss: 1.715330
2022-07-27 18:05:30.888 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 12 | step:  350 | mle_loss: 1.454873 | cl_loss: 0.055269 | loss: 1.731218
2022-07-27 18:05:48.847 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 12 | step:  400 | mle_loss: 1.418254 | cl_loss: 0.053873 | loss: 1.687620
2022-07-27 18:06:06.138 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 12 | step:  450 | mle_loss: 1.453740 | cl_loss: 0.051276 | loss: 1.710120
2022-07-27 18:06:23.498 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 12 | step:  500 | mle_loss: 1.442539 | cl_loss: 0.053764 | loss: 1.711359
2022-07-27 18:06:40.594 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 12 | step:  550 | mle_loss: 1.452324 | cl_loss: 0.052371 | loss: 1.714181
2022-07-27 18:06:57.988 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 12 | step:  600 | mle_loss: 1.437163 | cl_loss: 0.054039 | loss: 1.707358
2022-07-27 18:07:15.281 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 12 | step:  650 | mle_loss: 1.440030 | cl_loss: 0.051309 | loss: 1.696576
2022-07-27 18:07:32.865 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 12 | step:  700 | mle_loss: 1.432326 | cl_loss: 0.054109 | loss: 1.702873
2022-07-27 18:07:50.629 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 12 | step:  750 | mle_loss: 1.471625 | cl_loss: 0.051630 | loss: 1.729776
2022-07-27 18:08:08.433 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 12 | step:  800 | mle_loss: 1.391351 | cl_loss: 0.050912 | loss: 1.645912
2022-07-27 18:08:26.153 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 12 | step:  850 | mle_loss: 1.396152 | cl_loss: 0.052304 | loss: 1.657674
2022-07-27 18:08:43.687 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 12 | step:  900 | mle_loss: 1.408523 | cl_loss: 0.056342 | loss: 1.690231
2022-07-27 18:09:01.277 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 12 | step:  950 | mle_loss: 1.434394 | cl_loss: 0.055397 | loss: 1.711379
2022-07-27 18:09:18.520 | INFO     | __main__:evaluate:178 - Generating...
2022-07-27 18:10:38.509 | INFO     | __main__:evaluate:188 - Generation finished.
2022-07-27 18:10:38.510 | INFO     | __main__:evaluate:195 - Rouge scores: {'rouge-1': 0.3868, 'rouge-2': 0.2285, 'rouge-l': 0.3426}
2022-07-27 18:10:38.510 | INFO     | __main__:train:137 - Eval loss: 0.0, the best loss: {'loss': 0.0, 'epoch': 0, 'step': 749}
2022-07-27 18:10:38.510 | INFO     | __main__:train:138 - Rouge scores: {'rouge-1': 0.3868, 'rouge-2': 0.2285, 'rouge-l': 0.3426, 'epoch': 0, 'step': 999}, the best scores: {'rouge-1': 0.3868, 'rouge-2': 0.2285, 'rouge-l': 0.3426, 'epoch': 0, 'step': 999}
2022-07-27 18:10:38.510 | INFO     | __main__:train:143 - Saving model checkpoint to checkpoints/MoCoBart-0-12-999
2022-07-27 18:10:40.881 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 12 | step: 1000 | mle_loss: 1.419794 | cl_loss: 0.050088 | loss: 1.670235
2022-07-27 18:10:58.354 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 12 | step: 1050 | mle_loss: 1.420391 | cl_loss: 0.050021 | loss: 1.670497
2022-07-27 18:11:15.769 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 12 | step: 1100 | mle_loss: 1.423945 | cl_loss: 0.052532 | loss: 1.686606
2022-07-27 18:11:33.473 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 12 | step: 1150 | mle_loss: 1.418859 | cl_loss: 0.052712 | loss: 1.682417
2022-07-27 18:11:50.991 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 12 | step: 1200 | mle_loss: 1.421029 | cl_loss: 0.053572 | loss: 1.688890
2022-07-27 18:12:08.625 | INFO     | processing.dataset:_load_and_cache_examples:43 - Loading examples from cache file data/cache/train_set/train_13.pkl
2022-07-27 18:12:10.472 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 13 | step:    0 | mle_loss: 1.411087 | cl_loss: 0.049591 | loss: 1.659043
2022-07-27 18:12:28.498 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 13 | step:   50 | mle_loss: 1.523972 | cl_loss: 0.062551 | loss: 1.836728
2022-07-27 18:12:46.600 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 13 | step:  100 | mle_loss: 1.486789 | cl_loss: 0.063369 | loss: 1.803634
2022-07-27 18:13:04.667 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 13 | step:  150 | mle_loss: 1.502053 | cl_loss: 0.061711 | loss: 1.810608
2022-07-27 18:13:22.520 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 13 | step:  200 | mle_loss: 1.510628 | cl_loss: 0.062121 | loss: 1.821234
2022-07-27 18:13:40.537 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 13 | step:  250 | mle_loss: 1.494863 | cl_loss: 0.053465 | loss: 1.762186
2022-07-27 18:13:58.752 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 13 | step:  300 | mle_loss: 1.458268 | cl_loss: 0.056994 | loss: 1.743235
2022-07-27 18:14:16.587 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 13 | step:  350 | mle_loss: 1.503657 | cl_loss: 0.060118 | loss: 1.804246
2022-07-27 18:14:34.410 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 13 | step:  400 | mle_loss: 1.484453 | cl_loss: 0.057297 | loss: 1.770935
2022-07-27 18:14:52.682 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 13 | step:  450 | mle_loss: 1.432222 | cl_loss: 0.062082 | loss: 1.742630
2022-07-27 18:15:10.752 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 13 | step:  500 | mle_loss: 1.475689 | cl_loss: 0.057571 | loss: 1.763543
2022-07-27 18:15:28.737 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 13 | step:  550 | mle_loss: 1.440875 | cl_loss: 0.055179 | loss: 1.716770
2022-07-27 18:15:46.836 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 13 | step:  600 | mle_loss: 1.456140 | cl_loss: 0.056372 | loss: 1.738000
2022-07-27 18:16:04.752 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 13 | step:  650 | mle_loss: 1.454638 | cl_loss: 0.054305 | loss: 1.726165
2022-07-27 18:16:22.732 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 13 | step:  700 | mle_loss: 1.460347 | cl_loss: 0.052755 | loss: 1.724121
2022-07-27 18:16:41.021 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 13 | step:  750 | mle_loss: 1.438134 | cl_loss: 0.060257 | loss: 1.739419
2022-07-27 18:16:59.158 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 13 | step:  800 | mle_loss: 1.436472 | cl_loss: 0.055541 | loss: 1.714176
2022-07-27 18:17:17.556 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 13 | step:  850 | mle_loss: 1.454723 | cl_loss: 0.056178 | loss: 1.735614
2022-07-27 18:17:35.861 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 13 | step:  900 | mle_loss: 1.435138 | cl_loss: 0.052922 | loss: 1.699746
2022-07-27 18:17:53.955 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 13 | step:  950 | mle_loss: 1.415119 | cl_loss: 0.051966 | loss: 1.674949
2022-07-27 18:18:12.076 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 13 | step: 1000 | mle_loss: 1.428352 | cl_loss: 0.056800 | loss: 1.712353
2022-07-27 18:18:30.165 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 13 | step: 1050 | mle_loss: 1.450558 | cl_loss: 0.055514 | loss: 1.728130
2022-07-27 18:18:48.143 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 13 | step: 1100 | mle_loss: 1.439632 | cl_loss: 0.051766 | loss: 1.698463
2022-07-27 18:19:06.334 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 13 | step: 1150 | mle_loss: 1.436141 | cl_loss: 0.051576 | loss: 1.694021
2022-07-27 18:19:24.357 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 13 | step: 1200 | mle_loss: 1.422530 | cl_loss: 0.051199 | loss: 1.678525
2022-07-27 18:19:41.767 | INFO     | processing.dataset:_load_and_cache_examples:43 - Loading examples from cache file data/cache/train_set/train_14.pkl
2022-07-27 18:19:43.672 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 14 | step:    0 | mle_loss: 1.457046 | cl_loss: 0.052167 | loss: 1.717880
2022-07-27 18:20:01.307 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 14 | step:   50 | mle_loss: 1.476090 | cl_loss: 0.042821 | loss: 1.690198
2022-07-27 18:20:19.168 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 14 | step:  100 | mle_loss: 1.475643 | cl_loss: 0.044294 | loss: 1.697111
2022-07-27 18:20:37.126 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 14 | step:  150 | mle_loss: 1.454046 | cl_loss: 0.042792 | loss: 1.668006
2022-07-27 18:20:54.960 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 14 | step:  200 | mle_loss: 1.496351 | cl_loss: 0.042772 | loss: 1.710212
2022-07-27 18:21:12.742 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 14 | step:  250 | mle_loss: 1.439143 | cl_loss: 0.042329 | loss: 1.650786
2022-07-27 18:21:30.699 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 14 | step:  300 | mle_loss: 1.466527 | cl_loss: 0.042562 | loss: 1.679339
2022-07-27 18:21:48.588 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 14 | step:  350 | mle_loss: 1.460556 | cl_loss: 0.041925 | loss: 1.670178
2022-07-27 18:22:06.270 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 14 | step:  400 | mle_loss: 1.458190 | cl_loss: 0.044410 | loss: 1.680239
2022-07-27 18:22:24.322 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 14 | step:  450 | mle_loss: 1.452776 | cl_loss: 0.042747 | loss: 1.666513
2022-07-27 18:22:41.852 | INFO     | __main__:evaluate:178 - Generating...
2022-07-27 18:24:04.774 | INFO     | __main__:evaluate:188 - Generation finished.
2022-07-27 18:24:04.774 | INFO     | __main__:evaluate:195 - Rouge scores: {'rouge-1': 0.3991, 'rouge-2': 0.2428, 'rouge-l': 0.3527}
2022-07-27 18:24:04.774 | INFO     | __main__:train:137 - Eval loss: 0.0, the best loss: {'loss': 0.0, 'epoch': 0, 'step': 749}
2022-07-27 18:24:04.774 | INFO     | __main__:train:138 - Rouge scores: {'rouge-1': 0.3991, 'rouge-2': 0.2428, 'rouge-l': 0.3527, 'epoch': 0, 'step': 499}, the best scores: {'rouge-1': 0.3991, 'rouge-2': 0.2428, 'rouge-l': 0.3527, 'epoch': 0, 'step': 499}
2022-07-27 18:24:04.775 | INFO     | __main__:train:143 - Saving model checkpoint to checkpoints/MoCoBart-0-14-499
2022-07-27 18:24:07.236 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 14 | step:  500 | mle_loss: 1.448738 | cl_loss: 0.044949 | loss: 1.673483
2022-07-27 18:24:24.779 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 14 | step:  550 | mle_loss: 1.428687 | cl_loss: 0.042142 | loss: 1.639399
2022-07-27 18:24:42.621 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 14 | step:  600 | mle_loss: 1.456011 | cl_loss: 0.043789 | loss: 1.674958
2022-07-27 18:25:00.412 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 14 | step:  650 | mle_loss: 1.459396 | cl_loss: 0.042734 | loss: 1.673066
2022-07-27 18:25:18.271 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 14 | step:  700 | mle_loss: 1.445495 | cl_loss: 0.044775 | loss: 1.669368
2022-07-27 18:25:36.176 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 14 | step:  750 | mle_loss: 1.427396 | cl_loss: 0.042784 | loss: 1.641317
2022-07-27 18:25:54.166 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 14 | step:  800 | mle_loss: 1.444026 | cl_loss: 0.043553 | loss: 1.661789
2022-07-27 18:26:12.074 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 14 | step:  850 | mle_loss: 1.438255 | cl_loss: 0.044490 | loss: 1.660707
2022-07-27 18:26:29.982 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 14 | step:  900 | mle_loss: 1.428141 | cl_loss: 0.043189 | loss: 1.644088
2022-07-27 18:26:47.740 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 14 | step:  950 | mle_loss: 1.431865 | cl_loss: 0.044494 | loss: 1.654336
2022-07-27 18:27:05.739 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 14 | step: 1000 | mle_loss: 1.431818 | cl_loss: 0.042622 | loss: 1.644928
2022-07-27 18:27:23.422 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 14 | step: 1050 | mle_loss: 1.427320 | cl_loss: 0.042113 | loss: 1.637884
2022-07-27 18:27:41.302 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 14 | step: 1100 | mle_loss: 1.418892 | cl_loss: 0.044054 | loss: 1.639161
2022-07-27 18:27:59.345 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 14 | step: 1150 | mle_loss: 1.389870 | cl_loss: 0.045028 | loss: 1.615011
2022-07-27 18:28:17.200 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 14 | step: 1200 | mle_loss: 1.431908 | cl_loss: 0.043772 | loss: 1.650768
2022-07-27 18:28:34.936 | INFO     | processing.dataset:_load_and_cache_examples:43 - Loading examples from cache file data/cache/train_set/train_15.pkl
2022-07-27 18:28:37.441 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 15 | step:    0 | mle_loss: 1.415085 | cl_loss: 0.044089 | loss: 1.635528
2022-07-27 18:28:55.036 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 15 | step:   50 | mle_loss: 1.403742 | cl_loss: 0.043848 | loss: 1.622982
2022-07-27 18:29:12.861 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 15 | step:  100 | mle_loss: 1.372074 | cl_loss: 0.044060 | loss: 1.592373
2022-07-27 18:29:30.808 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 15 | step:  150 | mle_loss: 1.372249 | cl_loss: 0.046424 | loss: 1.604368
2022-07-27 18:29:48.468 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 15 | step:  200 | mle_loss: 1.374232 | cl_loss: 0.045655 | loss: 1.602505
2022-07-27 18:30:06.339 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 15 | step:  250 | mle_loss: 1.353394 | cl_loss: 0.044015 | loss: 1.573469
2022-07-27 18:30:24.182 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 15 | step:  300 | mle_loss: 1.383811 | cl_loss: 0.045837 | loss: 1.612995
2022-07-27 18:30:42.125 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 15 | step:  350 | mle_loss: 1.380441 | cl_loss: 0.042671 | loss: 1.593798
2022-07-27 18:30:59.924 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 15 | step:  400 | mle_loss: 1.361920 | cl_loss: 0.041410 | loss: 1.568972
2022-07-27 18:31:17.638 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 15 | step:  450 | mle_loss: 1.371261 | cl_loss: 0.041981 | loss: 1.581164
2022-07-27 18:31:35.647 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 15 | step:  500 | mle_loss: 1.357638 | cl_loss: 0.044614 | loss: 1.580707
2022-07-27 18:31:53.625 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 15 | step:  550 | mle_loss: 1.362833 | cl_loss: 0.042897 | loss: 1.577317
2022-07-27 18:32:11.351 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 15 | step:  600 | mle_loss: 1.376795 | cl_loss: 0.042927 | loss: 1.591431
2022-07-27 18:32:29.265 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 15 | step:  650 | mle_loss: 1.344525 | cl_loss: 0.043658 | loss: 1.562815
2022-07-27 18:32:47.030 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 15 | step:  700 | mle_loss: 1.326883 | cl_loss: 0.041578 | loss: 1.534771
2022-07-27 18:33:04.804 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 15 | step:  750 | mle_loss: 1.379197 | cl_loss: 0.040461 | loss: 1.581500
2022-07-27 18:33:22.789 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 15 | step:  800 | mle_loss: 1.340891 | cl_loss: 0.039567 | loss: 1.538726
2022-07-27 18:33:40.747 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 15 | step:  850 | mle_loss: 1.336568 | cl_loss: 0.042926 | loss: 1.551198
2022-07-27 18:33:58.571 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 15 | step:  900 | mle_loss: 1.335136 | cl_loss: 0.043522 | loss: 1.552748
2022-07-27 18:34:16.498 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 15 | step:  950 | mle_loss: 1.334594 | cl_loss: 0.042822 | loss: 1.548706
2022-07-27 18:34:34.440 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 15 | step: 1000 | mle_loss: 1.342272 | cl_loss: 0.039794 | loss: 1.541244
2022-07-27 18:34:52.301 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 15 | step: 1050 | mle_loss: 1.357287 | cl_loss: 0.042155 | loss: 1.568063
2022-07-27 18:35:10.319 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 15 | step: 1100 | mle_loss: 1.348290 | cl_loss: 0.041070 | loss: 1.553640
2022-07-27 18:35:28.070 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 15 | step: 1150 | mle_loss: 1.351823 | cl_loss: 0.041295 | loss: 1.558297
2022-07-27 18:35:45.874 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 15 | step: 1200 | mle_loss: 1.373215 | cl_loss: 0.042497 | loss: 1.585701
2022-07-27 18:36:03.226 | INFO     | __main__:evaluate:178 - Generating...
2022-07-27 18:37:26.091 | INFO     | __main__:evaluate:188 - Generation finished.
2022-07-27 18:37:26.092 | INFO     | __main__:evaluate:195 - Rouge scores: {'rouge-1': 0.3938, 'rouge-2': 0.2348, 'rouge-l': 0.3504}
2022-07-27 18:37:26.092 | INFO     | __main__:train:137 - Eval loss: 0.0, the best loss: {'loss': 0.0, 'epoch': 0, 'step': 749}
2022-07-27 18:37:26.092 | INFO     | __main__:train:138 - Rouge scores: {'rouge-1': 0.3938, 'rouge-2': 0.2348, 'rouge-l': 0.3504}, the best scores: {'rouge-1': 0.3991, 'rouge-2': 0.2428, 'rouge-l': 0.3527, 'epoch': 0, 'step': 499}
2022-07-27 18:37:26.093 | INFO     | __main__:train:143 - Saving model checkpoint to checkpoints/MoCoBart-0-15-1249
2022-07-27 18:37:28.013 | INFO     | processing.dataset:_load_and_cache_examples:43 - Loading examples from cache file data/cache/train_set/train_16.pkl
2022-07-27 18:37:29.907 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 16 | step:    0 | mle_loss: 1.336506 | cl_loss: 0.041169 | loss: 1.542353
2022-07-27 18:37:47.739 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 16 | step:   50 | mle_loss: 1.441637 | cl_loss: 0.040781 | loss: 1.645544
2022-07-27 18:38:05.392 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 16 | step:  100 | mle_loss: 1.428763 | cl_loss: 0.042490 | loss: 1.641211
2022-07-27 18:38:24.769 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 16 | step:  150 | mle_loss: 1.410447 | cl_loss: 0.044611 | loss: 1.633501
2022-07-27 18:38:42.489 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 16 | step:  200 | mle_loss: 1.433991 | cl_loss: 0.044572 | loss: 1.656850
2022-07-27 18:39:00.315 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 16 | step:  250 | mle_loss: 1.424682 | cl_loss: 0.043194 | loss: 1.640654
2022-07-27 18:39:18.084 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 16 | step:  300 | mle_loss: 1.405187 | cl_loss: 0.042323 | loss: 1.616802
2022-07-27 18:39:35.906 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 16 | step:  350 | mle_loss: 1.436804 | cl_loss: 0.044216 | loss: 1.657883
2022-07-27 18:39:53.568 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 16 | step:  400 | mle_loss: 1.444723 | cl_loss: 0.042974 | loss: 1.659594
2022-07-27 18:40:11.451 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 16 | step:  450 | mle_loss: 1.408345 | cl_loss: 0.043267 | loss: 1.624678
2022-07-27 18:40:29.361 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 16 | step:  500 | mle_loss: 1.410520 | cl_loss: 0.042736 | loss: 1.624200
2022-07-27 18:40:47.281 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 16 | step:  550 | mle_loss: 1.385969 | cl_loss: 0.040429 | loss: 1.588114
2022-07-27 18:41:05.275 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 16 | step:  600 | mle_loss: 1.374546 | cl_loss: 0.042430 | loss: 1.586695
2022-07-27 18:41:23.356 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 16 | step:  650 | mle_loss: 1.395664 | cl_loss: 0.040159 | loss: 1.596460
2022-07-27 18:41:41.253 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 16 | step:  700 | mle_loss: 1.400469 | cl_loss: 0.040260 | loss: 1.601768
2022-07-27 18:42:00.488 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 16 | step:  750 | mle_loss: 1.413244 | cl_loss: 0.043066 | loss: 1.628574
2022-07-27 18:42:18.065 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 16 | step:  800 | mle_loss: 1.430036 | cl_loss: 0.042753 | loss: 1.643798
2022-07-27 18:42:35.749 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 16 | step:  850 | mle_loss: 1.431773 | cl_loss: 0.042466 | loss: 1.644104
2022-07-27 18:42:54.615 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 16 | step:  900 | mle_loss: 1.388592 | cl_loss: 0.040776 | loss: 1.592473
2022-07-27 18:43:11.948 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 16 | step:  950 | mle_loss: 1.397477 | cl_loss: 0.041438 | loss: 1.604669
2022-07-27 18:43:30.627 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 16 | step: 1000 | mle_loss: 1.390369 | cl_loss: 0.040943 | loss: 1.595082
2022-07-27 18:43:49.004 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 16 | step: 1050 | mle_loss: 1.401214 | cl_loss: 0.040961 | loss: 1.606018
2022-07-27 18:44:07.240 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 16 | step: 1100 | mle_loss: 1.407853 | cl_loss: 0.042250 | loss: 1.619105
2022-07-27 18:44:25.459 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 16 | step: 1150 | mle_loss: 1.377447 | cl_loss: 0.042908 | loss: 1.591989
2022-07-27 18:44:44.170 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 16 | step: 1200 | mle_loss: 1.408547 | cl_loss: 0.042242 | loss: 1.619755
2022-07-27 18:45:02.609 | INFO     | processing.dataset:_load_and_cache_examples:43 - Loading examples from cache file data/cache/train_set/train_17.pkl
2022-07-27 18:45:03.997 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 17 | step:    0 | mle_loss: 1.395000 | cl_loss: 0.041646 | loss: 1.603230
2022-07-27 18:45:22.844 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 17 | step:   50 | mle_loss: 1.476902 | cl_loss: 0.045698 | loss: 1.705393
2022-07-27 18:45:41.284 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 17 | step:  100 | mle_loss: 1.461064 | cl_loss: 0.044103 | loss: 1.681581
2022-07-27 18:45:59.648 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 17 | step:  150 | mle_loss: 1.444234 | cl_loss: 0.042124 | loss: 1.654855
2022-07-27 18:46:17.872 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 17 | step:  200 | mle_loss: 1.440833 | cl_loss: 0.048356 | loss: 1.682611
2022-07-27 18:46:36.196 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 17 | step:  250 | mle_loss: 1.422050 | cl_loss: 0.043835 | loss: 1.641227
2022-07-27 18:46:54.717 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 17 | step:  300 | mle_loss: 1.431094 | cl_loss: 0.047074 | loss: 1.666462
2022-07-27 18:47:12.994 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 17 | step:  350 | mle_loss: 1.433650 | cl_loss: 0.045060 | loss: 1.658949
2022-07-27 18:47:31.423 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 17 | step:  400 | mle_loss: 1.460156 | cl_loss: 0.046158 | loss: 1.690947
2022-07-27 18:47:49.217 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 17 | step:  450 | mle_loss: 1.405871 | cl_loss: 0.043172 | loss: 1.621733
2022-07-27 18:48:07.078 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 17 | step:  500 | mle_loss: 1.434259 | cl_loss: 0.042283 | loss: 1.645673
2022-07-27 18:48:24.879 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 17 | step:  550 | mle_loss: 1.396538 | cl_loss: 0.044318 | loss: 1.618131
2022-07-27 18:48:42.944 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 17 | step:  600 | mle_loss: 1.411891 | cl_loss: 0.047267 | loss: 1.648226
2022-07-27 18:49:00.805 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 17 | step:  650 | mle_loss: 1.433120 | cl_loss: 0.042233 | loss: 1.644285
2022-07-27 18:49:19.664 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 17 | step:  700 | mle_loss: 1.431482 | cl_loss: 0.045264 | loss: 1.657802
2022-07-27 18:49:37.376 | INFO     | __main__:evaluate:178 - Generating...
2022-07-27 18:51:02.360 | INFO     | __main__:evaluate:188 - Generation finished.
2022-07-27 18:51:02.361 | INFO     | __main__:evaluate:195 - Rouge scores: {'rouge-1': 0.3964, 'rouge-2': 0.2329, 'rouge-l': 0.3513}
2022-07-27 18:51:02.361 | INFO     | __main__:train:137 - Eval loss: 0.0, the best loss: {'loss': 0.0, 'epoch': 0, 'step': 749}
2022-07-27 18:51:02.361 | INFO     | __main__:train:138 - Rouge scores: {'rouge-1': 0.3964, 'rouge-2': 0.2329, 'rouge-l': 0.3513}, the best scores: {'rouge-1': 0.3991, 'rouge-2': 0.2428, 'rouge-l': 0.3527, 'epoch': 0, 'step': 499}
2022-07-27 18:51:02.361 | INFO     | __main__:train:143 - Saving model checkpoint to checkpoints/MoCoBart-0-17-749
2022-07-27 18:51:05.382 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 17 | step:  750 | mle_loss: 1.456793 | cl_loss: 0.043545 | loss: 1.674519
2022-07-27 18:51:23.408 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 17 | step:  800 | mle_loss: 1.406743 | cl_loss: 0.042904 | loss: 1.621263
2022-07-27 18:51:41.614 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 17 | step:  850 | mle_loss: 1.384331 | cl_loss: 0.044581 | loss: 1.607234
2022-07-27 18:51:59.456 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 17 | step:  900 | mle_loss: 1.430650 | cl_loss: 0.043691 | loss: 1.649104
2022-07-27 18:52:17.250 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 17 | step:  950 | mle_loss: 1.416529 | cl_loss: 0.039310 | loss: 1.613077
2022-07-27 18:52:35.280 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 17 | step: 1000 | mle_loss: 1.387714 | cl_loss: 0.041212 | loss: 1.593772
2022-07-27 18:52:53.015 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 17 | step: 1050 | mle_loss: 1.410149 | cl_loss: 0.040144 | loss: 1.610869
2022-07-27 18:53:10.871 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 17 | step: 1100 | mle_loss: 1.396083 | cl_loss: 0.041144 | loss: 1.601800
2022-07-27 18:53:29.014 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 17 | step: 1150 | mle_loss: 1.398689 | cl_loss: 0.042013 | loss: 1.608756
2022-07-27 18:53:47.016 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 17 | step: 1200 | mle_loss: 1.398641 | cl_loss: 0.043815 | loss: 1.617715
2022-07-27 18:54:04.676 | INFO     | processing.dataset:_load_and_cache_examples:43 - Loading examples from cache file data/cache/train_set/train_18.pkl
2022-07-27 18:54:06.611 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 18 | step:    0 | mle_loss: 1.390767 | cl_loss: 0.040956 | loss: 1.595548
2022-07-27 18:54:25.298 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 18 | step:   50 | mle_loss: 1.429557 | cl_loss: 0.038681 | loss: 1.622960
2022-07-27 18:54:43.537 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 18 | step:  100 | mle_loss: 1.398585 | cl_loss: 0.038241 | loss: 1.589792
2022-07-27 18:55:01.695 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 18 | step:  150 | mle_loss: 1.412450 | cl_loss: 0.039761 | loss: 1.611256
2022-07-27 18:55:19.631 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 18 | step:  200 | mle_loss: 1.428582 | cl_loss: 0.040624 | loss: 1.631700
2022-07-27 18:55:37.712 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 18 | step:  250 | mle_loss: 1.434808 | cl_loss: 0.040234 | loss: 1.635975
2022-07-27 18:55:55.557 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 18 | step:  300 | mle_loss: 1.394432 | cl_loss: 0.039580 | loss: 1.592334
2022-07-27 18:56:13.605 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 18 | step:  350 | mle_loss: 1.388730 | cl_loss: 0.039431 | loss: 1.585885
2022-07-27 18:56:31.732 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 18 | step:  400 | mle_loss: 1.382130 | cl_loss: 0.038421 | loss: 1.574237
2022-07-27 18:56:49.896 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 18 | step:  450 | mle_loss: 1.415025 | cl_loss: 0.039300 | loss: 1.611525
2022-07-27 18:57:07.969 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 18 | step:  500 | mle_loss: 1.409944 | cl_loss: 0.039819 | loss: 1.609042
2022-07-27 18:57:25.797 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 18 | step:  550 | mle_loss: 1.378689 | cl_loss: 0.039754 | loss: 1.577459
2022-07-27 18:57:43.236 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 18 | step:  600 | mle_loss: 1.400160 | cl_loss: 0.040027 | loss: 1.600292
2022-07-27 18:58:01.023 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 18 | step:  650 | mle_loss: 1.379840 | cl_loss: 0.038201 | loss: 1.570845
2022-07-27 18:58:18.437 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 18 | step:  700 | mle_loss: 1.379170 | cl_loss: 0.036033 | loss: 1.559337
2022-07-27 18:58:36.075 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 18 | step:  750 | mle_loss: 1.399965 | cl_loss: 0.036799 | loss: 1.583958
2022-07-27 18:58:53.871 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 18 | step:  800 | mle_loss: 1.389964 | cl_loss: 0.035918 | loss: 1.569555
2022-07-27 18:59:11.624 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 18 | step:  850 | mle_loss: 1.383838 | cl_loss: 0.035661 | loss: 1.562142
2022-07-27 18:59:29.463 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 18 | step:  900 | mle_loss: 1.386624 | cl_loss: 0.035501 | loss: 1.564128
2022-07-27 18:59:47.223 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 18 | step:  950 | mle_loss: 1.391935 | cl_loss: 0.035005 | loss: 1.566961
2022-07-27 19:00:04.922 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 18 | step: 1000 | mle_loss: 1.387413 | cl_loss: 0.033634 | loss: 1.555586
2022-07-27 19:00:22.958 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 18 | step: 1050 | mle_loss: 1.371990 | cl_loss: 0.035045 | loss: 1.547216
2022-07-27 19:00:41.018 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 18 | step: 1100 | mle_loss: 1.383985 | cl_loss: 0.032900 | loss: 1.548483
2022-07-27 19:00:59.169 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 18 | step: 1150 | mle_loss: 1.341344 | cl_loss: 0.034886 | loss: 1.515773
2022-07-27 19:01:18.393 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 18 | step: 1200 | mle_loss: 1.353664 | cl_loss: 0.033371 | loss: 1.520521
2022-07-27 19:01:36.066 | INFO     | processing.dataset:_load_and_cache_examples:43 - Loading examples from cache file data/cache/train_set/train_19.pkl
2022-07-27 19:01:37.928 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 19 | step:    0 | mle_loss: 1.377836 | cl_loss: 0.033482 | loss: 1.545244
2022-07-27 19:01:55.591 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 19 | step:   50 | mle_loss: 1.378254 | cl_loss: 0.037754 | loss: 1.567024
2022-07-27 19:02:13.320 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 19 | step:  100 | mle_loss: 1.334969 | cl_loss: 0.036223 | loss: 1.516083
2022-07-27 19:02:31.146 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 19 | step:  150 | mle_loss: 1.361179 | cl_loss: 0.036968 | loss: 1.546019
2022-07-27 19:02:48.995 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 19 | step:  200 | mle_loss: 1.357485 | cl_loss: 0.036546 | loss: 1.540213
2022-07-27 19:03:07.265 | INFO     | __main__:evaluate:178 - Generating...
2022-07-27 19:04:28.405 | INFO     | __main__:evaluate:188 - Generation finished.
2022-07-27 19:04:28.405 | INFO     | __main__:evaluate:195 - Rouge scores: {'rouge-1': 0.375, 'rouge-2': 0.2227, 'rouge-l': 0.337}
2022-07-27 19:04:28.405 | INFO     | __main__:train:137 - Eval loss: 0.0, the best loss: {'loss': 0.0, 'epoch': 0, 'step': 749}
2022-07-27 19:04:28.405 | INFO     | __main__:train:138 - Rouge scores: {'rouge-1': 0.375, 'rouge-2': 0.2227, 'rouge-l': 0.337}, the best scores: {'rouge-1': 0.3991, 'rouge-2': 0.2428, 'rouge-l': 0.3527, 'epoch': 0, 'step': 499}
2022-07-27 19:04:28.409 | INFO     | __main__:train:143 - Saving model checkpoint to checkpoints/MoCoBart-0-19-249
2022-07-27 19:04:31.140 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 19 | step:  250 | mle_loss: 1.344952 | cl_loss: 0.037948 | loss: 1.534694
2022-07-27 19:04:48.777 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 19 | step:  300 | mle_loss: 1.376859 | cl_loss: 0.037256 | loss: 1.563140
2022-07-27 19:05:06.740 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 19 | step:  350 | mle_loss: 1.330345 | cl_loss: 0.035998 | loss: 1.510333
2022-07-27 19:05:24.633 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 19 | step:  400 | mle_loss: 1.355726 | cl_loss: 0.037006 | loss: 1.540757
2022-07-27 19:05:42.790 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 19 | step:  450 | mle_loss: 1.342345 | cl_loss: 0.035648 | loss: 1.520584
2022-07-27 19:06:00.989 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 19 | step:  500 | mle_loss: 1.320607 | cl_loss: 0.038308 | loss: 1.512147
2022-07-27 19:06:19.154 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 19 | step:  550 | mle_loss: 1.367880 | cl_loss: 0.035847 | loss: 1.547115
2022-07-27 19:06:37.267 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 19 | step:  600 | mle_loss: 1.359136 | cl_loss: 0.037487 | loss: 1.546571
2022-07-27 19:06:55.564 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 19 | step:  650 | mle_loss: 1.330443 | cl_loss: 0.037062 | loss: 1.515753
2022-07-27 19:07:13.885 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 19 | step:  700 | mle_loss: 1.336292 | cl_loss: 0.036237 | loss: 1.517475
2022-07-27 19:07:32.045 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 19 | step:  750 | mle_loss: 1.351919 | cl_loss: 0.034423 | loss: 1.524032
2022-07-27 19:07:50.111 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 19 | step:  800 | mle_loss: 1.330834 | cl_loss: 0.035194 | loss: 1.506803
2022-07-27 19:08:08.452 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 19 | step:  850 | mle_loss: 1.340286 | cl_loss: 0.035409 | loss: 1.517329
2022-07-27 19:08:26.252 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 19 | step:  900 | mle_loss: 1.322283 | cl_loss: 0.035089 | loss: 1.497730
2022-07-27 19:08:45.318 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 19 | step:  950 | mle_loss: 1.331822 | cl_loss: 0.035398 | loss: 1.508812
2022-07-27 19:09:03.606 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 19 | step: 1000 | mle_loss: 1.310634 | cl_loss: 0.034618 | loss: 1.483724
2022-07-27 19:09:21.749 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 19 | step: 1050 | mle_loss: 1.338328 | cl_loss: 0.036311 | loss: 1.519883
2022-07-27 19:09:39.963 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 19 | step: 1100 | mle_loss: 1.294189 | cl_loss: 0.035115 | loss: 1.469764
2022-07-27 19:09:57.832 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 19 | step: 1150 | mle_loss: 1.326371 | cl_loss: 0.035809 | loss: 1.505418
2022-07-27 19:10:16.082 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 19 | step: 1200 | mle_loss: 1.302137 | cl_loss: 0.034882 | loss: 1.476547
2022-07-27 19:10:34.135 | INFO     | processing.dataset:_load_and_cache_examples:43 - Loading examples from cache file data/cache/train_set/train_20.pkl
2022-07-27 19:10:36.055 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 20 | step:    0 | mle_loss: 1.313045 | cl_loss: 0.035360 | loss: 1.489843
2022-07-27 19:10:54.139 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 20 | step:   50 | mle_loss: 1.456385 | cl_loss: 0.036404 | loss: 1.638408
2022-07-27 19:11:12.198 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 20 | step:  100 | mle_loss: 1.422401 | cl_loss: 0.036627 | loss: 1.605534
2022-07-27 19:11:30.341 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 20 | step:  150 | mle_loss: 1.421815 | cl_loss: 0.034665 | loss: 1.595142
2022-07-27 19:11:48.296 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 20 | step:  200 | mle_loss: 1.453018 | cl_loss: 0.034660 | loss: 1.626318
2022-07-27 19:12:06.298 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 20 | step:  250 | mle_loss: 1.420071 | cl_loss: 0.035020 | loss: 1.595170
2022-07-27 19:12:24.444 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 20 | step:  300 | mle_loss: 1.434377 | cl_loss: 0.035598 | loss: 1.612367
2022-07-27 19:12:42.551 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 20 | step:  350 | mle_loss: 1.405985 | cl_loss: 0.036017 | loss: 1.586073
2022-07-27 19:13:00.820 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 20 | step:  400 | mle_loss: 1.407039 | cl_loss: 0.034159 | loss: 1.577834
2022-07-27 19:13:18.840 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 20 | step:  450 | mle_loss: 1.395318 | cl_loss: 0.034844 | loss: 1.569536
2022-07-27 19:13:36.755 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 20 | step:  500 | mle_loss: 1.387333 | cl_loss: 0.034369 | loss: 1.559175
2022-07-27 19:13:54.932 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 20 | step:  550 | mle_loss: 1.415587 | cl_loss: 0.036703 | loss: 1.599104
2022-07-27 19:14:13.016 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 20 | step:  600 | mle_loss: 1.423363 | cl_loss: 0.033918 | loss: 1.592953
2022-07-27 19:14:31.111 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 20 | step:  650 | mle_loss: 1.406783 | cl_loss: 0.035949 | loss: 1.586527
2022-07-27 19:14:48.742 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 20 | step:  700 | mle_loss: 1.408979 | cl_loss: 0.034211 | loss: 1.580036
2022-07-27 19:15:06.912 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 20 | step:  750 | mle_loss: 1.420810 | cl_loss: 0.034432 | loss: 1.592969
2022-07-27 19:15:25.126 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 20 | step:  800 | mle_loss: 1.403359 | cl_loss: 0.034120 | loss: 1.573957
2022-07-27 19:15:43.142 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 20 | step:  850 | mle_loss: 1.390129 | cl_loss: 0.035578 | loss: 1.568020
2022-07-27 19:16:01.132 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 20 | step:  900 | mle_loss: 1.395021 | cl_loss: 0.034761 | loss: 1.568826
2022-07-27 19:16:19.259 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 20 | step:  950 | mle_loss: 1.387433 | cl_loss: 0.034756 | loss: 1.561214
2022-07-27 19:16:36.751 | INFO     | __main__:evaluate:178 - Generating...
2022-07-27 19:18:01.732 | INFO     | __main__:evaluate:188 - Generation finished.
2022-07-27 19:18:01.733 | INFO     | __main__:evaluate:195 - Rouge scores: {'rouge-1': 0.3938, 'rouge-2': 0.235, 'rouge-l': 0.3491}
2022-07-27 19:18:01.733 | INFO     | __main__:train:137 - Eval loss: 0.0, the best loss: {'loss': 0.0, 'epoch': 0, 'step': 749}
2022-07-27 19:18:01.733 | INFO     | __main__:train:138 - Rouge scores: {'rouge-1': 0.3938, 'rouge-2': 0.235, 'rouge-l': 0.3491}, the best scores: {'rouge-1': 0.3991, 'rouge-2': 0.2428, 'rouge-l': 0.3527, 'epoch': 0, 'step': 499}
2022-07-27 19:18:01.733 | INFO     | __main__:train:143 - Saving model checkpoint to checkpoints/MoCoBart-0-20-999
2022-07-27 19:18:04.801 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 20 | step: 1000 | mle_loss: 1.413085 | cl_loss: 0.036603 | loss: 1.596100
2022-07-27 19:18:22.742 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 20 | step: 1050 | mle_loss: 1.401512 | cl_loss: 0.034179 | loss: 1.572407
2022-07-27 19:18:40.800 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 20 | step: 1100 | mle_loss: 1.408116 | cl_loss: 0.035946 | loss: 1.587848
2022-07-27 19:18:58.793 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 20 | step: 1150 | mle_loss: 1.405267 | cl_loss: 0.034988 | loss: 1.580207
2022-07-27 19:19:16.701 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 20 | step: 1200 | mle_loss: 1.401245 | cl_loss: 0.034542 | loss: 1.573955
2022-07-27 19:19:34.243 | INFO     | processing.dataset:_load_and_cache_examples:43 - Loading examples from cache file data/cache/train_set/train_21.pkl
2022-07-27 19:19:36.171 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 21 | step:    0 | mle_loss: 1.363536 | cl_loss: 0.035295 | loss: 1.540010
2022-07-27 19:19:54.133 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 21 | step:   50 | mle_loss: 1.431395 | cl_loss: 0.039007 | loss: 1.626428
2022-07-27 19:20:11.876 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 21 | step:  100 | mle_loss: 1.407141 | cl_loss: 0.038653 | loss: 1.600404
2022-07-27 19:20:29.945 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 21 | step:  150 | mle_loss: 1.412381 | cl_loss: 0.040465 | loss: 1.614707
2022-07-27 19:20:47.935 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 21 | step:  200 | mle_loss: 1.381757 | cl_loss: 0.039249 | loss: 1.578002
2022-07-27 19:21:06.256 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 21 | step:  250 | mle_loss: 1.414393 | cl_loss: 0.040321 | loss: 1.615996
2022-07-27 19:21:24.190 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 21 | step:  300 | mle_loss: 1.403276 | cl_loss: 0.039559 | loss: 1.601070
2022-07-27 19:21:42.499 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 21 | step:  350 | mle_loss: 1.393737 | cl_loss: 0.041135 | loss: 1.599413
2022-07-27 19:22:00.566 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 21 | step:  400 | mle_loss: 1.416979 | cl_loss: 0.039191 | loss: 1.612936
2022-07-27 19:22:18.682 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 21 | step:  450 | mle_loss: 1.376850 | cl_loss: 0.038944 | loss: 1.571568
2022-07-27 19:22:36.752 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 21 | step:  500 | mle_loss: 1.379210 | cl_loss: 0.040827 | loss: 1.583348
2022-07-27 19:22:54.731 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 21 | step:  550 | mle_loss: 1.388977 | cl_loss: 0.039725 | loss: 1.587600
2022-07-27 19:23:12.893 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 21 | step:  600 | mle_loss: 1.407889 | cl_loss: 0.037380 | loss: 1.594791
2022-07-27 19:23:30.878 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 21 | step:  650 | mle_loss: 1.382916 | cl_loss: 0.038625 | loss: 1.576040
2022-07-27 19:23:49.106 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 21 | step:  700 | mle_loss: 1.368891 | cl_loss: 0.038196 | loss: 1.559870
2022-07-27 19:24:07.343 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 21 | step:  750 | mle_loss: 1.377956 | cl_loss: 0.037891 | loss: 1.567413
2022-07-27 19:24:25.501 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 21 | step:  800 | mle_loss: 1.358383 | cl_loss: 0.039183 | loss: 1.554299
2022-07-27 19:24:43.627 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 21 | step:  850 | mle_loss: 1.353970 | cl_loss: 0.038292 | loss: 1.545431
2022-07-27 19:25:01.622 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 21 | step:  900 | mle_loss: 1.386909 | cl_loss: 0.042240 | loss: 1.598108
2022-07-27 19:25:19.891 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 21 | step:  950 | mle_loss: 1.371317 | cl_loss: 0.037828 | loss: 1.560456
2022-07-27 19:25:38.087 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 21 | step: 1000 | mle_loss: 1.357921 | cl_loss: 0.037260 | loss: 1.544219
2022-07-27 19:25:56.316 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 21 | step: 1050 | mle_loss: 1.375278 | cl_loss: 0.037071 | loss: 1.560632
2022-07-27 19:26:14.406 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 21 | step: 1100 | mle_loss: 1.376710 | cl_loss: 0.038556 | loss: 1.569492
2022-07-27 19:26:32.629 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 21 | step: 1150 | mle_loss: 1.392663 | cl_loss: 0.038725 | loss: 1.586287
2022-07-27 19:26:50.725 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 21 | step: 1200 | mle_loss: 1.380917 | cl_loss: 0.037867 | loss: 1.570255
2022-07-27 19:27:08.526 | INFO     | processing.dataset:_load_and_cache_examples:43 - Loading examples from cache file data/cache/train_set/train_22.pkl
2022-07-27 19:27:10.438 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 22 | step:    0 | mle_loss: 1.387259 | cl_loss: 0.038263 | loss: 1.578572
2022-07-27 19:27:28.583 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 22 | step:   50 | mle_loss: 1.474167 | cl_loss: 0.035899 | loss: 1.653662
2022-07-27 19:27:46.778 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 22 | step:  100 | mle_loss: 1.454532 | cl_loss: 0.037989 | loss: 1.644479
2022-07-27 19:28:04.786 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 22 | step:  150 | mle_loss: 1.456054 | cl_loss: 0.037241 | loss: 1.642259
2022-07-27 19:28:22.906 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 22 | step:  200 | mle_loss: 1.477823 | cl_loss: 0.037065 | loss: 1.663146
2022-07-27 19:28:41.030 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 22 | step:  250 | mle_loss: 1.450107 | cl_loss: 0.038411 | loss: 1.642164
2022-07-27 19:28:59.137 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 22 | step:  300 | mle_loss: 1.478476 | cl_loss: 0.036602 | loss: 1.661486
2022-07-27 19:29:17.316 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 22 | step:  350 | mle_loss: 1.433470 | cl_loss: 0.037548 | loss: 1.621211
2022-07-27 19:29:35.268 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 22 | step:  400 | mle_loss: 1.439242 | cl_loss: 0.037637 | loss: 1.627429
2022-07-27 19:29:53.250 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 22 | step:  450 | mle_loss: 1.466853 | cl_loss: 0.036604 | loss: 1.649872
2022-07-27 19:30:11.172 | INFO     | __main__:evaluate:178 - Generating...
2022-07-27 19:31:33.894 | INFO     | __main__:evaluate:188 - Generation finished.
2022-07-27 19:31:33.895 | INFO     | __main__:evaluate:195 - Rouge scores: {'rouge-1': 0.3932, 'rouge-2': 0.2344, 'rouge-l': 0.3509}
2022-07-27 19:31:33.895 | INFO     | __main__:train:137 - Eval loss: 0.0, the best loss: {'loss': 0.0, 'epoch': 0, 'step': 749}
2022-07-27 19:31:33.895 | INFO     | __main__:train:138 - Rouge scores: {'rouge-1': 0.3932, 'rouge-2': 0.2344, 'rouge-l': 0.3509}, the best scores: {'rouge-1': 0.3991, 'rouge-2': 0.2428, 'rouge-l': 0.3527, 'epoch': 0, 'step': 499}
2022-07-27 19:31:33.901 | INFO     | __main__:train:143 - Saving model checkpoint to checkpoints/MoCoBart-0-22-499
2022-07-27 19:31:36.719 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 22 | step:  500 | mle_loss: 1.424594 | cl_loss: 0.036414 | loss: 1.606665
2022-07-27 19:31:54.705 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 22 | step:  550 | mle_loss: 1.445523 | cl_loss: 0.036622 | loss: 1.628631
2022-07-27 19:32:12.579 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 22 | step:  600 | mle_loss: 1.455619 | cl_loss: 0.038615 | loss: 1.648695
2022-07-27 19:32:30.868 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 22 | step:  650 | mle_loss: 1.458663 | cl_loss: 0.039349 | loss: 1.655410
2022-07-27 19:32:48.652 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 22 | step:  700 | mle_loss: 1.428244 | cl_loss: 0.037232 | loss: 1.614404
2022-07-27 19:33:06.457 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 22 | step:  750 | mle_loss: 1.456604 | cl_loss: 0.037778 | loss: 1.645491
2022-07-27 19:33:24.457 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 22 | step:  800 | mle_loss: 1.462546 | cl_loss: 0.037418 | loss: 1.649634
2022-07-27 19:33:42.512 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 22 | step:  850 | mle_loss: 1.412684 | cl_loss: 0.036092 | loss: 1.593145
2022-07-27 19:34:00.518 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 22 | step:  900 | mle_loss: 1.416532 | cl_loss: 0.036362 | loss: 1.598344
2022-07-27 19:34:18.564 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 22 | step:  950 | mle_loss: 1.415688 | cl_loss: 0.036849 | loss: 1.599934
2022-07-27 19:34:36.536 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 22 | step: 1000 | mle_loss: 1.416528 | cl_loss: 0.036002 | loss: 1.596537
2022-07-27 19:34:54.466 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 22 | step: 1050 | mle_loss: 1.456387 | cl_loss: 0.037649 | loss: 1.644631
2022-07-27 19:35:12.351 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 22 | step: 1100 | mle_loss: 1.436601 | cl_loss: 0.037518 | loss: 1.624192
2022-07-27 19:35:30.403 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 22 | step: 1150 | mle_loss: 1.422752 | cl_loss: 0.038417 | loss: 1.614835
2022-07-27 19:35:48.211 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 22 | step: 1200 | mle_loss: 1.452684 | cl_loss: 0.038820 | loss: 1.646783
2022-07-27 19:36:05.990 | INFO     | processing.dataset:_load_and_cache_examples:43 - Loading examples from cache file data/cache/train_set/train_23.pkl
2022-07-27 19:36:08.175 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 23 | step:    0 | mle_loss: 1.401459 | cl_loss: 0.037535 | loss: 1.589135
2022-07-27 19:36:26.274 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 23 | step:   50 | mle_loss: 1.393270 | cl_loss: 0.038250 | loss: 1.584517
2022-07-27 19:36:43.996 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 23 | step:  100 | mle_loss: 1.387001 | cl_loss: 0.037438 | loss: 1.574188
2022-07-27 19:37:02.020 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 23 | step:  150 | mle_loss: 1.393111 | cl_loss: 0.037832 | loss: 1.582269
2022-07-27 19:37:20.285 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 23 | step:  200 | mle_loss: 1.349837 | cl_loss: 0.036838 | loss: 1.534027
2022-07-27 19:37:38.176 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 23 | step:  250 | mle_loss: 1.358248 | cl_loss: 0.036926 | loss: 1.542880
2022-07-27 19:37:56.377 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 23 | step:  300 | mle_loss: 1.363542 | cl_loss: 0.039329 | loss: 1.560189
2022-07-27 19:38:14.661 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 23 | step:  350 | mle_loss: 1.367346 | cl_loss: 0.037016 | loss: 1.552425
2022-07-27 19:38:32.906 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 23 | step:  400 | mle_loss: 1.340844 | cl_loss: 0.036870 | loss: 1.525194
2022-07-27 19:38:50.741 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 23 | step:  450 | mle_loss: 1.372933 | cl_loss: 0.035994 | loss: 1.552902
2022-07-27 19:39:08.849 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 23 | step:  500 | mle_loss: 1.386223 | cl_loss: 0.037428 | loss: 1.573364
2022-07-27 19:39:26.885 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 23 | step:  550 | mle_loss: 1.345335 | cl_loss: 0.036942 | loss: 1.530047
2022-07-27 19:39:44.795 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 23 | step:  600 | mle_loss: 1.349927 | cl_loss: 0.038216 | loss: 1.541006
2022-07-27 19:40:03.077 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 23 | step:  650 | mle_loss: 1.354015 | cl_loss: 0.038825 | loss: 1.548142
2022-07-27 19:40:20.960 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 23 | step:  700 | mle_loss: 1.367123 | cl_loss: 0.039130 | loss: 1.562772
2022-07-27 19:40:39.157 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 23 | step:  750 | mle_loss: 1.395181 | cl_loss: 0.038382 | loss: 1.587090
2022-07-27 19:40:57.053 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 23 | step:  800 | mle_loss: 1.322905 | cl_loss: 0.038229 | loss: 1.514051
2022-07-27 19:41:15.296 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 23 | step:  850 | mle_loss: 1.344947 | cl_loss: 0.037834 | loss: 1.534117
2022-07-27 19:41:33.536 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 23 | step:  900 | mle_loss: 1.337490 | cl_loss: 0.036672 | loss: 1.520850
2022-07-27 19:41:51.677 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 23 | step:  950 | mle_loss: 1.383211 | cl_loss: 0.038652 | loss: 1.576469
2022-07-27 19:42:09.801 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 23 | step: 1000 | mle_loss: 1.338438 | cl_loss: 0.037410 | loss: 1.525488
2022-07-27 19:42:27.576 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 23 | step: 1050 | mle_loss: 1.368071 | cl_loss: 0.036687 | loss: 1.551504
2022-07-27 19:42:45.476 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 23 | step: 1100 | mle_loss: 1.342201 | cl_loss: 0.037026 | loss: 1.527333
2022-07-27 19:43:02.997 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 23 | step: 1150 | mle_loss: 1.373627 | cl_loss: 0.036569 | loss: 1.556470
2022-07-27 19:43:20.869 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 23 | step: 1200 | mle_loss: 1.362620 | cl_loss: 0.036625 | loss: 1.545747
2022-07-27 19:43:38.636 | INFO     | __main__:evaluate:178 - Generating...
2022-07-27 19:45:03.708 | INFO     | __main__:evaluate:188 - Generation finished.
2022-07-27 19:45:03.708 | INFO     | __main__:evaluate:195 - Rouge scores: {'rouge-1': 0.3961, 'rouge-2': 0.2369, 'rouge-l': 0.3518}
2022-07-27 19:45:03.709 | INFO     | __main__:train:137 - Eval loss: 0.0, the best loss: {'loss': 0.0, 'epoch': 0, 'step': 749}
2022-07-27 19:45:03.709 | INFO     | __main__:train:138 - Rouge scores: {'rouge-1': 0.3961, 'rouge-2': 0.2369, 'rouge-l': 0.3518}, the best scores: {'rouge-1': 0.3991, 'rouge-2': 0.2428, 'rouge-l': 0.3527, 'epoch': 0, 'step': 499}
2022-07-27 19:45:03.709 | INFO     | __main__:train:143 - Saving model checkpoint to checkpoints/MoCoBart-0-23-1249
2022-07-27 19:45:06.400 | INFO     | processing.dataset:_load_and_cache_examples:43 - Loading examples from cache file data/cache/train_set/train_24.pkl
2022-07-27 19:45:08.318 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 24 | step:    0 | mle_loss: 1.319863 | cl_loss: 0.037709 | loss: 1.508408
2022-07-27 19:45:26.470 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 24 | step:   50 | mle_loss: 1.368443 | cl_loss: 0.035777 | loss: 1.547327
2022-07-27 19:45:44.520 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 24 | step:  100 | mle_loss: 1.386334 | cl_loss: 0.036210 | loss: 1.567383
2022-07-27 19:46:02.602 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 24 | step:  150 | mle_loss: 1.355585 | cl_loss: 0.036391 | loss: 1.537539
2022-07-27 19:46:20.756 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 24 | step:  200 | mle_loss: 1.382626 | cl_loss: 0.035768 | loss: 1.561467
2022-07-27 19:46:38.945 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 24 | step:  250 | mle_loss: 1.338725 | cl_loss: 0.035482 | loss: 1.516136
2022-07-27 19:46:57.105 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 24 | step:  300 | mle_loss: 1.364420 | cl_loss: 0.035418 | loss: 1.541509
2022-07-27 19:47:15.263 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 24 | step:  350 | mle_loss: 1.348073 | cl_loss: 0.035296 | loss: 1.524553
2022-07-27 19:47:33.654 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 24 | step:  400 | mle_loss: 1.380156 | cl_loss: 0.034335 | loss: 1.551834
2022-07-27 19:47:52.036 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 24 | step:  450 | mle_loss: 1.358243 | cl_loss: 0.034859 | loss: 1.532540
2022-07-27 19:48:10.336 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 24 | step:  500 | mle_loss: 1.369962 | cl_loss: 0.035009 | loss: 1.545007
2022-07-27 19:48:28.558 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 24 | step:  550 | mle_loss: 1.339820 | cl_loss: 0.036404 | loss: 1.521839
2022-07-27 19:48:46.827 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 24 | step:  600 | mle_loss: 1.353307 | cl_loss: 0.035018 | loss: 1.528398
2022-07-27 19:49:05.153 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 24 | step:  650 | mle_loss: 1.348179 | cl_loss: 0.036347 | loss: 1.529915
2022-07-27 19:49:23.442 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 24 | step:  700 | mle_loss: 1.354922 | cl_loss: 0.034166 | loss: 1.525753
2022-07-27 19:49:41.768 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 24 | step:  750 | mle_loss: 1.331120 | cl_loss: 0.035429 | loss: 1.508265
2022-07-27 19:49:59.803 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 24 | step:  800 | mle_loss: 1.336946 | cl_loss: 0.033473 | loss: 1.504310
2022-07-27 19:50:17.965 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 24 | step:  850 | mle_loss: 1.337795 | cl_loss: 0.034214 | loss: 1.508866
2022-07-27 19:50:36.336 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 24 | step:  900 | mle_loss: 1.332938 | cl_loss: 0.035311 | loss: 1.509491
2022-07-27 19:50:54.590 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 24 | step:  950 | mle_loss: 1.345088 | cl_loss: 0.034619 | loss: 1.518181
2022-07-27 19:51:12.567 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 24 | step: 1000 | mle_loss: 1.357615 | cl_loss: 0.035077 | loss: 1.533002
2022-07-27 19:51:30.869 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 24 | step: 1050 | mle_loss: 1.330561 | cl_loss: 0.034423 | loss: 1.502675
2022-07-27 19:51:49.133 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 24 | step: 1100 | mle_loss: 1.345432 | cl_loss: 0.035490 | loss: 1.522882
2022-07-27 19:52:07.434 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 24 | step: 1150 | mle_loss: 1.320180 | cl_loss: 0.034490 | loss: 1.492629
2022-07-27 19:52:25.684 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 24 | step: 1200 | mle_loss: 1.351700 | cl_loss: 0.034600 | loss: 1.524699
2022-07-27 19:52:43.444 | INFO     | processing.dataset:_load_and_cache_examples:43 - Loading examples from cache file data/cache/train_set/train_25.pkl
2022-07-27 19:52:45.475 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 25 | step:    0 | mle_loss: 1.329982 | cl_loss: 0.034031 | loss: 1.500139
2022-07-27 19:53:03.412 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 25 | step:   50 | mle_loss: 1.473150 | cl_loss: 0.037771 | loss: 1.662006
2022-07-27 19:53:21.251 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 25 | step:  100 | mle_loss: 1.413508 | cl_loss: 0.038834 | loss: 1.607677
2022-07-27 19:53:38.986 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 25 | step:  150 | mle_loss: 1.398781 | cl_loss: 0.040423 | loss: 1.600894
2022-07-27 19:53:56.836 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 25 | step:  200 | mle_loss: 1.385432 | cl_loss: 0.038569 | loss: 1.578274
2022-07-27 19:54:14.980 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 25 | step:  250 | mle_loss: 1.368394 | cl_loss: 0.040806 | loss: 1.572422
2022-07-27 19:54:33.010 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 25 | step:  300 | mle_loss: 1.386046 | cl_loss: 0.040267 | loss: 1.587379
2022-07-27 19:54:50.879 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 25 | step:  350 | mle_loss: 1.373522 | cl_loss: 0.040938 | loss: 1.578210
2022-07-27 19:55:08.752 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 25 | step:  400 | mle_loss: 1.394154 | cl_loss: 0.038808 | loss: 1.588193
2022-07-27 19:55:26.845 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 25 | step:  450 | mle_loss: 1.391201 | cl_loss: 0.040140 | loss: 1.591901
2022-07-27 19:55:45.106 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 25 | step:  500 | mle_loss: 1.378091 | cl_loss: 0.040027 | loss: 1.578226
2022-07-27 19:56:03.108 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 25 | step:  550 | mle_loss: 1.375852 | cl_loss: 0.039174 | loss: 1.571724
2022-07-27 19:56:21.267 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 25 | step:  600 | mle_loss: 1.387724 | cl_loss: 0.037897 | loss: 1.577210
2022-07-27 19:56:39.056 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 25 | step:  650 | mle_loss: 1.400621 | cl_loss: 0.039418 | loss: 1.597713
2022-07-27 19:56:56.968 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 25 | step:  700 | mle_loss: 1.384050 | cl_loss: 0.038376 | loss: 1.575929
2022-07-27 19:57:14.718 | INFO     | __main__:evaluate:178 - Generating...
2022-07-27 19:58:39.649 | INFO     | __main__:evaluate:188 - Generation finished.
2022-07-27 19:58:39.649 | INFO     | __main__:evaluate:195 - Rouge scores: {'rouge-1': 0.4145, 'rouge-2': 0.2508, 'rouge-l': 0.3637}
2022-07-27 19:58:39.650 | INFO     | __main__:train:137 - Eval loss: 0.0, the best loss: {'loss': 0.0, 'epoch': 0, 'step': 749}
2022-07-27 19:58:39.650 | INFO     | __main__:train:138 - Rouge scores: {'rouge-1': 0.4145, 'rouge-2': 0.2508, 'rouge-l': 0.3637, 'epoch': 0, 'step': 749}, the best scores: {'rouge-1': 0.4145, 'rouge-2': 0.2508, 'rouge-l': 0.3637, 'epoch': 0, 'step': 749}
2022-07-27 19:58:39.650 | INFO     | __main__:train:143 - Saving model checkpoint to checkpoints/MoCoBart-0-25-749
2022-07-27 19:58:42.270 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 25 | step:  750 | mle_loss: 1.391777 | cl_loss: 0.039839 | loss: 1.590969
2022-07-27 19:59:00.105 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 25 | step:  800 | mle_loss: 1.402973 | cl_loss: 0.038243 | loss: 1.594190
2022-07-27 19:59:18.096 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 25 | step:  850 | mle_loss: 1.356897 | cl_loss: 0.039712 | loss: 1.555457
2022-07-27 19:59:35.829 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 25 | step:  900 | mle_loss: 1.366360 | cl_loss: 0.037363 | loss: 1.553174
2022-07-27 19:59:53.779 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 25 | step:  950 | mle_loss: 1.396046 | cl_loss: 0.038865 | loss: 1.590373
2022-07-27 20:00:11.617 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 25 | step: 1000 | mle_loss: 1.362497 | cl_loss: 0.036856 | loss: 1.546776
2022-07-27 20:00:29.672 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 25 | step: 1050 | mle_loss: 1.358662 | cl_loss: 0.038327 | loss: 1.550297
2022-07-27 20:00:47.730 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 25 | step: 1100 | mle_loss: 1.380854 | cl_loss: 0.038049 | loss: 1.571100
2022-07-27 20:01:05.521 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 25 | step: 1150 | mle_loss: 1.388114 | cl_loss: 0.039375 | loss: 1.584990
2022-07-27 20:01:23.452 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 25 | step: 1200 | mle_loss: 1.357901 | cl_loss: 0.038192 | loss: 1.548859
2022-07-27 20:01:41.138 | INFO     | processing.dataset:_load_and_cache_examples:43 - Loading examples from cache file data/cache/train_set/train_26.pkl
2022-07-27 20:01:42.714 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 26 | step:    0 | mle_loss: 1.384849 | cl_loss: 0.038195 | loss: 1.575824
2022-07-27 20:02:00.689 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 26 | step:   50 | mle_loss: 1.440300 | cl_loss: 0.040961 | loss: 1.645103
2022-07-27 20:02:18.746 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 26 | step:  100 | mle_loss: 1.435095 | cl_loss: 0.043552 | loss: 1.652854
2022-07-27 20:02:36.947 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 26 | step:  150 | mle_loss: 1.432281 | cl_loss: 0.044330 | loss: 1.653931
2022-07-27 20:02:55.059 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 26 | step:  200 | mle_loss: 1.420630 | cl_loss: 0.043353 | loss: 1.637395
2022-07-27 20:03:13.196 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 26 | step:  250 | mle_loss: 1.405829 | cl_loss: 0.041488 | loss: 1.613267
2022-07-27 20:03:31.288 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 26 | step:  300 | mle_loss: 1.409882 | cl_loss: 0.041531 | loss: 1.617536
2022-07-27 20:03:49.403 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 26 | step:  350 | mle_loss: 1.425177 | cl_loss: 0.042099 | loss: 1.635673
2022-07-27 20:04:07.629 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 26 | step:  400 | mle_loss: 1.400527 | cl_loss: 0.043655 | loss: 1.618804
2022-07-27 20:04:25.629 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 26 | step:  450 | mle_loss: 1.420791 | cl_loss: 0.043756 | loss: 1.639568
2022-07-27 20:04:43.748 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 26 | step:  500 | mle_loss: 1.374491 | cl_loss: 0.041667 | loss: 1.582823
2022-07-27 20:05:01.597 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 26 | step:  550 | mle_loss: 1.404483 | cl_loss: 0.040091 | loss: 1.604939
2022-07-27 20:05:19.735 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 26 | step:  600 | mle_loss: 1.383036 | cl_loss: 0.042725 | loss: 1.596662
2022-07-27 20:05:37.896 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 26 | step:  650 | mle_loss: 1.395854 | cl_loss: 0.040325 | loss: 1.597479
2022-07-27 20:05:56.226 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 26 | step:  700 | mle_loss: 1.351904 | cl_loss: 0.039581 | loss: 1.549812
2022-07-27 20:06:14.284 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 26 | step:  750 | mle_loss: 1.373426 | cl_loss: 0.038932 | loss: 1.568088
2022-07-27 20:06:32.590 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 26 | step:  800 | mle_loss: 1.348151 | cl_loss: 0.039243 | loss: 1.544367
2022-07-27 20:06:50.871 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 26 | step:  850 | mle_loss: 1.374353 | cl_loss: 0.038793 | loss: 1.568316
2022-07-27 20:07:08.971 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 26 | step:  900 | mle_loss: 1.351469 | cl_loss: 0.038585 | loss: 1.544393
2022-07-27 20:07:27.377 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 26 | step:  950 | mle_loss: 1.383717 | cl_loss: 0.038098 | loss: 1.574208
2022-07-27 20:07:45.513 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 26 | step: 1000 | mle_loss: 1.396292 | cl_loss: 0.037849 | loss: 1.585537
2022-07-27 20:08:03.715 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 26 | step: 1050 | mle_loss: 1.356041 | cl_loss: 0.038771 | loss: 1.549896
2022-07-27 20:08:21.747 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 26 | step: 1100 | mle_loss: 1.403034 | cl_loss: 0.038827 | loss: 1.597168
2022-07-27 20:08:40.078 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 26 | step: 1150 | mle_loss: 1.384654 | cl_loss: 0.037995 | loss: 1.574628
2022-07-27 20:08:58.371 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 26 | step: 1200 | mle_loss: 1.363894 | cl_loss: 0.037155 | loss: 1.549668
2022-07-27 20:09:16.192 | INFO     | processing.dataset:_load_and_cache_examples:43 - Loading examples from cache file data/cache/train_set/train_27.pkl
2022-07-27 20:09:18.300 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 27 | step:    0 | mle_loss: 1.371184 | cl_loss: 0.037927 | loss: 1.560819
2022-07-27 20:09:36.333 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 27 | step:   50 | mle_loss: 1.282765 | cl_loss: 0.035298 | loss: 1.459252
2022-07-27 20:09:54.234 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 27 | step:  100 | mle_loss: 1.289725 | cl_loss: 0.035784 | loss: 1.468646
2022-07-27 20:10:12.290 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 27 | step:  150 | mle_loss: 1.295166 | cl_loss: 0.035354 | loss: 1.471936
2022-07-27 20:10:30.265 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 27 | step:  200 | mle_loss: 1.295528 | cl_loss: 0.034255 | loss: 1.466801
2022-07-27 20:10:48.048 | INFO     | __main__:evaluate:178 - Generating...
2022-07-27 20:12:11.165 | INFO     | __main__:evaluate:188 - Generation finished.
2022-07-27 20:12:11.166 | INFO     | __main__:evaluate:195 - Rouge scores: {'rouge-1': 0.4016, 'rouge-2': 0.2404, 'rouge-l': 0.356}
2022-07-27 20:12:11.166 | INFO     | __main__:train:137 - Eval loss: 0.0, the best loss: {'loss': 0.0, 'epoch': 0, 'step': 749}
2022-07-27 20:12:11.166 | INFO     | __main__:train:138 - Rouge scores: {'rouge-1': 0.4016, 'rouge-2': 0.2404, 'rouge-l': 0.356}, the best scores: {'rouge-1': 0.4145, 'rouge-2': 0.2508, 'rouge-l': 0.3637, 'epoch': 0, 'step': 749}
2022-07-27 20:12:11.166 | INFO     | __main__:train:143 - Saving model checkpoint to checkpoints/MoCoBart-0-27-249
2022-07-27 20:12:13.877 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 27 | step:  250 | mle_loss: 1.293286 | cl_loss: 0.036214 | loss: 1.474355
2022-07-27 20:12:32.179 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 27 | step:  300 | mle_loss: 1.256638 | cl_loss: 0.036930 | loss: 1.441290
2022-07-27 20:12:50.123 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 27 | step:  350 | mle_loss: 1.305121 | cl_loss: 0.033743 | loss: 1.473834
2022-07-27 20:13:08.170 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 27 | step:  400 | mle_loss: 1.260332 | cl_loss: 0.034207 | loss: 1.431369
2022-07-27 20:13:26.142 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 27 | step:  450 | mle_loss: 1.289390 | cl_loss: 0.033863 | loss: 1.458706
2022-07-27 20:13:44.254 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 27 | step:  500 | mle_loss: 1.280594 | cl_loss: 0.035745 | loss: 1.459320
2022-07-27 20:14:02.182 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 27 | step:  550 | mle_loss: 1.277804 | cl_loss: 0.034780 | loss: 1.451702
2022-07-27 20:14:20.408 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 27 | step:  600 | mle_loss: 1.271842 | cl_loss: 0.034196 | loss: 1.442822
2022-07-27 20:14:38.489 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 27 | step:  650 | mle_loss: 1.268204 | cl_loss: 0.034891 | loss: 1.442661
2022-07-27 20:14:56.773 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 27 | step:  700 | mle_loss: 1.283240 | cl_loss: 0.037223 | loss: 1.469356
2022-07-27 20:15:15.006 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 27 | step:  750 | mle_loss: 1.244025 | cl_loss: 0.034030 | loss: 1.414175
2022-07-27 20:15:32.907 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 27 | step:  800 | mle_loss: 1.255918 | cl_loss: 0.034206 | loss: 1.426948
2022-07-27 20:15:51.247 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 27 | step:  850 | mle_loss: 1.259370 | cl_loss: 0.034612 | loss: 1.432428
2022-07-27 20:16:09.047 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 27 | step:  900 | mle_loss: 1.245069 | cl_loss: 0.033995 | loss: 1.415047
2022-07-27 20:16:26.860 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 27 | step:  950 | mle_loss: 1.250593 | cl_loss: 0.035131 | loss: 1.426247
2022-07-27 20:16:44.439 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 27 | step: 1000 | mle_loss: 1.263259 | cl_loss: 0.034414 | loss: 1.435328
2022-07-27 20:17:02.511 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 27 | step: 1050 | mle_loss: 1.262812 | cl_loss: 0.033152 | loss: 1.428570
2022-07-27 20:17:20.575 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 27 | step: 1100 | mle_loss: 1.253734 | cl_loss: 0.034700 | loss: 1.427232
2022-07-27 20:17:38.485 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 27 | step: 1150 | mle_loss: 1.251297 | cl_loss: 0.035029 | loss: 1.426442
2022-07-27 20:17:56.672 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 27 | step: 1200 | mle_loss: 1.261478 | cl_loss: 0.034254 | loss: 1.432749
2022-07-27 20:18:14.439 | INFO     | processing.dataset:_load_and_cache_examples:43 - Loading examples from cache file data/cache/train_set/train_28.pkl
2022-07-27 20:18:16.287 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 28 | step:    0 | mle_loss: 1.234809 | cl_loss: 0.033850 | loss: 1.404057
2022-07-27 20:18:34.455 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 28 | step:   50 | mle_loss: 1.366790 | cl_loss: 0.035748 | loss: 1.545530
2022-07-27 20:18:52.519 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 28 | step:  100 | mle_loss: 1.371613 | cl_loss: 0.037679 | loss: 1.560009
2022-07-27 20:19:10.843 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 28 | step:  150 | mle_loss: 1.336142 | cl_loss: 0.036426 | loss: 1.518270
2022-07-27 20:19:29.279 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 28 | step:  200 | mle_loss: 1.342197 | cl_loss: 0.041410 | loss: 1.549246
2022-07-27 20:19:47.503 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 28 | step:  250 | mle_loss: 1.329543 | cl_loss: 0.037928 | loss: 1.519184
2022-07-27 20:20:05.560 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 28 | step:  300 | mle_loss: 1.333450 | cl_loss: 0.036219 | loss: 1.514545
2022-07-27 20:20:23.864 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 28 | step:  350 | mle_loss: 1.339486 | cl_loss: 0.039702 | loss: 1.537998
2022-07-27 20:20:42.235 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 28 | step:  400 | mle_loss: 1.325799 | cl_loss: 0.039974 | loss: 1.525666
2022-07-27 20:21:00.501 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 28 | step:  450 | mle_loss: 1.321777 | cl_loss: 0.036767 | loss: 1.505612
2022-07-27 20:21:18.281 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 28 | step:  500 | mle_loss: 1.322290 | cl_loss: 0.035847 | loss: 1.501527
2022-07-27 20:21:36.453 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 28 | step:  550 | mle_loss: 1.324049 | cl_loss: 0.037676 | loss: 1.512429
2022-07-27 20:21:54.553 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 28 | step:  600 | mle_loss: 1.328297 | cl_loss: 0.039051 | loss: 1.523553
2022-07-27 20:22:12.685 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 28 | step:  650 | mle_loss: 1.322177 | cl_loss: 0.036382 | loss: 1.504085
2022-07-27 20:22:30.786 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 28 | step:  700 | mle_loss: 1.342821 | cl_loss: 0.036060 | loss: 1.523120
2022-07-27 20:22:49.051 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 28 | step:  750 | mle_loss: 1.306576 | cl_loss: 0.037848 | loss: 1.495815
2022-07-27 20:23:07.191 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 28 | step:  800 | mle_loss: 1.332248 | cl_loss: 0.035992 | loss: 1.512208
2022-07-27 20:23:25.333 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 28 | step:  850 | mle_loss: 1.321823 | cl_loss: 0.038472 | loss: 1.514183
2022-07-27 20:23:43.603 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 28 | step:  900 | mle_loss: 1.311927 | cl_loss: 0.037237 | loss: 1.498110
2022-07-27 20:24:02.077 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 28 | step:  950 | mle_loss: 1.307286 | cl_loss: 0.037080 | loss: 1.492685
2022-07-27 20:24:19.978 | INFO     | __main__:evaluate:178 - Generating...
2022-07-27 20:25:45.853 | INFO     | __main__:evaluate:188 - Generation finished.
2022-07-27 20:25:45.853 | INFO     | __main__:evaluate:195 - Rouge scores: {'rouge-1': 0.3861, 'rouge-2': 0.2223, 'rouge-l': 0.339}
2022-07-27 20:25:45.853 | INFO     | __main__:train:137 - Eval loss: 0.0, the best loss: {'loss': 0.0, 'epoch': 0, 'step': 749}
2022-07-27 20:25:45.854 | INFO     | __main__:train:138 - Rouge scores: {'rouge-1': 0.3861, 'rouge-2': 0.2223, 'rouge-l': 0.339}, the best scores: {'rouge-1': 0.4145, 'rouge-2': 0.2508, 'rouge-l': 0.3637, 'epoch': 0, 'step': 749}
2022-07-27 20:25:45.854 | INFO     | __main__:train:143 - Saving model checkpoint to checkpoints/MoCoBart-0-28-999
2022-07-27 20:25:48.793 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 28 | step: 1000 | mle_loss: 1.300013 | cl_loss: 0.035879 | loss: 1.479409
2022-07-27 20:26:06.966 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 28 | step: 1050 | mle_loss: 1.324412 | cl_loss: 0.035313 | loss: 1.500980
2022-07-27 20:26:25.107 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 28 | step: 1100 | mle_loss: 1.293355 | cl_loss: 0.036821 | loss: 1.477457
2022-07-27 20:26:43.578 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 28 | step: 1150 | mle_loss: 1.268971 | cl_loss: 0.036759 | loss: 1.452766
2022-07-27 20:27:01.843 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 28 | step: 1200 | mle_loss: 1.316503 | cl_loss: 0.037172 | loss: 1.502363
2022-07-27 20:27:20.092 | INFO     | processing.dataset:_load_and_cache_examples:43 - Loading examples from cache file data/cache/train_set/train_29.pkl
2022-07-27 20:27:21.873 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 29 | step:    0 | mle_loss: 1.314853 | cl_loss: 0.039111 | loss: 1.510406
2022-07-27 20:27:40.126 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 29 | step:   50 | mle_loss: 1.446802 | cl_loss: 0.035273 | loss: 1.623168
2022-07-27 20:27:57.832 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 29 | step:  100 | mle_loss: 1.426328 | cl_loss: 0.037171 | loss: 1.612183
2022-07-27 20:28:15.381 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 29 | step:  150 | mle_loss: 1.431768 | cl_loss: 0.033805 | loss: 1.600795
2022-07-27 20:28:33.327 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 29 | step:  200 | mle_loss: 1.417263 | cl_loss: 0.035309 | loss: 1.593807
2022-07-27 20:28:51.400 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 29 | step:  250 | mle_loss: 1.438532 | cl_loss: 0.036546 | loss: 1.621260
2022-07-27 20:29:09.312 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 29 | step:  300 | mle_loss: 1.398043 | cl_loss: 0.036621 | loss: 1.581148
2022-07-27 20:29:26.941 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 29 | step:  350 | mle_loss: 1.399412 | cl_loss: 0.032995 | loss: 1.564389
2022-07-27 20:29:45.163 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 29 | step:  400 | mle_loss: 1.395875 | cl_loss: 0.033850 | loss: 1.565122
2022-07-27 20:30:02.867 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 29 | step:  450 | mle_loss: 1.398834 | cl_loss: 0.033232 | loss: 1.564995
2022-07-27 20:30:20.477 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 29 | step:  500 | mle_loss: 1.409454 | cl_loss: 0.033359 | loss: 1.576249
2022-07-27 20:30:38.387 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 29 | step:  550 | mle_loss: 1.393310 | cl_loss: 0.035283 | loss: 1.569726
2022-07-27 20:30:56.185 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 29 | step:  600 | mle_loss: 1.405751 | cl_loss: 0.034710 | loss: 1.579299
2022-07-27 20:31:14.236 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 29 | step:  650 | mle_loss: 1.351520 | cl_loss: 0.034797 | loss: 1.525507
2022-07-27 20:31:32.049 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 29 | step:  700 | mle_loss: 1.398307 | cl_loss: 0.035040 | loss: 1.573505
2022-07-27 20:31:49.977 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 29 | step:  750 | mle_loss: 1.403943 | cl_loss: 0.034538 | loss: 1.576632
2022-07-27 20:32:08.030 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 29 | step:  800 | mle_loss: 1.401928 | cl_loss: 0.035696 | loss: 1.580408
2022-07-27 20:32:25.780 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 29 | step:  850 | mle_loss: 1.421998 | cl_loss: 0.035702 | loss: 1.600507
2022-07-27 20:32:43.442 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 29 | step:  900 | mle_loss: 1.383653 | cl_loss: 0.033917 | loss: 1.553238
2022-07-27 20:33:01.147 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 29 | step:  950 | mle_loss: 1.390518 | cl_loss: 0.034875 | loss: 1.564891
2022-07-27 20:33:18.988 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 29 | step: 1000 | mle_loss: 1.369190 | cl_loss: 0.032532 | loss: 1.531852
2022-07-27 20:33:36.954 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 29 | step: 1050 | mle_loss: 1.373008 | cl_loss: 0.034517 | loss: 1.545595
2022-07-27 20:33:54.744 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 29 | step: 1100 | mle_loss: 1.379051 | cl_loss: 0.033825 | loss: 1.548175
2022-07-27 20:34:12.803 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 29 | step: 1150 | mle_loss: 1.364258 | cl_loss: 0.033835 | loss: 1.533435
2022-07-27 20:34:30.571 | INFO     | __main__:train:118 - Epoch:  0 | Chunk: 29 | step: 1200 | mle_loss: 1.352569 | cl_loss: 0.034344 | loss: 1.524291
2022-07-27 20:34:47.811 | INFO     | processing.dataset:_load_and_cache_examples:43 - Loading examples from cache file data/cache/train_set/train_0.pkl
2022-07-27 20:34:50.214 | INFO     | __main__:train:118 - Epoch:  1 | Chunk:  0 | step:    0 | mle_loss: 1.373341 | cl_loss: 0.032539 | loss: 1.536035
2022-07-27 20:35:07.946 | INFO     | __main__:train:118 - Epoch:  1 | Chunk:  0 | step:   50 | mle_loss: 1.261434 | cl_loss: 0.032424 | loss: 1.423553
2022-07-27 20:35:26.131 | INFO     | __main__:train:118 - Epoch:  1 | Chunk:  0 | step:  100 | mle_loss: 1.288411 | cl_loss: 0.033829 | loss: 1.457556
2022-07-27 20:35:44.195 | INFO     | __main__:train:118 - Epoch:  1 | Chunk:  0 | step:  150 | mle_loss: 1.258465 | cl_loss: 0.033783 | loss: 1.427381
2022-07-27 20:36:02.598 | INFO     | __main__:train:118 - Epoch:  1 | Chunk:  0 | step:  200 | mle_loss: 1.240810 | cl_loss: 0.033613 | loss: 1.408876
2022-07-27 20:36:20.730 | INFO     | __main__:train:118 - Epoch:  1 | Chunk:  0 | step:  250 | mle_loss: 1.250329 | cl_loss: 0.032078 | loss: 1.410716
2022-07-27 20:36:38.883 | INFO     | __main__:train:118 - Epoch:  1 | Chunk:  0 | step:  300 | mle_loss: 1.250631 | cl_loss: 0.031320 | loss: 1.407231
2022-07-27 20:36:56.845 | INFO     | __main__:train:118 - Epoch:  1 | Chunk:  0 | step:  350 | mle_loss: 1.235843 | cl_loss: 0.031156 | loss: 1.391621
2022-07-27 20:37:15.011 | INFO     | __main__:train:118 - Epoch:  1 | Chunk:  0 | step:  400 | mle_loss: 1.264215 | cl_loss: 0.031225 | loss: 1.420338
2022-07-27 20:37:33.031 | INFO     | __main__:train:118 - Epoch:  1 | Chunk:  0 | step:  450 | mle_loss: 1.251136 | cl_loss: 0.032632 | loss: 1.414297
2022-07-27 20:37:50.516 | INFO     | __main__:evaluate:178 - Generating...
2022-07-27 20:39:11.475 | INFO     | __main__:evaluate:188 - Generation finished.
2022-07-27 20:39:11.475 | INFO     | __main__:evaluate:195 - Rouge scores: {'rouge-1': 0.3956, 'rouge-2': 0.2348, 'rouge-l': 0.3502}
2022-07-27 20:39:11.476 | INFO     | __main__:train:137 - Eval loss: 0.0, the best loss: {'loss': 0.0, 'epoch': 0, 'step': 749}
2022-07-27 20:39:11.476 | INFO     | __main__:train:138 - Rouge scores: {'rouge-1': 0.3956, 'rouge-2': 0.2348, 'rouge-l': 0.3502}, the best scores: {'rouge-1': 0.4145, 'rouge-2': 0.2508, 'rouge-l': 0.3637, 'epoch': 0, 'step': 749}
2022-07-27 20:39:11.476 | INFO     | __main__:train:143 - Saving model checkpoint to checkpoints/MoCoBart-1-0-499
2022-07-27 20:39:13.617 | INFO     | __main__:train:118 - Epoch:  1 | Chunk:  0 | step:  500 | mle_loss: 1.239524 | cl_loss: 0.032712 | loss: 1.403085
2022-07-27 20:39:31.505 | INFO     | __main__:train:118 - Epoch:  1 | Chunk:  0 | step:  550 | mle_loss: 1.260186 | cl_loss: 0.033081 | loss: 1.425593
2022-07-27 20:39:49.330 | INFO     | __main__:train:118 - Epoch:  1 | Chunk:  0 | step:  600 | mle_loss: 1.226213 | cl_loss: 0.033323 | loss: 1.392828
2022-07-27 20:40:07.283 | INFO     | __main__:train:118 - Epoch:  1 | Chunk:  0 | step:  650 | mle_loss: 1.255055 | cl_loss: 0.032317 | loss: 1.416638
2022-07-27 20:40:25.524 | INFO     | __main__:train:118 - Epoch:  1 | Chunk:  0 | step:  700 | mle_loss: 1.236120 | cl_loss: 0.031938 | loss: 1.395813
2022-07-27 20:40:43.810 | INFO     | __main__:train:118 - Epoch:  1 | Chunk:  0 | step:  750 | mle_loss: 1.253742 | cl_loss: 0.033677 | loss: 1.422127
2022-07-27 20:41:01.911 | INFO     | __main__:train:118 - Epoch:  1 | Chunk:  0 | step:  800 | mle_loss: 1.237496 | cl_loss: 0.032229 | loss: 1.398643
2022-07-27 20:41:19.884 | INFO     | __main__:train:118 - Epoch:  1 | Chunk:  0 | step:  850 | mle_loss: 1.233688 | cl_loss: 0.033236 | loss: 1.399870
2022-07-27 20:41:37.816 | INFO     | __main__:train:118 - Epoch:  1 | Chunk:  0 | step:  900 | mle_loss: 1.242953 | cl_loss: 0.031298 | loss: 1.399444
2022-07-27 20:41:56.053 | INFO     | __main__:train:118 - Epoch:  1 | Chunk:  0 | step:  950 | mle_loss: 1.259714 | cl_loss: 0.031188 | loss: 1.415656
2022-07-27 20:42:14.225 | INFO     | __main__:train:118 - Epoch:  1 | Chunk:  0 | step: 1000 | mle_loss: 1.241684 | cl_loss: 0.032811 | loss: 1.405741
2022-07-27 20:42:32.527 | INFO     | __main__:train:118 - Epoch:  1 | Chunk:  0 | step: 1050 | mle_loss: 1.243857 | cl_loss: 0.031238 | loss: 1.400045
2022-07-27 20:42:50.898 | INFO     | __main__:train:118 - Epoch:  1 | Chunk:  0 | step: 1100 | mle_loss: 1.238848 | cl_loss: 0.033086 | loss: 1.404278
2022-07-27 20:43:09.008 | INFO     | __main__:train:118 - Epoch:  1 | Chunk:  0 | step: 1150 | mle_loss: 1.249792 | cl_loss: 0.032498 | loss: 1.412282
2022-07-27 20:43:27.021 | INFO     | __main__:train:118 - Epoch:  1 | Chunk:  0 | step: 1200 | mle_loss: 1.244665 | cl_loss: 0.033145 | loss: 1.410392
2022-07-27 20:43:44.797 | INFO     | processing.dataset:_load_and_cache_examples:43 - Loading examples from cache file data/cache/train_set/train_1.pkl
2022-07-27 20:43:46.278 | INFO     | __main__:train:118 - Epoch:  1 | Chunk:  1 | step:    0 | mle_loss: 1.249066 | cl_loss: 0.031926 | loss: 1.408694
2022-07-27 20:44:04.089 | INFO     | __main__:train:118 - Epoch:  1 | Chunk:  1 | step:   50 | mle_loss: 1.352372 | cl_loss: 0.037503 | loss: 1.539889
2022-07-27 20:44:22.222 | INFO     | __main__:train:118 - Epoch:  1 | Chunk:  1 | step:  100 | mle_loss: 1.357689 | cl_loss: 0.039880 | loss: 1.557091
2022-07-27 20:44:40.041 | INFO     | __main__:train:118 - Epoch:  1 | Chunk:  1 | step:  150 | mle_loss: 1.363787 | cl_loss: 0.039494 | loss: 1.561258
2022-07-27 20:44:58.181 | INFO     | __main__:train:118 - Epoch:  1 | Chunk:  1 | step:  200 | mle_loss: 1.354428 | cl_loss: 0.039605 | loss: 1.552455
2022-07-27 20:45:16.090 | INFO     | __main__:train:118 - Epoch:  1 | Chunk:  1 | step:  250 | mle_loss: 1.337393 | cl_loss: 0.038947 | loss: 1.532129
2022-07-27 20:45:33.889 | INFO     | __main__:train:118 - Epoch:  1 | Chunk:  1 | step:  300 | mle_loss: 1.339162 | cl_loss: 0.037935 | loss: 1.528838
2022-07-27 20:45:51.641 | INFO     | __main__:train:118 - Epoch:  1 | Chunk:  1 | step:  350 | mle_loss: 1.333029 | cl_loss: 0.037108 | loss: 1.518567
2022-07-27 20:46:09.459 | INFO     | __main__:train:118 - Epoch:  1 | Chunk:  1 | step:  400 | mle_loss: 1.354197 | cl_loss: 0.040017 | loss: 1.554280
2022-07-27 20:46:27.127 | INFO     | __main__:train:118 - Epoch:  1 | Chunk:  1 | step:  450 | mle_loss: 1.317542 | cl_loss: 0.038432 | loss: 1.509702
2022-07-27 20:46:45.150 | INFO     | __main__:train:118 - Epoch:  1 | Chunk:  1 | step:  500 | mle_loss: 1.318647 | cl_loss: 0.037868 | loss: 1.507988
2022-07-27 20:47:03.183 | INFO     | __main__:train:118 - Epoch:  1 | Chunk:  1 | step:  550 | mle_loss: 1.313575 | cl_loss: 0.038361 | loss: 1.505381
2022-07-27 20:47:21.328 | INFO     | __main__:train:118 - Epoch:  1 | Chunk:  1 | step:  600 | mle_loss: 1.307632 | cl_loss: 0.038274 | loss: 1.499003
2022-07-27 20:47:39.393 | INFO     | __main__:train:118 - Epoch:  1 | Chunk:  1 | step:  650 | mle_loss: 1.326843 | cl_loss: 0.036703 | loss: 1.510358
2022-07-27 20:47:57.351 | INFO     | __main__:train:118 - Epoch:  1 | Chunk:  1 | step:  700 | mle_loss: 1.339092 | cl_loss: 0.036525 | loss: 1.521716
2022-07-27 20:48:15.431 | INFO     | __main__:train:118 - Epoch:  1 | Chunk:  1 | step:  750 | mle_loss: 1.333111 | cl_loss: 0.040053 | loss: 1.533377
2022-07-27 20:48:33.485 | INFO     | __main__:train:118 - Epoch:  1 | Chunk:  1 | step:  800 | mle_loss: 1.301122 | cl_loss: 0.039102 | loss: 1.496631
2022-07-27 20:48:51.319 | INFO     | __main__:train:118 - Epoch:  1 | Chunk:  1 | step:  850 | mle_loss: 1.338198 | cl_loss: 0.038316 | loss: 1.529780
2022-07-27 20:49:09.163 | INFO     | __main__:train:118 - Epoch:  1 | Chunk:  1 | step:  900 | mle_loss: 1.315278 | cl_loss: 0.036379 | loss: 1.497174
2022-07-27 20:49:27.067 | INFO     | __main__:train:118 - Epoch:  1 | Chunk:  1 | step:  950 | mle_loss: 1.303409 | cl_loss: 0.037790 | loss: 1.492357
2022-07-27 20:49:45.351 | INFO     | __main__:train:118 - Epoch:  1 | Chunk:  1 | step: 1000 | mle_loss: 1.300954 | cl_loss: 0.034735 | loss: 1.474630
2022-07-27 20:50:03.324 | INFO     | __main__:train:118 - Epoch:  1 | Chunk:  1 | step: 1050 | mle_loss: 1.320374 | cl_loss: 0.035869 | loss: 1.499719
2022-07-27 20:50:21.219 | INFO     | __main__:train:118 - Epoch:  1 | Chunk:  1 | step: 1100 | mle_loss: 1.332771 | cl_loss: 0.035279 | loss: 1.509165
2022-07-27 20:50:38.997 | INFO     | __main__:train:118 - Epoch:  1 | Chunk:  1 | step: 1150 | mle_loss: 1.328327 | cl_loss: 0.037047 | loss: 1.513563
2022-07-27 20:50:56.872 | INFO     | __main__:train:118 - Epoch:  1 | Chunk:  1 | step: 1200 | mle_loss: 1.286239 | cl_loss: 0.036029 | loss: 1.466382
2022-07-27 20:51:14.560 | INFO     | __main__:evaluate:178 - Generating...
2022-07-27 20:52:39.934 | INFO     | __main__:evaluate:188 - Generation finished.
2022-07-27 20:52:39.937 | INFO     | __main__:evaluate:195 - Rouge scores: {'rouge-1': 0.4018, 'rouge-2': 0.243, 'rouge-l': 0.3612}
2022-07-27 20:52:39.938 | INFO     | __main__:train:137 - Eval loss: 0.0, the best loss: {'loss': 0.0, 'epoch': 0, 'step': 749}
2022-07-27 20:52:39.938 | INFO     | __main__:train:138 - Rouge scores: {'rouge-1': 0.4018, 'rouge-2': 0.243, 'rouge-l': 0.3612}, the best scores: {'rouge-1': 0.4145, 'rouge-2': 0.2508, 'rouge-l': 0.3637, 'epoch': 0, 'step': 749}
2022-07-27 20:52:39.940 | INFO     | __main__:train:143 - Saving model checkpoint to checkpoints/MoCoBart-1-1-1249
2022-07-27 20:52:42.301 | INFO     | processing.dataset:_load_and_cache_examples:43 - Loading examples from cache file data/cache/train_set/train_2.pkl
2022-07-27 20:52:44.177 | INFO     | __main__:train:118 - Epoch:  1 | Chunk:  2 | step:    0 | mle_loss: 1.352163 | cl_loss: 0.036519 | loss: 1.534760
2022-07-27 20:53:02.123 | INFO     | __main__:train:118 - Epoch:  1 | Chunk:  2 | step:   50 | mle_loss: 1.361784 | cl_loss: 0.038212 | loss: 1.552842
2022-07-27 20:53:20.107 | INFO     | __main__:train:118 - Epoch:  1 | Chunk:  2 | step:  100 | mle_loss: 1.356274 | cl_loss: 0.037908 | loss: 1.545812
2022-07-27 20:53:37.993 | INFO     | __main__:train:118 - Epoch:  1 | Chunk:  2 | step:  150 | mle_loss: 1.348757 | cl_loss: 0.037865 | loss: 1.538080
2022-07-27 20:53:55.828 | INFO     | __main__:train:118 - Epoch:  1 | Chunk:  2 | step:  200 | mle_loss: 1.339113 | cl_loss: 0.039792 | loss: 1.538072
2022-07-27 20:54:13.967 | INFO     | __main__:train:118 - Epoch:  1 | Chunk:  2 | step:  250 | mle_loss: 1.330130 | cl_loss: 0.034675 | loss: 1.503505
2022-07-27 20:54:32.139 | INFO     | __main__:train:118 - Epoch:  1 | Chunk:  2 | step:  300 | mle_loss: 1.328996 | cl_loss: 0.036595 | loss: 1.511969
2022-07-27 20:54:50.161 | INFO     | __main__:train:118 - Epoch:  1 | Chunk:  2 | step:  350 | mle_loss: 1.334894 | cl_loss: 0.036869 | loss: 1.519239
2022-07-27 20:55:07.968 | INFO     | __main__:train:118 - Epoch:  1 | Chunk:  2 | step:  400 | mle_loss: 1.357409 | cl_loss: 0.036029 | loss: 1.537554
2022-07-27 20:55:25.955 | INFO     | __main__:train:118 - Epoch:  1 | Chunk:  2 | step:  450 | mle_loss: 1.321630 | cl_loss: 0.036019 | loss: 1.501724
2022-07-27 20:55:44.052 | INFO     | __main__:train:118 - Epoch:  1 | Chunk:  2 | step:  500 | mle_loss: 1.330894 | cl_loss: 0.036711 | loss: 1.514451
2022-07-27 20:56:01.845 | INFO     | __main__:train:118 - Epoch:  1 | Chunk:  2 | step:  550 | mle_loss: 1.337107 | cl_loss: 0.035525 | loss: 1.514734
2022-07-27 20:56:19.807 | INFO     | __main__:train:118 - Epoch:  1 | Chunk:  2 | step:  600 | mle_loss: 1.326184 | cl_loss: 0.036640 | loss: 1.509386
2022-07-27 20:56:37.709 | INFO     | __main__:train:118 - Epoch:  1 | Chunk:  2 | step:  650 | mle_loss: 1.350491 | cl_loss: 0.035045 | loss: 1.525716
2022-07-27 20:56:55.885 | INFO     | __main__:train:118 - Epoch:  1 | Chunk:  2 | step:  700 | mle_loss: 1.315778 | cl_loss: 0.036989 | loss: 1.500723
2022-07-27 20:57:13.916 | INFO     | __main__:train:118 - Epoch:  1 | Chunk:  2 | step:  750 | mle_loss: 1.335950 | cl_loss: 0.037204 | loss: 1.521972
2022-07-27 20:57:32.219 | INFO     | __main__:train:118 - Epoch:  1 | Chunk:  2 | step:  800 | mle_loss: 1.299676 | cl_loss: 0.038459 | loss: 1.491972
2022-07-27 20:57:50.101 | INFO     | __main__:train:118 - Epoch:  1 | Chunk:  2 | step:  850 | mle_loss: 1.298360 | cl_loss: 0.036171 | loss: 1.479217
2022-07-27 20:58:08.446 | INFO     | __main__:train:118 - Epoch:  1 | Chunk:  2 | step:  900 | mle_loss: 1.294531 | cl_loss: 0.036510 | loss: 1.477079
2022-07-27 20:58:26.533 | INFO     | __main__:train:118 - Epoch:  1 | Chunk:  2 | step:  950 | mle_loss: 1.320804 | cl_loss: 0.036080 | loss: 1.501204
2022-07-27 20:58:44.924 | INFO     | __main__:train:118 - Epoch:  1 | Chunk:  2 | step: 1000 | mle_loss: 1.295712 | cl_loss: 0.035832 | loss: 1.474874
2022-07-27 20:59:02.915 | INFO     | __main__:train:118 - Epoch:  1 | Chunk:  2 | step: 1050 | mle_loss: 1.311037 | cl_loss: 0.034416 | loss: 1.483119
2022-07-27 20:59:20.838 | INFO     | __main__:train:118 - Epoch:  1 | Chunk:  2 | step: 1100 | mle_loss: 1.322437 | cl_loss: 0.033646 | loss: 1.490665
2022-07-27 20:59:38.758 | INFO     | __main__:train:118 - Epoch:  1 | Chunk:  2 | step: 1150 | mle_loss: 1.365613 | cl_loss: 0.034986 | loss: 1.540540
2022-07-27 20:59:56.753 | INFO     | __main__:train:118 - Epoch:  1 | Chunk:  2 | step: 1200 | mle_loss: 1.307587 | cl_loss: 0.036243 | loss: 1.488803
2022-07-27 21:00:14.325 | INFO     | processing.dataset:_load_and_cache_examples:43 - Loading examples from cache file data/cache/train_set/train_3.pkl
2022-07-27 21:00:16.172 | INFO     | __main__:train:118 - Epoch:  1 | Chunk:  3 | step:    0 | mle_loss: 1.324224 | cl_loss: 0.036786 | loss: 1.508153
2022-07-27 21:00:34.087 | INFO     | __main__:train:118 - Epoch:  1 | Chunk:  3 | step:   50 | mle_loss: 1.304012 | cl_loss: 0.043677 | loss: 1.522395
2022-07-27 21:00:52.383 | INFO     | __main__:train:118 - Epoch:  1 | Chunk:  3 | step:  100 | mle_loss: 1.279909 | cl_loss: 0.041314 | loss: 1.486481
2022-07-27 21:01:10.716 | INFO     | __main__:train:118 - Epoch:  1 | Chunk:  3 | step:  150 | mle_loss: 1.252984 | cl_loss: 0.038901 | loss: 1.447491
2022-07-27 21:01:28.716 | INFO     | __main__:train:118 - Epoch:  1 | Chunk:  3 | step:  200 | mle_loss: 1.267084 | cl_loss: 0.040319 | loss: 1.468677
2022-07-27 21:01:46.645 | INFO     | __main__:train:118 - Epoch:  1 | Chunk:  3 | step:  250 | mle_loss: 1.278338 | cl_loss: 0.041438 | loss: 1.485526
2022-07-27 21:02:04.935 | INFO     | __main__:train:118 - Epoch:  1 | Chunk:  3 | step:  300 | mle_loss: 1.247471 | cl_loss: 0.042246 | loss: 1.458701
2022-07-27 21:02:23.001 | INFO     | __main__:train:118 - Epoch:  1 | Chunk:  3 | step:  350 | mle_loss: 1.275981 | cl_loss: 0.039027 | loss: 1.471115
2022-07-27 21:02:41.207 | INFO     | __main__:train:118 - Epoch:  1 | Chunk:  3 | step:  400 | mle_loss: 1.256628 | cl_loss: 0.040395 | loss: 1.458603
2022-07-27 21:02:59.457 | INFO     | __main__:train:118 - Epoch:  1 | Chunk:  3 | step:  450 | mle_loss: 1.263216 | cl_loss: 0.036542 | loss: 1.445928
2022-07-27 21:03:17.844 | INFO     | __main__:train:118 - Epoch:  1 | Chunk:  3 | step:  500 | mle_loss: 1.273967 | cl_loss: 0.038367 | loss: 1.465805
2022-07-27 21:03:36.210 | INFO     | __main__:train:118 - Epoch:  1 | Chunk:  3 | step:  550 | mle_loss: 1.257822 | cl_loss: 0.040151 | loss: 1.458578
2022-07-27 21:03:54.392 | INFO     | __main__:train:118 - Epoch:  1 | Chunk:  3 | step:  600 | mle_loss: 1.227616 | cl_loss: 0.037936 | loss: 1.417295
2022-07-27 21:04:12.625 | INFO     | __main__:train:118 - Epoch:  1 | Chunk:  3 | step:  650 | mle_loss: 1.254676 | cl_loss: 0.039093 | loss: 1.450143
2022-07-27 21:04:30.965 | INFO     | __main__:train:118 - Epoch:  1 | Chunk:  3 | step:  700 | mle_loss: 1.248424 | cl_loss: 0.039929 | loss: 1.448070
2022-07-27 21:04:48.959 | INFO     | __main__:evaluate:178 - Generating...
2022-07-27 21:06:11.867 | INFO     | __main__:evaluate:188 - Generation finished.
2022-07-27 21:06:11.868 | INFO     | __main__:evaluate:195 - Rouge scores: {'rouge-1': 0.3977, 'rouge-2': 0.2395, 'rouge-l': 0.3507}
2022-07-27 21:06:11.868 | INFO     | __main__:train:137 - Eval loss: 0.0, the best loss: {'loss': 0.0, 'epoch': 0, 'step': 749}
2022-07-27 21:06:11.868 | INFO     | __main__:train:138 - Rouge scores: {'rouge-1': 0.3977, 'rouge-2': 0.2395, 'rouge-l': 0.3507}, the best scores: {'rouge-1': 0.4145, 'rouge-2': 0.2508, 'rouge-l': 0.3637, 'epoch': 0, 'step': 749}
2022-07-27 21:06:11.869 | INFO     | __main__:train:143 - Saving model checkpoint to checkpoints/MoCoBart-1-3-749
2022-07-27 21:06:14.578 | INFO     | __main__:train:118 - Epoch:  1 | Chunk:  3 | step:  750 | mle_loss: 1.234765 | cl_loss: 0.040933 | loss: 1.439432
2022-07-27 21:06:32.786 | INFO     | __main__:train:118 - Epoch:  1 | Chunk:  3 | step:  800 | mle_loss: 1.249162 | cl_loss: 0.038443 | loss: 1.441378
2022-07-27 21:06:50.853 | INFO     | __main__:train:118 - Epoch:  1 | Chunk:  3 | step:  850 | mle_loss: 1.230658 | cl_loss: 0.041639 | loss: 1.438851
2022-07-27 21:07:09.059 | INFO     | __main__:train:118 - Epoch:  1 | Chunk:  3 | step:  900 | mle_loss: 1.244221 | cl_loss: 0.038402 | loss: 1.436231
2022-07-27 21:07:27.215 | INFO     | __main__:train:118 - Epoch:  1 | Chunk:  3 | step:  950 | mle_loss: 1.251697 | cl_loss: 0.039909 | loss: 1.451243
2022-07-27 21:07:45.554 | INFO     | __main__:train:118 - Epoch:  1 | Chunk:  3 | step: 1000 | mle_loss: 1.229554 | cl_loss: 0.038114 | loss: 1.420124
2022-07-27 21:08:03.706 | INFO     | __main__:train:118 - Epoch:  1 | Chunk:  3 | step: 1050 | mle_loss: 1.241986 | cl_loss: 0.039089 | loss: 1.437432
2022-07-27 21:08:22.216 | INFO     | __main__:train:118 - Epoch:  1 | Chunk:  3 | step: 1100 | mle_loss: 1.233071 | cl_loss: 0.037958 | loss: 1.422860
2022-07-27 21:08:40.425 | INFO     | __main__:train:118 - Epoch:  1 | Chunk:  3 | step: 1150 | mle_loss: 1.236129 | cl_loss: 0.040792 | loss: 1.440087
2022-07-27 21:08:58.978 | INFO     | __main__:train:118 - Epoch:  1 | Chunk:  3 | step: 1200 | mle_loss: 1.238971 | cl_loss: 0.038126 | loss: 1.429600
2022-07-27 21:09:17.009 | INFO     | processing.dataset:_load_and_cache_examples:43 - Loading examples from cache file data/cache/train_set/train_4.pkl
2022-07-27 21:09:19.217 | INFO     | __main__:train:118 - Epoch:  1 | Chunk:  4 | step:    0 | mle_loss: 1.231076 | cl_loss: 0.038210 | loss: 1.422125
2022-07-27 21:09:37.327 | INFO     | __main__:train:118 - Epoch:  1 | Chunk:  4 | step:   50 | mle_loss: 1.257264 | cl_loss: 0.038726 | loss: 1.450895
2022-07-27 21:09:55.138 | INFO     | __main__:train:118 - Epoch:  1 | Chunk:  4 | step:  100 | mle_loss: 1.270322 | cl_loss: 0.036188 | loss: 1.451262
2022-07-27 21:10:13.044 | INFO     | __main__:train:118 - Epoch:  1 | Chunk:  4 | step:  150 | mle_loss: 1.242367 | cl_loss: 0.036109 | loss: 1.422910
2022-07-27 21:10:31.069 | INFO     | __main__:train:118 - Epoch:  1 | Chunk:  4 | step:  200 | mle_loss: 1.235087 | cl_loss: 0.038071 | loss: 1.425443
2022-07-27 21:10:48.935 | INFO     | __main__:train:118 - Epoch:  1 | Chunk:  4 | step:  250 | mle_loss: 1.248896 | cl_loss: 0.037271 | loss: 1.435250
2022-07-27 21:11:06.981 | INFO     | __main__:train:118 - Epoch:  1 | Chunk:  4 | step:  300 | mle_loss: 1.208053 | cl_loss: 0.038559 | loss: 1.400849
2022-07-27 21:11:24.844 | INFO     | __main__:train:118 - Epoch:  1 | Chunk:  4 | step:  350 | mle_loss: 1.192706 | cl_loss: 0.035163 | loss: 1.368521
2022-07-27 21:11:42.882 | INFO     | __main__:train:118 - Epoch:  1 | Chunk:  4 | step:  400 | mle_loss: 1.198054 | cl_loss: 0.037788 | loss: 1.386994
2022-07-27 21:12:00.778 | INFO     | __main__:train:118 - Epoch:  1 | Chunk:  4 | step:  450 | mle_loss: 1.237891 | cl_loss: 0.037445 | loss: 1.425115
2022-07-27 21:12:18.964 | INFO     | __main__:train:118 - Epoch:  1 | Chunk:  4 | step:  500 | mle_loss: 1.219204 | cl_loss: 0.036483 | loss: 1.401619
2022-07-27 21:12:36.847 | INFO     | __main__:train:118 - Epoch:  1 | Chunk:  4 | step:  550 | mle_loss: 1.203428 | cl_loss: 0.034799 | loss: 1.377424
2022-07-27 21:12:54.922 | INFO     | __main__:train:118 - Epoch:  1 | Chunk:  4 | step:  600 | mle_loss: 1.226747 | cl_loss: 0.036890 | loss: 1.411196
2022-07-27 21:13:13.000 | INFO     | __main__:train:118 - Epoch:  1 | Chunk:  4 | step:  650 | mle_loss: 1.172149 | cl_loss: 0.037261 | loss: 1.358455
2022-07-27 21:13:30.905 | INFO     | __main__:train:118 - Epoch:  1 | Chunk:  4 | step:  700 | mle_loss: 1.208825 | cl_loss: 0.034657 | loss: 1.382111
2022-07-27 21:13:49.051 | INFO     | __main__:train:118 - Epoch:  1 | Chunk:  4 | step:  750 | mle_loss: 1.197241 | cl_loss: 0.034095 | loss: 1.367718
2022-07-27 21:14:07.055 | INFO     | __main__:train:118 - Epoch:  1 | Chunk:  4 | step:  800 | mle_loss: 1.187663 | cl_loss: 0.036706 | loss: 1.371195
2022-07-27 21:14:25.208 | INFO     | __main__:train:118 - Epoch:  1 | Chunk:  4 | step:  850 | mle_loss: 1.192912 | cl_loss: 0.035114 | loss: 1.368482
2022-07-27 21:14:43.022 | INFO     | __main__:train:118 - Epoch:  1 | Chunk:  4 | step:  900 | mle_loss: 1.194083 | cl_loss: 0.036210 | loss: 1.375133
2022-07-27 21:15:01.172 | INFO     | __main__:train:118 - Epoch:  1 | Chunk:  4 | step:  950 | mle_loss: 1.194116 | cl_loss: 0.037906 | loss: 1.383646
2022-07-27 21:15:21.108 | INFO     | __main__:train:118 - Epoch:  1 | Chunk:  4 | step: 1000 | mle_loss: 1.184358 | cl_loss: 0.035445 | loss: 1.361581
2022-07-27 21:15:39.023 | INFO     | __main__:train:118 - Epoch:  1 | Chunk:  4 | step: 1050 | mle_loss: 1.177154 | cl_loss: 0.037250 | loss: 1.363405
2022-07-27 21:15:56.628 | INFO     | __main__:train:118 - Epoch:  1 | Chunk:  4 | step: 1100 | mle_loss: 1.180978 | cl_loss: 0.037753 | loss: 1.369741
2022-07-27 21:16:14.436 | INFO     | __main__:train:118 - Epoch:  1 | Chunk:  4 | step: 1150 | mle_loss: 1.196011 | cl_loss: 0.036217 | loss: 1.377098
2022-07-27 21:16:32.172 | INFO     | __main__:train:118 - Epoch:  1 | Chunk:  4 | step: 1200 | mle_loss: 1.183502 | cl_loss: 0.036163 | loss: 1.364318
2022-07-27 21:16:49.732 | INFO     | processing.dataset:_load_and_cache_examples:43 - Loading examples from cache file data/cache/train_set/train_5.pkl
2022-07-27 21:16:51.667 | INFO     | __main__:train:118 - Epoch:  1 | Chunk:  5 | step:    0 | mle_loss: 1.192541 | cl_loss: 0.037245 | loss: 1.378769
2022-07-27 21:17:09.270 | INFO     | __main__:train:118 - Epoch:  1 | Chunk:  5 | step:   50 | mle_loss: 1.318455 | cl_loss: 0.032713 | loss: 1.482018
2022-07-27 21:17:27.141 | INFO     | __main__:train:118 - Epoch:  1 | Chunk:  5 | step:  100 | mle_loss: 1.347968 | cl_loss: 0.034301 | loss: 1.519472
2022-07-27 21:17:44.783 | INFO     | __main__:train:118 - Epoch:  1 | Chunk:  5 | step:  150 | mle_loss: 1.312705 | cl_loss: 0.033674 | loss: 1.481075
2022-07-27 21:18:02.619 | INFO     | __main__:train:118 - Epoch:  1 | Chunk:  5 | step:  200 | mle_loss: 1.301107 | cl_loss: 0.034777 | loss: 1.474994
2022-07-27 21:18:19.982 | INFO     | __main__:evaluate:178 - Generating...
2022-07-27 21:19:41.500 | INFO     | __main__:evaluate:188 - Generation finished.
2022-07-27 21:19:41.501 | INFO     | __main__:evaluate:195 - Rouge scores: {'rouge-1': 0.4008, 'rouge-2': 0.2457, 'rouge-l': 0.3595}
2022-07-27 21:19:41.501 | INFO     | __main__:train:137 - Eval loss: 0.0, the best loss: {'loss': 0.0, 'epoch': 0, 'step': 749}
2022-07-27 21:19:41.501 | INFO     | __main__:train:138 - Rouge scores: {'rouge-1': 0.4008, 'rouge-2': 0.2457, 'rouge-l': 0.3595}, the best scores: {'rouge-1': 0.4145, 'rouge-2': 0.2508, 'rouge-l': 0.3637, 'epoch': 0, 'step': 749}
2022-07-27 21:19:41.502 | INFO     | __main__:train:143 - Saving model checkpoint to checkpoints/MoCoBart-1-5-249
2022-07-27 21:19:44.250 | INFO     | __main__:train:118 - Epoch:  1 | Chunk:  5 | step:  250 | mle_loss: 1.283151 | cl_loss: 0.032854 | loss: 1.447423
2022-07-27 21:20:02.242 | INFO     | __main__:train:118 - Epoch:  1 | Chunk:  5 | step:  300 | mle_loss: 1.298784 | cl_loss: 0.035564 | loss: 1.476603
2022-07-27 21:20:19.923 | INFO     | __main__:train:118 - Epoch:  1 | Chunk:  5 | step:  350 | mle_loss: 1.284001 | cl_loss: 0.033942 | loss: 1.453713
2022-07-27 21:20:37.761 | INFO     | __main__:train:118 - Epoch:  1 | Chunk:  5 | step:  400 | mle_loss: 1.338139 | cl_loss: 0.034042 | loss: 1.508350
2022-07-27 21:20:55.679 | INFO     | __main__:train:118 - Epoch:  1 | Chunk:  5 | step:  450 | mle_loss: 1.305059 | cl_loss: 0.034594 | loss: 1.478029
2022-07-27 21:21:13.623 | INFO     | __main__:train:118 - Epoch:  1 | Chunk:  5 | step:  500 | mle_loss: 1.305076 | cl_loss: 0.034102 | loss: 1.475588
2022-07-27 21:21:31.532 | INFO     | __main__:train:118 - Epoch:  1 | Chunk:  5 | step:  550 | mle_loss: 1.283043 | cl_loss: 0.034785 | loss: 1.456967
2022-07-27 21:21:49.455 | INFO     | __main__:train:118 - Epoch:  1 | Chunk:  5 | step:  600 | mle_loss: 1.310386 | cl_loss: 0.034654 | loss: 1.483654
2022-07-27 21:22:07.356 | INFO     | __main__:train:118 - Epoch:  1 | Chunk:  5 | step:  650 | mle_loss: 1.280451 | cl_loss: 0.032393 | loss: 1.442414
2022-07-27 21:22:25.035 | INFO     | __main__:train:118 - Epoch:  1 | Chunk:  5 | step:  700 | mle_loss: 1.288934 | cl_loss: 0.032127 | loss: 1.449567
2022-07-27 21:22:43.025 | INFO     | __main__:train:118 - Epoch:  1 | Chunk:  5 | step:  750 | mle_loss: 1.257986 | cl_loss: 0.032686 | loss: 1.421414
2022-07-27 21:23:01.025 | INFO     | __main__:train:118 - Epoch:  1 | Chunk:  5 | step:  800 | mle_loss: 1.286734 | cl_loss: 0.034293 | loss: 1.458198
2022-07-27 21:23:18.863 | INFO     | __main__:train:118 - Epoch:  1 | Chunk:  5 | step:  850 | mle_loss: 1.306817 | cl_loss: 0.033121 | loss: 1.472423
2022-07-27 21:23:36.918 | INFO     | __main__:train:118 - Epoch:  1 | Chunk:  5 | step:  900 | mle_loss: 1.270760 | cl_loss: 0.035401 | loss: 1.447765
2022-07-27 21:23:54.722 | INFO     | __main__:train:118 - Epoch:  1 | Chunk:  5 | step:  950 | mle_loss: 1.283707 | cl_loss: 0.033665 | loss: 1.452032
2022-07-27 21:24:12.484 | INFO     | __main__:train:118 - Epoch:  1 | Chunk:  5 | step: 1000 | mle_loss: 1.279295 | cl_loss: 0.032532 | loss: 1.441955
2022-07-27 21:24:30.521 | INFO     | __main__:train:118 - Epoch:  1 | Chunk:  5 | step: 1050 | mle_loss: 1.290285 | cl_loss: 0.033144 | loss: 1.456003
2022-07-27 21:24:48.387 | INFO     | __main__:train:118 - Epoch:  1 | Chunk:  5 | step: 1100 | mle_loss: 1.274592 | cl_loss: 0.032407 | loss: 1.436625
2022-07-27 21:25:06.206 | INFO     | __main__:train:118 - Epoch:  1 | Chunk:  5 | step: 1150 | mle_loss: 1.258045 | cl_loss: 0.034061 | loss: 1.428348
2022-07-27 21:25:24.038 | INFO     | __main__:train:118 - Epoch:  1 | Chunk:  5 | step: 1200 | mle_loss: 1.282168 | cl_loss: 0.033678 | loss: 1.450557
2022-07-27 21:25:41.382 | INFO     | processing.dataset:_load_and_cache_examples:43 - Loading examples from cache file data/cache/train_set/train_6.pkl
2022-07-27 21:25:43.122 | INFO     | __main__:train:118 - Epoch:  1 | Chunk:  6 | step:    0 | mle_loss: 1.255186 | cl_loss: 0.030703 | loss: 1.408699
2022-07-27 21:26:01.108 | INFO     | __main__:train:118 - Epoch:  1 | Chunk:  6 | step:   50 | mle_loss: 1.326631 | cl_loss: 0.037122 | loss: 1.512242
2022-07-27 21:26:18.895 | INFO     | __main__:train:118 - Epoch:  1 | Chunk:  6 | step:  100 | mle_loss: 1.333843 | cl_loss: 0.036855 | loss: 1.518116
2022-07-27 21:26:36.723 | INFO     | __main__:train:118 - Epoch:  1 | Chunk:  6 | step:  150 | mle_loss: 1.331332 | cl_loss: 0.036260 | loss: 1.512633
2022-07-27 21:26:54.714 | INFO     | __main__:train:118 - Epoch:  1 | Chunk:  6 | step:  200 | mle_loss: 1.317057 | cl_loss: 0.037788 | loss: 1.505996
2022-07-27 21:27:12.548 | INFO     | __main__:train:118 - Epoch:  1 | Chunk:  6 | step:  250 | mle_loss: 1.319553 | cl_loss: 0.036341 | loss: 1.501258
2022-07-27 21:27:30.556 | INFO     | __main__:train:118 - Epoch:  1 | Chunk:  6 | step:  300 | mle_loss: 1.291938 | cl_loss: 0.035545 | loss: 1.469665
2022-07-27 21:27:48.105 | INFO     | __main__:train:118 - Epoch:  1 | Chunk:  6 | step:  350 | mle_loss: 1.291780 | cl_loss: 0.036975 | loss: 1.476654
2022-07-27 21:28:06.073 | INFO     | __main__:train:118 - Epoch:  1 | Chunk:  6 | step:  400 | mle_loss: 1.300101 | cl_loss: 0.036709 | loss: 1.483646
2022-07-27 21:28:23.761 | INFO     | __main__:train:118 - Epoch:  1 | Chunk:  6 | step:  450 | mle_loss: 1.299618 | cl_loss: 0.037777 | loss: 1.488505
2022-07-27 21:28:41.516 | INFO     | __main__:train:118 - Epoch:  1 | Chunk:  6 | step:  500 | mle_loss: 1.305820 | cl_loss: 0.036229 | loss: 1.486965
2022-07-27 21:28:59.510 | INFO     | __main__:train:118 - Epoch:  1 | Chunk:  6 | step:  550 | mle_loss: 1.302648 | cl_loss: 0.037627 | loss: 1.490784
2022-07-27 21:29:17.284 | INFO     | __main__:train:118 - Epoch:  1 | Chunk:  6 | step:  600 | mle_loss: 1.313188 | cl_loss: 0.039058 | loss: 1.508479
2022-07-27 21:29:35.031 | INFO     | __main__:train:118 - Epoch:  1 | Chunk:  6 | step:  650 | mle_loss: 1.317667 | cl_loss: 0.037653 | loss: 1.505931
2022-07-27 21:29:52.513 | INFO     | __main__:train:118 - Epoch:  1 | Chunk:  6 | step:  700 | mle_loss: 1.295761 | cl_loss: 0.035050 | loss: 1.471012
2022-07-27 21:30:10.402 | INFO     | __main__:train:118 - Epoch:  1 | Chunk:  6 | step:  750 | mle_loss: 1.308524 | cl_loss: 0.037312 | loss: 1.495086
2022-07-27 21:30:27.972 | INFO     | __main__:train:118 - Epoch:  1 | Chunk:  6 | step:  800 | mle_loss: 1.290097 | cl_loss: 0.035561 | loss: 1.467901
2022-07-27 21:30:45.755 | INFO     | __main__:train:118 - Epoch:  1 | Chunk:  6 | step:  850 | mle_loss: 1.312062 | cl_loss: 0.035446 | loss: 1.489292
2022-07-27 21:31:03.615 | INFO     | __main__:train:118 - Epoch:  1 | Chunk:  6 | step:  900 | mle_loss: 1.275996 | cl_loss: 0.033997 | loss: 1.445983
2022-07-27 21:31:21.363 | INFO     | __main__:train:118 - Epoch:  1 | Chunk:  6 | step:  950 | mle_loss: 1.308119 | cl_loss: 0.033802 | loss: 1.477130
2022-07-27 21:31:38.752 | INFO     | __main__:evaluate:178 - Generating...
2022-07-27 21:32:58.530 | INFO     | __main__:evaluate:188 - Generation finished.
2022-07-27 21:32:58.530 | INFO     | __main__:evaluate:195 - Rouge scores: {'rouge-1': 0.3915, 'rouge-2': 0.2357, 'rouge-l': 0.3488}
2022-07-27 21:32:58.530 | INFO     | __main__:train:137 - Eval loss: 0.0, the best loss: {'loss': 0.0, 'epoch': 0, 'step': 749}
2022-07-27 21:32:58.530 | INFO     | __main__:train:138 - Rouge scores: {'rouge-1': 0.3915, 'rouge-2': 0.2357, 'rouge-l': 0.3488}, the best scores: {'rouge-1': 0.4145, 'rouge-2': 0.2508, 'rouge-l': 0.3637, 'epoch': 0, 'step': 749}
2022-07-27 21:32:58.531 | INFO     | __main__:train:143 - Saving model checkpoint to checkpoints/MoCoBart-1-6-999
2022-07-27 21:33:00.965 | INFO     | __main__:train:118 - Epoch:  1 | Chunk:  6 | step: 1000 | mle_loss: 1.292822 | cl_loss: 0.037121 | loss: 1.478425
2022-07-27 21:33:18.615 | INFO     | __main__:train:118 - Epoch:  1 | Chunk:  6 | step: 1050 | mle_loss: 1.311641 | cl_loss: 0.035250 | loss: 1.487890
2022-07-27 21:33:36.270 | INFO     | __main__:train:118 - Epoch:  1 | Chunk:  6 | step: 1100 | mle_loss: 1.287140 | cl_loss: 0.036625 | loss: 1.470264
2022-07-27 21:33:53.920 | INFO     | __main__:train:118 - Epoch:  1 | Chunk:  6 | step: 1150 | mle_loss: 1.291625 | cl_loss: 0.034921 | loss: 1.466232
2022-07-27 21:34:11.651 | INFO     | __main__:train:118 - Epoch:  1 | Chunk:  6 | step: 1200 | mle_loss: 1.291650 | cl_loss: 0.035092 | loss: 1.467111
2022-07-27 21:34:29.173 | INFO     | processing.dataset:_load_and_cache_examples:43 - Loading examples from cache file data/cache/train_set/train_7.pkl
2022-07-27 21:34:30.938 | INFO     | __main__:train:118 - Epoch:  1 | Chunk:  7 | step:    0 | mle_loss: 1.281854 | cl_loss: 0.033734 | loss: 1.450525
2022-07-27 21:34:48.916 | INFO     | __main__:train:118 - Epoch:  1 | Chunk:  7 | step:   50 | mle_loss: 1.424324 | cl_loss: 0.051588 | loss: 1.682266
2022-07-27 21:35:06.561 | INFO     | __main__:train:118 - Epoch:  1 | Chunk:  7 | step:  100 | mle_loss: 1.447679 | cl_loss: 0.052031 | loss: 1.707832
2022-07-27 21:35:24.742 | INFO     | __main__:train:118 - Epoch:  1 | Chunk:  7 | step:  150 | mle_loss: 1.431479 | cl_loss: 0.050989 | loss: 1.686422
2022-07-27 21:35:42.609 | INFO     | __main__:train:118 - Epoch:  1 | Chunk:  7 | step:  200 | mle_loss: 1.432534 | cl_loss: 0.048188 | loss: 1.673473
2022-07-27 21:36:00.180 | INFO     | __main__:train:118 - Epoch:  1 | Chunk:  7 | step:  250 | mle_loss: 1.420580 | cl_loss: 0.044899 | loss: 1.645076
2022-07-27 21:36:18.240 | INFO     | __main__:train:118 - Epoch:  1 | Chunk:  7 | step:  300 | mle_loss: 1.422054 | cl_loss: 0.048157 | loss: 1.662840
2022-07-27 21:36:36.077 | INFO     | __main__:train:118 - Epoch:  1 | Chunk:  7 | step:  350 | mle_loss: 1.413236 | cl_loss: 0.045427 | loss: 1.640373
2022-07-27 21:36:53.892 | INFO     | __main__:train:118 - Epoch:  1 | Chunk:  7 | step:  400 | mle_loss: 1.406293 | cl_loss: 0.043431 | loss: 1.623450
2022-07-27 21:37:11.988 | INFO     | __main__:train:118 - Epoch:  1 | Chunk:  7 | step:  450 | mle_loss: 1.386234 | cl_loss: 0.041553 | loss: 1.593998
2022-07-27 21:37:29.883 | INFO     | __main__:train:118 - Epoch:  1 | Chunk:  7 | step:  500 | mle_loss: 1.406151 | cl_loss: 0.042117 | loss: 1.616736
2022-07-27 21:37:47.742 | INFO     | __main__:train:118 - Epoch:  1 | Chunk:  7 | step:  550 | mle_loss: 1.375842 | cl_loss: 0.039280 | loss: 1.572242
2022-07-27 21:38:05.690 | INFO     | __main__:train:118 - Epoch:  1 | Chunk:  7 | step:  600 | mle_loss: 1.407152 | cl_loss: 0.040391 | loss: 1.609106
2022-07-27 21:38:23.421 | INFO     | __main__:train:118 - Epoch:  1 | Chunk:  7 | step:  650 | mle_loss: 1.398984 | cl_loss: 0.040834 | loss: 1.603154
2022-07-27 21:38:40.941 | INFO     | __main__:train:118 - Epoch:  1 | Chunk:  7 | step:  700 | mle_loss: 1.394422 | cl_loss: 0.039496 | loss: 1.591901
2022-07-27 21:38:58.583 | INFO     | __main__:train:118 - Epoch:  1 | Chunk:  7 | step:  750 | mle_loss: 1.411986 | cl_loss: 0.038923 | loss: 1.606598
2022-07-27 21:39:16.311 | INFO     | __main__:train:118 - Epoch:  1 | Chunk:  7 | step:  800 | mle_loss: 1.354250 | cl_loss: 0.036814 | loss: 1.538321
2022-07-27 21:39:34.113 | INFO     | __main__:train:118 - Epoch:  1 | Chunk:  7 | step:  850 | mle_loss: 1.386880 | cl_loss: 0.036876 | loss: 1.571260
2022-07-27 21:39:52.015 | INFO     | __main__:train:118 - Epoch:  1 | Chunk:  7 | step:  900 | mle_loss: 1.389731 | cl_loss: 0.037594 | loss: 1.577703
2022-07-27 21:40:09.742 | INFO     | __main__:train:118 - Epoch:  1 | Chunk:  7 | step:  950 | mle_loss: 1.395616 | cl_loss: 0.036360 | loss: 1.577417
2022-07-27 21:40:27.816 | INFO     | __main__:train:118 - Epoch:  1 | Chunk:  7 | step: 1000 | mle_loss: 1.381580 | cl_loss: 0.036101 | loss: 1.562087
2022-07-27 21:40:45.853 | INFO     | __main__:train:118 - Epoch:  1 | Chunk:  7 | step: 1050 | mle_loss: 1.375602 | cl_loss: 0.034792 | loss: 1.549563
2022-07-27 21:41:03.611 | INFO     | __main__:train:118 - Epoch:  1 | Chunk:  7 | step: 1100 | mle_loss: 1.382781 | cl_loss: 0.036962 | loss: 1.567594
2022-07-27 21:41:21.498 | INFO     | __main__:train:118 - Epoch:  1 | Chunk:  7 | step: 1150 | mle_loss: 1.373424 | cl_loss: 0.034550 | loss: 1.546172
2022-07-27 21:41:39.120 | INFO     | __main__:train:118 - Epoch:  1 | Chunk:  7 | step: 1200 | mle_loss: 1.405357 | cl_loss: 0.034851 | loss: 1.579614
2022-07-27 21:41:56.158 | INFO     | processing.dataset:_load_and_cache_examples:43 - Loading examples from cache file data/cache/train_set/train_8.pkl
2022-07-27 21:41:58.109 | INFO     | __main__:train:118 - Epoch:  1 | Chunk:  8 | step:    0 | mle_loss: 1.374522 | cl_loss: 0.034433 | loss: 1.546688
2022-07-27 21:42:15.661 | INFO     | __main__:train:118 - Epoch:  1 | Chunk:  8 | step:   50 | mle_loss: 1.361080 | cl_loss: 0.032049 | loss: 1.521323
2022-07-27 21:42:33.300 | INFO     | __main__:train:118 - Epoch:  1 | Chunk:  8 | step:  100 | mle_loss: 1.365142 | cl_loss: 0.030055 | loss: 1.515417
2022-07-27 21:42:50.350 | INFO     | __main__:train:118 - Epoch:  1 | Chunk:  8 | step:  150 | mle_loss: 1.366686 | cl_loss: 0.030481 | loss: 1.519089
2022-07-27 21:43:08.136 | INFO     | __main__:train:118 - Epoch:  1 | Chunk:  8 | step:  200 | mle_loss: 1.380507 | cl_loss: 0.031476 | loss: 1.537889
2022-07-27 21:43:25.812 | INFO     | __main__:train:118 - Epoch:  1 | Chunk:  8 | step:  250 | mle_loss: 1.336523 | cl_loss: 0.030409 | loss: 1.488566
2022-07-27 21:43:43.541 | INFO     | __main__:train:118 - Epoch:  1 | Chunk:  8 | step:  300 | mle_loss: 1.337117 | cl_loss: 0.031387 | loss: 1.494051
2022-07-27 21:44:01.508 | INFO     | __main__:train:118 - Epoch:  1 | Chunk:  8 | step:  350 | mle_loss: 1.334212 | cl_loss: 0.031831 | loss: 1.493369
2022-07-27 21:44:19.149 | INFO     | __main__:train:118 - Epoch:  1 | Chunk:  8 | step:  400 | mle_loss: 1.370578 | cl_loss: 0.029552 | loss: 1.518338
2022-07-27 21:44:37.011 | INFO     | __main__:train:118 - Epoch:  1 | Chunk:  8 | step:  450 | mle_loss: 1.325025 | cl_loss: 0.030059 | loss: 1.475318
2022-07-27 21:44:54.251 | INFO     | __main__:evaluate:178 - Generating...
2022-07-27 21:46:14.771 | INFO     | __main__:evaluate:188 - Generation finished.
2022-07-27 21:46:14.772 | INFO     | __main__:evaluate:195 - Rouge scores: {'rouge-1': 0.402, 'rouge-2': 0.2436, 'rouge-l': 0.3584}
2022-07-27 21:46:14.772 | INFO     | __main__:train:137 - Eval loss: 0.0, the best loss: {'loss': 0.0, 'epoch': 0, 'step': 749}
2022-07-27 21:46:14.772 | INFO     | __main__:train:138 - Rouge scores: {'rouge-1': 0.402, 'rouge-2': 0.2436, 'rouge-l': 0.3584}, the best scores: {'rouge-1': 0.4145, 'rouge-2': 0.2508, 'rouge-l': 0.3637, 'epoch': 0, 'step': 749}
2022-07-27 21:46:14.772 | INFO     | __main__:train:143 - Saving model checkpoint to checkpoints/MoCoBart-1-8-499
2022-07-27 21:46:16.873 | INFO     | __main__:train:118 - Epoch:  1 | Chunk:  8 | step:  500 | mle_loss: 1.361606 | cl_loss: 0.030094 | loss: 1.512074
2022-07-27 21:46:34.264 | INFO     | __main__:train:118 - Epoch:  1 | Chunk:  8 | step:  550 | mle_loss: 1.341422 | cl_loss: 0.029633 | loss: 1.489586
2022-07-27 21:46:51.846 | INFO     | __main__:train:118 - Epoch:  1 | Chunk:  8 | step:  600 | mle_loss: 1.345146 | cl_loss: 0.029146 | loss: 1.490875
2022-07-27 21:47:09.615 | INFO     | __main__:train:118 - Epoch:  1 | Chunk:  8 | step:  650 | mle_loss: 1.378137 | cl_loss: 0.031728 | loss: 1.536779
2022-07-27 21:47:27.649 | INFO     | __main__:train:118 - Epoch:  1 | Chunk:  8 | step:  700 | mle_loss: 1.299865 | cl_loss: 0.030035 | loss: 1.450037
2022-07-27 21:47:45.515 | INFO     | __main__:train:118 - Epoch:  1 | Chunk:  8 | step:  750 | mle_loss: 1.329491 | cl_loss: 0.030351 | loss: 1.481248
2022-07-27 21:48:03.416 | INFO     | __main__:train:118 - Epoch:  1 | Chunk:  8 | step:  800 | mle_loss: 1.324719 | cl_loss: 0.030211 | loss: 1.475773
2022-07-27 21:48:21.390 | INFO     | __main__:train:118 - Epoch:  1 | Chunk:  8 | step:  850 | mle_loss: 1.314639 | cl_loss: 0.030240 | loss: 1.465839
2022-07-27 21:48:38.959 | INFO     | __main__:train:118 - Epoch:  1 | Chunk:  8 | step:  900 | mle_loss: 1.326867 | cl_loss: 0.031507 | loss: 1.484403
2022-07-27 21:48:56.518 | INFO     | __main__:train:118 - Epoch:  1 | Chunk:  8 | step:  950 | mle_loss: 1.334562 | cl_loss: 0.031788 | loss: 1.493500
2022-07-27 21:49:14.120 | INFO     | __main__:train:118 - Epoch:  1 | Chunk:  8 | step: 1000 | mle_loss: 1.336555 | cl_loss: 0.029517 | loss: 1.484140
2022-07-27 21:49:31.703 | INFO     | __main__:train:118 - Epoch:  1 | Chunk:  8 | step: 1050 | mle_loss: 1.331083 | cl_loss: 0.030637 | loss: 1.484268
2022-07-27 21:49:49.397 | INFO     | __main__:train:118 - Epoch:  1 | Chunk:  8 | step: 1100 | mle_loss: 1.314781 | cl_loss: 0.030482 | loss: 1.467193
2022-07-27 21:50:06.834 | INFO     | __main__:train:118 - Epoch:  1 | Chunk:  8 | step: 1150 | mle_loss: 1.344384 | cl_loss: 0.030755 | loss: 1.498161
2022-07-27 21:50:24.683 | INFO     | __main__:train:118 - Epoch:  1 | Chunk:  8 | step: 1200 | mle_loss: 1.308290 | cl_loss: 0.029883 | loss: 1.457703
2022-07-27 21:50:42.034 | INFO     | processing.dataset:_load_and_cache_examples:43 - Loading examples from cache file data/cache/train_set/train_9.pkl
2022-07-27 21:50:43.863 | INFO     | __main__:train:118 - Epoch:  1 | Chunk:  9 | step:    0 | mle_loss: 1.311474 | cl_loss: 0.029621 | loss: 1.459581
2022-07-27 21:51:01.458 | INFO     | __main__:train:118 - Epoch:  1 | Chunk:  9 | step:   50 | mle_loss: 1.313439 | cl_loss: 0.032841 | loss: 1.477641
2022-07-27 21:51:19.521 | INFO     | __main__:train:118 - Epoch:  1 | Chunk:  9 | step:  100 | mle_loss: 1.315982 | cl_loss: 0.034056 | loss: 1.486259
2022-07-27 21:51:37.144 | INFO     | __main__:train:118 - Epoch:  1 | Chunk:  9 | step:  150 | mle_loss: 1.300100 | cl_loss: 0.033012 | loss: 1.465158
2022-07-27 21:51:55.016 | INFO     | __main__:train:118 - Epoch:  1 | Chunk:  9 | step:  200 | mle_loss: 1.281542 | cl_loss: 0.032900 | loss: 1.446041
2022-07-27 21:52:12.989 | INFO     | __main__:train:118 - Epoch:  1 | Chunk:  9 | step:  250 | mle_loss: 1.307141 | cl_loss: 0.033373 | loss: 1.474008
2022-07-27 21:52:30.644 | INFO     | __main__:train:118 - Epoch:  1 | Chunk:  9 | step:  300 | mle_loss: 1.269761 | cl_loss: 0.032749 | loss: 1.433505
2022-07-27 21:52:48.635 | INFO     | __main__:train:118 - Epoch:  1 | Chunk:  9 | step:  350 | mle_loss: 1.320393 | cl_loss: 0.033770 | loss: 1.489244
2022-07-27 21:53:06.346 | INFO     | __main__:train:118 - Epoch:  1 | Chunk:  9 | step:  400 | mle_loss: 1.276420 | cl_loss: 0.033256 | loss: 1.442701
2022-07-27 21:53:24.291 | INFO     | __main__:train:118 - Epoch:  1 | Chunk:  9 | step:  450 | mle_loss: 1.275569 | cl_loss: 0.031501 | loss: 1.433075
2022-07-27 21:53:42.051 | INFO     | __main__:train:118 - Epoch:  1 | Chunk:  9 | step:  500 | mle_loss: 1.309830 | cl_loss: 0.032281 | loss: 1.471233
2022-07-27 21:53:59.500 | INFO     | __main__:train:118 - Epoch:  1 | Chunk:  9 | step:  550 | mle_loss: 1.299197 | cl_loss: 0.032516 | loss: 1.461776
2022-07-27 21:54:17.315 | INFO     | __main__:train:118 - Epoch:  1 | Chunk:  9 | step:  600 | mle_loss: 1.293192 | cl_loss: 0.032046 | loss: 1.453421
2022-07-27 21:54:35.001 | INFO     | __main__:train:118 - Epoch:  1 | Chunk:  9 | step:  650 | mle_loss: 1.295999 | cl_loss: 0.031508 | loss: 1.453539
2022-07-27 21:54:53.002 | INFO     | __main__:train:118 - Epoch:  1 | Chunk:  9 | step:  700 | mle_loss: 1.279441 | cl_loss: 0.031964 | loss: 1.439263
2022-07-27 21:55:10.849 | INFO     | __main__:train:118 - Epoch:  1 | Chunk:  9 | step:  750 | mle_loss: 1.264239 | cl_loss: 0.030479 | loss: 1.416632
2022-07-27 21:55:28.719 | INFO     | __main__:train:118 - Epoch:  1 | Chunk:  9 | step:  800 | mle_loss: 1.241893 | cl_loss: 0.031934 | loss: 1.401565
2022-07-27 21:55:46.542 | INFO     | __main__:train:118 - Epoch:  1 | Chunk:  9 | step:  850 | mle_loss: 1.299935 | cl_loss: 0.032358 | loss: 1.461724
2022-07-27 21:56:04.242 | INFO     | __main__:train:118 - Epoch:  1 | Chunk:  9 | step:  900 | mle_loss: 1.287343 | cl_loss: 0.031758 | loss: 1.446135
2022-07-27 21:56:22.424 | INFO     | __main__:train:118 - Epoch:  1 | Chunk:  9 | step:  950 | mle_loss: 1.247498 | cl_loss: 0.031222 | loss: 1.403608
2022-07-27 21:56:40.071 | INFO     | __main__:train:118 - Epoch:  1 | Chunk:  9 | step: 1000 | mle_loss: 1.274944 | cl_loss: 0.032011 | loss: 1.435000
2022-07-27 21:56:57.462 | INFO     | __main__:train:118 - Epoch:  1 | Chunk:  9 | step: 1050 | mle_loss: 1.294938 | cl_loss: 0.032309 | loss: 1.456484
2022-07-27 21:57:15.229 | INFO     | __main__:train:118 - Epoch:  1 | Chunk:  9 | step: 1100 | mle_loss: 1.259747 | cl_loss: 0.032835 | loss: 1.423923
2022-07-27 21:57:33.041 | INFO     | __main__:train:118 - Epoch:  1 | Chunk:  9 | step: 1150 | mle_loss: 1.288258 | cl_loss: 0.032381 | loss: 1.450161
2022-07-27 21:57:50.667 | INFO     | __main__:train:118 - Epoch:  1 | Chunk:  9 | step: 1200 | mle_loss: 1.290890 | cl_loss: 0.032708 | loss: 1.454432
2022-07-27 21:58:08.135 | INFO     | __main__:evaluate:178 - Generating...
2022-07-27 21:59:30.899 | INFO     | __main__:evaluate:188 - Generation finished.
2022-07-27 21:59:30.899 | INFO     | __main__:evaluate:195 - Rouge scores: {'rouge-1': 0.3994, 'rouge-2': 0.2389, 'rouge-l': 0.351}
2022-07-27 21:59:30.899 | INFO     | __main__:train:137 - Eval loss: 0.0, the best loss: {'loss': 0.0, 'epoch': 0, 'step': 749}
2022-07-27 21:59:30.900 | INFO     | __main__:train:138 - Rouge scores: {'rouge-1': 0.3994, 'rouge-2': 0.2389, 'rouge-l': 0.351}, the best scores: {'rouge-1': 0.4145, 'rouge-2': 0.2508, 'rouge-l': 0.3637, 'epoch': 0, 'step': 749}
2022-07-27 21:59:30.900 | INFO     | __main__:train:143 - Saving model checkpoint to checkpoints/MoCoBart-1-9-1249
2022-07-27 21:59:33.063 | INFO     | processing.dataset:_load_and_cache_examples:43 - Loading examples from cache file data/cache/train_set/train_10.pkl
2022-07-27 21:59:34.833 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 10 | step:    0 | mle_loss: 1.268046 | cl_loss: 0.030912 | loss: 1.422608
2022-07-27 21:59:52.643 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 10 | step:   50 | mle_loss: 1.273829 | cl_loss: 0.033977 | loss: 1.443713
2022-07-27 22:00:10.626 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 10 | step:  100 | mle_loss: 1.258450 | cl_loss: 0.037451 | loss: 1.445706
2022-07-27 22:00:28.518 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 10 | step:  150 | mle_loss: 1.269705 | cl_loss: 0.033718 | loss: 1.438296
2022-07-27 22:00:46.117 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 10 | step:  200 | mle_loss: 1.257170 | cl_loss: 0.035724 | loss: 1.435788
2022-07-27 22:01:03.832 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 10 | step:  250 | mle_loss: 1.270362 | cl_loss: 0.033285 | loss: 1.436788
2022-07-27 22:01:21.515 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 10 | step:  300 | mle_loss: 1.248095 | cl_loss: 0.034966 | loss: 1.422923
2022-07-27 22:01:39.228 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 10 | step:  350 | mle_loss: 1.224828 | cl_loss: 0.035856 | loss: 1.404110
2022-07-27 22:01:56.656 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 10 | step:  400 | mle_loss: 1.232461 | cl_loss: 0.036651 | loss: 1.415713
2022-07-27 22:02:14.270 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 10 | step:  450 | mle_loss: 1.233505 | cl_loss: 0.036199 | loss: 1.414502
2022-07-27 22:02:32.275 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 10 | step:  500 | mle_loss: 1.214726 | cl_loss: 0.036180 | loss: 1.395624
2022-07-27 22:02:50.057 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 10 | step:  550 | mle_loss: 1.244186 | cl_loss: 0.033576 | loss: 1.412067
2022-07-27 22:03:07.669 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 10 | step:  600 | mle_loss: 1.257796 | cl_loss: 0.034180 | loss: 1.428696
2022-07-27 22:03:25.397 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 10 | step:  650 | mle_loss: 1.257991 | cl_loss: 0.035581 | loss: 1.435896
2022-07-27 22:03:43.211 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 10 | step:  700 | mle_loss: 1.262053 | cl_loss: 0.032353 | loss: 1.423819
2022-07-27 22:04:01.026 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 10 | step:  750 | mle_loss: 1.242256 | cl_loss: 0.034295 | loss: 1.413731
2022-07-27 22:04:18.941 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 10 | step:  800 | mle_loss: 1.224487 | cl_loss: 0.034659 | loss: 1.397784
2022-07-27 22:04:36.755 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 10 | step:  850 | mle_loss: 1.207250 | cl_loss: 0.034917 | loss: 1.381835
2022-07-27 22:04:54.559 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 10 | step:  900 | mle_loss: 1.220500 | cl_loss: 0.036503 | loss: 1.403015
2022-07-27 22:05:12.321 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 10 | step:  950 | mle_loss: 1.258788 | cl_loss: 0.033210 | loss: 1.424836
2022-07-27 22:05:30.196 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 10 | step: 1000 | mle_loss: 1.239420 | cl_loss: 0.034668 | loss: 1.412760
2022-07-27 22:05:48.065 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 10 | step: 1050 | mle_loss: 1.253091 | cl_loss: 0.032096 | loss: 1.413569
2022-07-27 22:06:05.741 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 10 | step: 1100 | mle_loss: 1.211313 | cl_loss: 0.036047 | loss: 1.391548
2022-07-27 22:06:23.449 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 10 | step: 1150 | mle_loss: 1.210038 | cl_loss: 0.034010 | loss: 1.380088
2022-07-27 22:06:41.230 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 10 | step: 1200 | mle_loss: 1.243359 | cl_loss: 0.034581 | loss: 1.416262
2022-07-27 22:06:58.796 | INFO     | processing.dataset:_load_and_cache_examples:43 - Loading examples from cache file data/cache/train_set/train_11.pkl
2022-07-27 22:07:00.654 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 11 | step:    0 | mle_loss: 1.235681 | cl_loss: 0.035236 | loss: 1.411862
2022-07-27 22:07:18.695 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 11 | step:   50 | mle_loss: 1.254967 | cl_loss: 0.032078 | loss: 1.415358
2022-07-27 22:07:36.614 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 11 | step:  100 | mle_loss: 1.251215 | cl_loss: 0.031133 | loss: 1.406878
2022-07-27 22:07:54.480 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 11 | step:  150 | mle_loss: 1.285623 | cl_loss: 0.031930 | loss: 1.445273
2022-07-27 22:08:12.434 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 11 | step:  200 | mle_loss: 1.234492 | cl_loss: 0.031316 | loss: 1.391074
2022-07-27 22:08:30.609 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 11 | step:  250 | mle_loss: 1.258952 | cl_loss: 0.032446 | loss: 1.421184
2022-07-27 22:08:48.448 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 11 | step:  300 | mle_loss: 1.243872 | cl_loss: 0.031746 | loss: 1.402600
2022-07-27 22:09:06.217 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 11 | step:  350 | mle_loss: 1.262191 | cl_loss: 0.031343 | loss: 1.418907
2022-07-27 22:09:23.982 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 11 | step:  400 | mle_loss: 1.263781 | cl_loss: 0.031307 | loss: 1.420316
2022-07-27 22:09:41.994 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 11 | step:  450 | mle_loss: 1.265741 | cl_loss: 0.032422 | loss: 1.427848
2022-07-27 22:09:59.837 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 11 | step:  500 | mle_loss: 1.254035 | cl_loss: 0.032286 | loss: 1.415464
2022-07-27 22:10:17.892 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 11 | step:  550 | mle_loss: 1.236816 | cl_loss: 0.032241 | loss: 1.398019
2022-07-27 22:10:36.011 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 11 | step:  600 | mle_loss: 1.224702 | cl_loss: 0.031141 | loss: 1.380406
2022-07-27 22:10:54.151 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 11 | step:  650 | mle_loss: 1.240259 | cl_loss: 0.032141 | loss: 1.400966
2022-07-27 22:11:12.203 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 11 | step:  700 | mle_loss: 1.216416 | cl_loss: 0.029436 | loss: 1.363594
2022-07-27 22:11:29.719 | INFO     | __main__:evaluate:178 - Generating...
2022-07-27 22:12:51.636 | INFO     | __main__:evaluate:188 - Generation finished.
2022-07-27 22:12:51.636 | INFO     | __main__:evaluate:195 - Rouge scores: {'rouge-1': 0.4046, 'rouge-2': 0.2426, 'rouge-l': 0.3605}
2022-07-27 22:12:51.637 | INFO     | __main__:train:137 - Eval loss: 0.0, the best loss: {'loss': 0.0, 'epoch': 0, 'step': 749}
2022-07-27 22:12:51.637 | INFO     | __main__:train:138 - Rouge scores: {'rouge-1': 0.4046, 'rouge-2': 0.2426, 'rouge-l': 0.3605}, the best scores: {'rouge-1': 0.4145, 'rouge-2': 0.2508, 'rouge-l': 0.3637, 'epoch': 0, 'step': 749}
2022-07-27 22:12:51.637 | INFO     | __main__:train:143 - Saving model checkpoint to checkpoints/MoCoBart-1-11-749
2022-07-27 22:12:53.766 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 11 | step:  750 | mle_loss: 1.221763 | cl_loss: 0.031977 | loss: 1.381646
2022-07-27 22:13:11.707 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 11 | step:  800 | mle_loss: 1.226568 | cl_loss: 0.033542 | loss: 1.394280
2022-07-27 22:13:29.390 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 11 | step:  850 | mle_loss: 1.244522 | cl_loss: 0.032432 | loss: 1.406681
2022-07-27 22:13:47.430 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 11 | step:  900 | mle_loss: 1.197887 | cl_loss: 0.030597 | loss: 1.350870
2022-07-27 22:14:05.448 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 11 | step:  950 | mle_loss: 1.205503 | cl_loss: 0.030799 | loss: 1.359497
2022-07-27 22:14:23.280 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 11 | step: 1000 | mle_loss: 1.242867 | cl_loss: 0.031637 | loss: 1.401053
2022-07-27 22:14:41.252 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 11 | step: 1050 | mle_loss: 1.224788 | cl_loss: 0.031506 | loss: 1.382319
2022-07-27 22:14:59.407 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 11 | step: 1100 | mle_loss: 1.233442 | cl_loss: 0.033919 | loss: 1.403038
2022-07-27 22:15:17.485 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 11 | step: 1150 | mle_loss: 1.235313 | cl_loss: 0.029893 | loss: 1.384778
2022-07-27 22:15:35.482 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 11 | step: 1200 | mle_loss: 1.188200 | cl_loss: 0.030430 | loss: 1.340351
2022-07-27 22:15:53.362 | INFO     | processing.dataset:_load_and_cache_examples:43 - Loading examples from cache file data/cache/train_set/train_12.pkl
2022-07-27 22:15:55.638 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 12 | step:    0 | mle_loss: 1.231648 | cl_loss: 0.031104 | loss: 1.387169
2022-07-27 22:16:13.561 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 12 | step:   50 | mle_loss: 1.322975 | cl_loss: 0.033649 | loss: 1.491220
2022-07-27 22:16:31.355 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 12 | step:  100 | mle_loss: 1.314087 | cl_loss: 0.036509 | loss: 1.496633
2022-07-27 22:16:49.090 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 12 | step:  150 | mle_loss: 1.246910 | cl_loss: 0.038130 | loss: 1.437559
2022-07-27 22:17:06.910 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 12 | step:  200 | mle_loss: 1.274124 | cl_loss: 0.035006 | loss: 1.449155
2022-07-27 22:17:24.783 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 12 | step:  250 | mle_loss: 1.255219 | cl_loss: 0.033970 | loss: 1.425067
2022-07-27 22:17:42.464 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 12 | step:  300 | mle_loss: 1.255917 | cl_loss: 0.033791 | loss: 1.424870
2022-07-27 22:18:00.429 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 12 | step:  350 | mle_loss: 1.300421 | cl_loss: 0.033611 | loss: 1.468477
2022-07-27 22:18:17.975 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 12 | step:  400 | mle_loss: 1.291699 | cl_loss: 0.034510 | loss: 1.464248
2022-07-27 22:18:35.753 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 12 | step:  450 | mle_loss: 1.271270 | cl_loss: 0.036645 | loss: 1.454497
2022-07-27 22:18:53.511 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 12 | step:  500 | mle_loss: 1.272233 | cl_loss: 0.033854 | loss: 1.441502
2022-07-27 22:19:11.379 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 12 | step:  550 | mle_loss: 1.247031 | cl_loss: 0.034451 | loss: 1.419288
2022-07-27 22:19:29.323 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 12 | step:  600 | mle_loss: 1.288025 | cl_loss: 0.034403 | loss: 1.460038
2022-07-27 22:19:46.948 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 12 | step:  650 | mle_loss: 1.242195 | cl_loss: 0.034815 | loss: 1.416268
2022-07-27 22:20:04.512 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 12 | step:  700 | mle_loss: 1.260693 | cl_loss: 0.032774 | loss: 1.424564
2022-07-27 22:20:22.352 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 12 | step:  750 | mle_loss: 1.261838 | cl_loss: 0.032880 | loss: 1.426238
2022-07-27 22:20:40.261 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 12 | step:  800 | mle_loss: 1.224380 | cl_loss: 0.033398 | loss: 1.391370
2022-07-27 22:20:57.731 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 12 | step:  850 | mle_loss: 1.289086 | cl_loss: 0.035523 | loss: 1.466700
2022-07-27 22:21:15.165 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 12 | step:  900 | mle_loss: 1.240235 | cl_loss: 0.034583 | loss: 1.413150
2022-07-27 22:21:32.580 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 12 | step:  950 | mle_loss: 1.242928 | cl_loss: 0.034027 | loss: 1.413062
2022-07-27 22:21:50.292 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 12 | step: 1000 | mle_loss: 1.257566 | cl_loss: 0.034190 | loss: 1.428517
2022-07-27 22:22:07.980 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 12 | step: 1050 | mle_loss: 1.223338 | cl_loss: 0.032505 | loss: 1.385863
2022-07-27 22:22:25.914 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 12 | step: 1100 | mle_loss: 1.236112 | cl_loss: 0.033586 | loss: 1.404041
2022-07-27 22:22:43.680 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 12 | step: 1150 | mle_loss: 1.282749 | cl_loss: 0.032703 | loss: 1.446265
2022-07-27 22:23:01.499 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 12 | step: 1200 | mle_loss: 1.258421 | cl_loss: 0.034170 | loss: 1.429269
2022-07-27 22:23:18.992 | INFO     | processing.dataset:_load_and_cache_examples:43 - Loading examples from cache file data/cache/train_set/train_13.pkl
2022-07-27 22:23:21.246 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 13 | step:    0 | mle_loss: 1.238355 | cl_loss: 0.031547 | loss: 1.396089
2022-07-27 22:23:39.200 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 13 | step:   50 | mle_loss: 1.326763 | cl_loss: 0.038669 | loss: 1.520109
2022-07-27 22:23:57.090 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 13 | step:  100 | mle_loss: 1.324016 | cl_loss: 0.038308 | loss: 1.515553
2022-07-27 22:24:15.044 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 13 | step:  150 | mle_loss: 1.333358 | cl_loss: 0.039414 | loss: 1.530425
2022-07-27 22:24:33.076 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 13 | step:  200 | mle_loss: 1.286205 | cl_loss: 0.042240 | loss: 1.497407
2022-07-27 22:24:50.548 | INFO     | __main__:evaluate:178 - Generating...
2022-07-27 22:26:13.639 | INFO     | __main__:evaluate:188 - Generation finished.
2022-07-27 22:26:13.640 | INFO     | __main__:evaluate:195 - Rouge scores: {'rouge-1': 0.411, 'rouge-2': 0.2525, 'rouge-l': 0.3657}
2022-07-27 22:26:13.640 | INFO     | __main__:train:137 - Eval loss: 0.0, the best loss: {'loss': 0.0, 'epoch': 0, 'step': 749}
2022-07-27 22:26:13.640 | INFO     | __main__:train:138 - Rouge scores: {'rouge-1': 0.411, 'rouge-2': 0.2525, 'rouge-l': 0.3657}, the best scores: {'rouge-1': 0.4145, 'rouge-2': 0.2508, 'rouge-l': 0.3637, 'epoch': 0, 'step': 749}
2022-07-27 22:26:13.641 | INFO     | __main__:train:143 - Saving model checkpoint to checkpoints/MoCoBart-1-13-249
2022-07-27 22:26:15.621 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 13 | step:  250 | mle_loss: 1.301680 | cl_loss: 0.035364 | loss: 1.478501
2022-07-27 22:26:33.564 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 13 | step:  300 | mle_loss: 1.295183 | cl_loss: 0.038580 | loss: 1.488081
2022-07-27 22:26:51.482 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 13 | step:  350 | mle_loss: 1.307474 | cl_loss: 0.038003 | loss: 1.497490
2022-07-27 22:27:09.690 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 13 | step:  400 | mle_loss: 1.313853 | cl_loss: 0.036791 | loss: 1.497807
2022-07-27 22:27:27.838 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 13 | step:  450 | mle_loss: 1.299342 | cl_loss: 0.036262 | loss: 1.480653
2022-07-27 22:27:46.096 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 13 | step:  500 | mle_loss: 1.294499 | cl_loss: 0.041241 | loss: 1.500706
2022-07-27 22:28:04.104 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 13 | step:  550 | mle_loss: 1.274631 | cl_loss: 0.041545 | loss: 1.482355
2022-07-27 22:28:21.999 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 13 | step:  600 | mle_loss: 1.317888 | cl_loss: 0.036344 | loss: 1.499608
2022-07-27 22:28:39.640 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 13 | step:  650 | mle_loss: 1.309823 | cl_loss: 0.040127 | loss: 1.510458
2022-07-27 22:28:57.634 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 13 | step:  700 | mle_loss: 1.273077 | cl_loss: 0.037730 | loss: 1.461725
2022-07-27 22:29:15.710 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 13 | step:  750 | mle_loss: 1.287142 | cl_loss: 0.035135 | loss: 1.462815
2022-07-27 22:29:33.876 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 13 | step:  800 | mle_loss: 1.300745 | cl_loss: 0.037141 | loss: 1.486450
2022-07-27 22:29:52.081 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 13 | step:  850 | mle_loss: 1.260878 | cl_loss: 0.035786 | loss: 1.439807
2022-07-27 22:30:10.351 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 13 | step:  900 | mle_loss: 1.264735 | cl_loss: 0.038387 | loss: 1.456669
2022-07-27 22:30:28.252 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 13 | step:  950 | mle_loss: 1.286844 | cl_loss: 0.037914 | loss: 1.476416
2022-07-27 22:30:46.367 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 13 | step: 1000 | mle_loss: 1.273082 | cl_loss: 0.038416 | loss: 1.465161
2022-07-27 22:31:04.337 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 13 | step: 1050 | mle_loss: 1.263879 | cl_loss: 0.038032 | loss: 1.454040
2022-07-27 22:31:22.464 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 13 | step: 1100 | mle_loss: 1.282783 | cl_loss: 0.042750 | loss: 1.496534
2022-07-27 22:31:40.634 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 13 | step: 1150 | mle_loss: 1.247904 | cl_loss: 0.039681 | loss: 1.446309
2022-07-27 22:31:58.856 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 13 | step: 1200 | mle_loss: 1.301897 | cl_loss: 0.038918 | loss: 1.496485
2022-07-27 22:32:16.803 | INFO     | processing.dataset:_load_and_cache_examples:43 - Loading examples from cache file data/cache/train_set/train_14.pkl
2022-07-27 22:32:18.255 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 14 | step:    0 | mle_loss: 1.280399 | cl_loss: 0.037550 | loss: 1.468148
2022-07-27 22:32:36.142 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 14 | step:   50 | mle_loss: 1.328327 | cl_loss: 0.031741 | loss: 1.487032
2022-07-27 22:32:53.988 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 14 | step:  100 | mle_loss: 1.314494 | cl_loss: 0.030056 | loss: 1.464774
2022-07-27 22:33:11.820 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 14 | step:  150 | mle_loss: 1.317846 | cl_loss: 0.030009 | loss: 1.467890
2022-07-27 22:33:29.938 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 14 | step:  200 | mle_loss: 1.295479 | cl_loss: 0.029447 | loss: 1.442716
2022-07-27 22:33:47.768 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 14 | step:  250 | mle_loss: 1.287053 | cl_loss: 0.028668 | loss: 1.430395
2022-07-27 22:34:05.735 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 14 | step:  300 | mle_loss: 1.271736 | cl_loss: 0.029856 | loss: 1.421016
2022-07-27 22:34:23.308 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 14 | step:  350 | mle_loss: 1.297180 | cl_loss: 0.030247 | loss: 1.448416
2022-07-27 22:34:40.988 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 14 | step:  400 | mle_loss: 1.300585 | cl_loss: 0.030370 | loss: 1.452433
2022-07-27 22:34:58.434 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 14 | step:  450 | mle_loss: 1.284028 | cl_loss: 0.028294 | loss: 1.425501
2022-07-27 22:35:16.092 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 14 | step:  500 | mle_loss: 1.292136 | cl_loss: 0.029811 | loss: 1.441189
2022-07-27 22:35:34.318 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 14 | step:  550 | mle_loss: 1.275271 | cl_loss: 0.029902 | loss: 1.424780
2022-07-27 22:35:52.114 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 14 | step:  600 | mle_loss: 1.283220 | cl_loss: 0.030945 | loss: 1.437948
2022-07-27 22:36:09.763 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 14 | step:  650 | mle_loss: 1.287335 | cl_loss: 0.031165 | loss: 1.443158
2022-07-27 22:36:27.514 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 14 | step:  700 | mle_loss: 1.291094 | cl_loss: 0.029021 | loss: 1.436200
2022-07-27 22:36:45.326 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 14 | step:  750 | mle_loss: 1.287989 | cl_loss: 0.029942 | loss: 1.437701
2022-07-27 22:37:03.272 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 14 | step:  800 | mle_loss: 1.289494 | cl_loss: 0.030879 | loss: 1.443888
2022-07-27 22:37:21.234 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 14 | step:  850 | mle_loss: 1.263115 | cl_loss: 0.030219 | loss: 1.414209
2022-07-27 22:37:39.100 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 14 | step:  900 | mle_loss: 1.282459 | cl_loss: 0.030124 | loss: 1.433078
2022-07-27 22:37:57.129 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 14 | step:  950 | mle_loss: 1.261556 | cl_loss: 0.029618 | loss: 1.409645
2022-07-27 22:38:14.440 | INFO     | __main__:evaluate:178 - Generating...
2022-07-27 22:39:37.892 | INFO     | __main__:evaluate:188 - Generation finished.
2022-07-27 22:39:37.893 | INFO     | __main__:evaluate:195 - Rouge scores: {'rouge-1': 0.3999, 'rouge-2': 0.2392, 'rouge-l': 0.3571}
2022-07-27 22:39:37.893 | INFO     | __main__:train:137 - Eval loss: 0.0, the best loss: {'loss': 0.0, 'epoch': 0, 'step': 749}
2022-07-27 22:39:37.893 | INFO     | __main__:train:138 - Rouge scores: {'rouge-1': 0.3999, 'rouge-2': 0.2392, 'rouge-l': 0.3571}, the best scores: {'rouge-1': 0.4145, 'rouge-2': 0.2508, 'rouge-l': 0.3637, 'epoch': 0, 'step': 749}
2022-07-27 22:39:37.894 | INFO     | __main__:train:143 - Saving model checkpoint to checkpoints/MoCoBart-1-14-999
2022-07-27 22:39:40.381 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 14 | step: 1000 | mle_loss: 1.270255 | cl_loss: 0.029355 | loss: 1.417031
2022-07-27 22:39:58.367 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 14 | step: 1050 | mle_loss: 1.265409 | cl_loss: 0.028879 | loss: 1.409802
2022-07-27 22:40:16.118 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 14 | step: 1100 | mle_loss: 1.274644 | cl_loss: 0.029751 | loss: 1.423398
2022-07-27 22:40:33.745 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 14 | step: 1150 | mle_loss: 1.280744 | cl_loss: 0.029896 | loss: 1.430226
2022-07-27 22:40:51.579 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 14 | step: 1200 | mle_loss: 1.263414 | cl_loss: 0.029131 | loss: 1.409070
2022-07-27 22:41:09.257 | INFO     | processing.dataset:_load_and_cache_examples:43 - Loading examples from cache file data/cache/train_set/train_15.pkl
2022-07-27 22:41:11.119 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 15 | step:    0 | mle_loss: 1.271474 | cl_loss: 0.029114 | loss: 1.417046
2022-07-27 22:41:28.968 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 15 | step:   50 | mle_loss: 1.216200 | cl_loss: 0.031230 | loss: 1.372352
2022-07-27 22:41:47.120 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 15 | step:  100 | mle_loss: 1.207461 | cl_loss: 0.030689 | loss: 1.360907
2022-07-27 22:42:05.235 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 15 | step:  150 | mle_loss: 1.187463 | cl_loss: 0.030991 | loss: 1.342416
2022-07-27 22:42:23.261 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 15 | step:  200 | mle_loss: 1.206254 | cl_loss: 0.029640 | loss: 1.354452
2022-07-27 22:42:40.958 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 15 | step:  250 | mle_loss: 1.199838 | cl_loss: 0.030559 | loss: 1.352632
2022-07-27 22:42:58.920 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 15 | step:  300 | mle_loss: 1.227336 | cl_loss: 0.029422 | loss: 1.374447
2022-07-27 22:43:17.051 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 15 | step:  350 | mle_loss: 1.198573 | cl_loss: 0.030722 | loss: 1.352184
2022-07-27 22:43:34.925 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 15 | step:  400 | mle_loss: 1.181990 | cl_loss: 0.028362 | loss: 1.323801
2022-07-27 22:43:52.701 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 15 | step:  450 | mle_loss: 1.226226 | cl_loss: 0.029332 | loss: 1.372888
2022-07-27 22:44:10.311 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 15 | step:  500 | mle_loss: 1.219472 | cl_loss: 0.028995 | loss: 1.364444
2022-07-27 22:44:28.344 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 15 | step:  550 | mle_loss: 1.206831 | cl_loss: 0.028226 | loss: 1.347963
2022-07-27 22:44:46.366 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 15 | step:  600 | mle_loss: 1.222082 | cl_loss: 0.029327 | loss: 1.368716
2022-07-27 22:45:04.084 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 15 | step:  650 | mle_loss: 1.196247 | cl_loss: 0.028334 | loss: 1.337917
2022-07-27 22:45:21.824 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 15 | step:  700 | mle_loss: 1.203622 | cl_loss: 0.028420 | loss: 1.345721
2022-07-27 22:45:39.634 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 15 | step:  750 | mle_loss: 1.219115 | cl_loss: 0.029676 | loss: 1.367494
2022-07-27 22:45:57.660 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 15 | step:  800 | mle_loss: 1.212849 | cl_loss: 0.029303 | loss: 1.359365
2022-07-27 22:46:15.250 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 15 | step:  850 | mle_loss: 1.203381 | cl_loss: 0.029469 | loss: 1.350728
2022-07-27 22:46:33.115 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 15 | step:  900 | mle_loss: 1.189355 | cl_loss: 0.028450 | loss: 1.331608
2022-07-27 22:46:50.963 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 15 | step:  950 | mle_loss: 1.180593 | cl_loss: 0.028164 | loss: 1.321411
2022-07-27 22:47:08.733 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 15 | step: 1000 | mle_loss: 1.190853 | cl_loss: 0.029474 | loss: 1.338221
2022-07-27 22:47:26.631 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 15 | step: 1050 | mle_loss: 1.186857 | cl_loss: 0.028714 | loss: 1.330430
2022-07-27 22:47:44.688 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 15 | step: 1100 | mle_loss: 1.174944 | cl_loss: 0.029024 | loss: 1.320062
2022-07-27 22:48:02.223 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 15 | step: 1150 | mle_loss: 1.194450 | cl_loss: 0.028876 | loss: 1.338831
2022-07-27 22:48:19.945 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 15 | step: 1200 | mle_loss: 1.185977 | cl_loss: 0.028788 | loss: 1.329918
2022-07-27 22:48:37.440 | INFO     | processing.dataset:_load_and_cache_examples:43 - Loading examples from cache file data/cache/train_set/train_16.pkl
2022-07-27 22:48:39.650 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 16 | step:    0 | mle_loss: 1.172953 | cl_loss: 0.028542 | loss: 1.315664
2022-07-27 22:48:57.322 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 16 | step:   50 | mle_loss: 1.286245 | cl_loss: 0.029940 | loss: 1.435946
2022-07-27 22:49:15.312 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 16 | step:  100 | mle_loss: 1.269663 | cl_loss: 0.032465 | loss: 1.431985
2022-07-27 22:49:33.103 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 16 | step:  150 | mle_loss: 1.255903 | cl_loss: 0.029618 | loss: 1.403994
2022-07-27 22:49:51.011 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 16 | step:  200 | mle_loss: 1.239794 | cl_loss: 0.030453 | loss: 1.392059
2022-07-27 22:50:09.086 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 16 | step:  250 | mle_loss: 1.222898 | cl_loss: 0.032744 | loss: 1.386617
2022-07-27 22:50:27.006 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 16 | step:  300 | mle_loss: 1.222903 | cl_loss: 0.029910 | loss: 1.372456
2022-07-27 22:50:45.006 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 16 | step:  350 | mle_loss: 1.245732 | cl_loss: 0.031346 | loss: 1.402460
2022-07-27 22:51:03.013 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 16 | step:  400 | mle_loss: 1.231192 | cl_loss: 0.029909 | loss: 1.380735
2022-07-27 22:51:20.865 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 16 | step:  450 | mle_loss: 1.255088 | cl_loss: 0.030219 | loss: 1.406184
2022-07-27 22:51:38.394 | INFO     | __main__:evaluate:178 - Generating...
2022-07-27 22:53:03.156 | INFO     | __main__:evaluate:188 - Generation finished.
2022-07-27 22:53:03.156 | INFO     | __main__:evaluate:195 - Rouge scores: {'rouge-1': 0.4114, 'rouge-2': 0.2472, 'rouge-l': 0.3651}
2022-07-27 22:53:03.156 | INFO     | __main__:train:137 - Eval loss: 0.0, the best loss: {'loss': 0.0, 'epoch': 0, 'step': 749}
2022-07-27 22:53:03.156 | INFO     | __main__:train:138 - Rouge scores: {'rouge-1': 0.4114, 'rouge-2': 0.2472, 'rouge-l': 0.3651}, the best scores: {'rouge-1': 0.4145, 'rouge-2': 0.2508, 'rouge-l': 0.3637, 'epoch': 0, 'step': 749}
2022-07-27 22:53:03.157 | INFO     | __main__:train:143 - Saving model checkpoint to checkpoints/MoCoBart-1-16-499
2022-07-27 22:53:05.947 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 16 | step:  500 | mle_loss: 1.222212 | cl_loss: 0.029551 | loss: 1.369967
2022-07-27 22:53:23.722 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 16 | step:  550 | mle_loss: 1.246099 | cl_loss: 0.028832 | loss: 1.390259
2022-07-27 22:53:41.834 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 16 | step:  600 | mle_loss: 1.228136 | cl_loss: 0.030569 | loss: 1.380979
2022-07-27 22:53:59.743 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 16 | step:  650 | mle_loss: 1.220049 | cl_loss: 0.032089 | loss: 1.380494
2022-07-27 22:54:17.392 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 16 | step:  700 | mle_loss: 1.252222 | cl_loss: 0.031600 | loss: 1.410223
2022-07-27 22:54:35.427 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 16 | step:  750 | mle_loss: 1.215734 | cl_loss: 0.031744 | loss: 1.374456
2022-07-27 22:54:53.441 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 16 | step:  800 | mle_loss: 1.199472 | cl_loss: 0.030068 | loss: 1.349813
2022-07-27 22:55:11.392 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 16 | step:  850 | mle_loss: 1.194680 | cl_loss: 0.030907 | loss: 1.349216
2022-07-27 22:55:29.262 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 16 | step:  900 | mle_loss: 1.202091 | cl_loss: 0.031397 | loss: 1.359077
2022-07-27 22:55:47.088 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 16 | step:  950 | mle_loss: 1.212824 | cl_loss: 0.030289 | loss: 1.364269
2022-07-27 22:56:04.562 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 16 | step: 1000 | mle_loss: 1.228832 | cl_loss: 0.028976 | loss: 1.373712
2022-07-27 22:56:22.231 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 16 | step: 1050 | mle_loss: 1.220306 | cl_loss: 0.029480 | loss: 1.367706
2022-07-27 22:56:40.435 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 16 | step: 1100 | mle_loss: 1.209587 | cl_loss: 0.031187 | loss: 1.365523
2022-07-27 22:56:58.537 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 16 | step: 1150 | mle_loss: 1.228669 | cl_loss: 0.030254 | loss: 1.379939
2022-07-27 22:57:16.561 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 16 | step: 1200 | mle_loss: 1.217813 | cl_loss: 0.029060 | loss: 1.363116
2022-07-27 22:57:34.168 | INFO     | processing.dataset:_load_and_cache_examples:43 - Loading examples from cache file data/cache/train_set/train_17.pkl
2022-07-27 22:57:36.280 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 17 | step:    0 | mle_loss: 1.207040 | cl_loss: 0.028508 | loss: 1.349580
2022-07-27 22:57:54.084 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 17 | step:   50 | mle_loss: 1.324414 | cl_loss: 0.032944 | loss: 1.489134
2022-07-27 22:58:12.292 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 17 | step:  100 | mle_loss: 1.291975 | cl_loss: 0.034776 | loss: 1.465854
2022-07-27 22:58:30.494 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 17 | step:  150 | mle_loss: 1.290651 | cl_loss: 0.038522 | loss: 1.483259
2022-07-27 22:58:48.774 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 17 | step:  200 | mle_loss: 1.277904 | cl_loss: 0.032696 | loss: 1.441385
2022-07-27 22:59:06.849 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 17 | step:  250 | mle_loss: 1.288099 | cl_loss: 0.035218 | loss: 1.464190
2022-07-27 22:59:25.010 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 17 | step:  300 | mle_loss: 1.298264 | cl_loss: 0.032550 | loss: 1.461014
2022-07-27 22:59:43.193 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 17 | step:  350 | mle_loss: 1.277471 | cl_loss: 0.035183 | loss: 1.453388
2022-07-27 23:00:01.118 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 17 | step:  400 | mle_loss: 1.278186 | cl_loss: 0.034867 | loss: 1.452523
2022-07-27 23:00:19.128 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 17 | step:  450 | mle_loss: 1.276107 | cl_loss: 0.033784 | loss: 1.445024
2022-07-27 23:00:37.021 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 17 | step:  500 | mle_loss: 1.282742 | cl_loss: 0.033675 | loss: 1.451116
2022-07-27 23:00:54.900 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 17 | step:  550 | mle_loss: 1.272659 | cl_loss: 0.031229 | loss: 1.428805
2022-07-27 23:01:13.045 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 17 | step:  600 | mle_loss: 1.272439 | cl_loss: 0.034533 | loss: 1.445102
2022-07-27 23:01:31.158 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 17 | step:  650 | mle_loss: 1.274546 | cl_loss: 0.033607 | loss: 1.442583
2022-07-27 23:01:49.379 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 17 | step:  700 | mle_loss: 1.234493 | cl_loss: 0.035944 | loss: 1.414210
2022-07-27 23:02:07.183 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 17 | step:  750 | mle_loss: 1.268882 | cl_loss: 0.032289 | loss: 1.430328
2022-07-27 23:02:25.387 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 17 | step:  800 | mle_loss: 1.261561 | cl_loss: 0.030571 | loss: 1.414414
2022-07-27 23:02:43.579 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 17 | step:  850 | mle_loss: 1.283325 | cl_loss: 0.032756 | loss: 1.447104
2022-07-27 23:03:01.748 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 17 | step:  900 | mle_loss: 1.259245 | cl_loss: 0.034418 | loss: 1.431335
2022-07-27 23:03:19.868 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 17 | step:  950 | mle_loss: 1.276670 | cl_loss: 0.035548 | loss: 1.454413
2022-07-27 23:03:37.829 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 17 | step: 1000 | mle_loss: 1.280076 | cl_loss: 0.032127 | loss: 1.440711
2022-07-27 23:03:55.896 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 17 | step: 1050 | mle_loss: 1.271106 | cl_loss: 0.034348 | loss: 1.442846
2022-07-27 23:04:14.050 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 17 | step: 1100 | mle_loss: 1.274803 | cl_loss: 0.033962 | loss: 1.444613
2022-07-27 23:04:32.044 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 17 | step: 1150 | mle_loss: 1.280171 | cl_loss: 0.031222 | loss: 1.436279
2022-07-27 23:04:50.233 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 17 | step: 1200 | mle_loss: 1.282923 | cl_loss: 0.034545 | loss: 1.455649
2022-07-27 23:05:07.919 | INFO     | __main__:evaluate:178 - Generating...
2022-07-27 23:06:30.668 | INFO     | __main__:evaluate:188 - Generation finished.
2022-07-27 23:06:30.668 | INFO     | __main__:evaluate:195 - Rouge scores: {'rouge-1': 0.4026, 'rouge-2': 0.2435, 'rouge-l': 0.3573}
2022-07-27 23:06:30.669 | INFO     | __main__:train:137 - Eval loss: 0.0, the best loss: {'loss': 0.0, 'epoch': 0, 'step': 749}
2022-07-27 23:06:30.669 | INFO     | __main__:train:138 - Rouge scores: {'rouge-1': 0.4026, 'rouge-2': 0.2435, 'rouge-l': 0.3573}, the best scores: {'rouge-1': 0.4145, 'rouge-2': 0.2508, 'rouge-l': 0.3637, 'epoch': 0, 'step': 749}
2022-07-27 23:06:30.669 | INFO     | __main__:train:143 - Saving model checkpoint to checkpoints/MoCoBart-1-17-1249
2022-07-27 23:06:32.570 | INFO     | processing.dataset:_load_and_cache_examples:43 - Loading examples from cache file data/cache/train_set/train_18.pkl
2022-07-27 23:06:34.553 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 18 | step:    0 | mle_loss: 1.272665 | cl_loss: 0.030468 | loss: 1.425004
2022-07-27 23:06:52.350 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 18 | step:   50 | mle_loss: 1.246624 | cl_loss: 0.027941 | loss: 1.386328
2022-07-27 23:07:10.564 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 18 | step:  100 | mle_loss: 1.239568 | cl_loss: 0.028777 | loss: 1.383452
2022-07-27 23:07:28.717 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 18 | step:  150 | mle_loss: 1.255381 | cl_loss: 0.029839 | loss: 1.404578
2022-07-27 23:07:46.686 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 18 | step:  200 | mle_loss: 1.231181 | cl_loss: 0.028928 | loss: 1.375821
2022-07-27 23:08:04.934 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 18 | step:  250 | mle_loss: 1.244497 | cl_loss: 0.028599 | loss: 1.387491
2022-07-27 23:08:22.935 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 18 | step:  300 | mle_loss: 1.241535 | cl_loss: 0.029389 | loss: 1.388478
2022-07-27 23:08:41.016 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 18 | step:  350 | mle_loss: 1.228835 | cl_loss: 0.029485 | loss: 1.376262
2022-07-27 23:08:58.793 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 18 | step:  400 | mle_loss: 1.231188 | cl_loss: 0.028465 | loss: 1.373515
2022-07-27 23:09:16.710 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 18 | step:  450 | mle_loss: 1.205545 | cl_loss: 0.028213 | loss: 1.346610
2022-07-27 23:09:34.792 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 18 | step:  500 | mle_loss: 1.235370 | cl_loss: 0.027972 | loss: 1.375228
2022-07-27 23:09:52.895 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 18 | step:  550 | mle_loss: 1.227023 | cl_loss: 0.027606 | loss: 1.365053
2022-07-27 23:10:10.919 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 18 | step:  600 | mle_loss: 1.238658 | cl_loss: 0.029288 | loss: 1.385100
2022-07-27 23:10:28.714 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 18 | step:  650 | mle_loss: 1.248321 | cl_loss: 0.027822 | loss: 1.387429
2022-07-27 23:10:46.786 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 18 | step:  700 | mle_loss: 1.219167 | cl_loss: 0.028550 | loss: 1.361915
2022-07-27 23:11:04.687 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 18 | step:  750 | mle_loss: 1.250550 | cl_loss: 0.027788 | loss: 1.389488
2022-07-27 23:11:22.509 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 18 | step:  800 | mle_loss: 1.234921 | cl_loss: 0.028119 | loss: 1.375515
2022-07-27 23:11:40.132 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 18 | step:  850 | mle_loss: 1.211482 | cl_loss: 0.028635 | loss: 1.354656
2022-07-27 23:11:58.040 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 18 | step:  900 | mle_loss: 1.197770 | cl_loss: 0.027114 | loss: 1.333337
2022-07-27 23:12:15.812 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 18 | step:  950 | mle_loss: 1.234732 | cl_loss: 0.028134 | loss: 1.375400
2022-07-27 23:12:33.730 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 18 | step: 1000 | mle_loss: 1.203692 | cl_loss: 0.028028 | loss: 1.343831
2022-07-27 23:12:51.740 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 18 | step: 1050 | mle_loss: 1.246209 | cl_loss: 0.028477 | loss: 1.388594
2022-07-27 23:13:09.643 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 18 | step: 1100 | mle_loss: 1.210110 | cl_loss: 0.027563 | loss: 1.347925
2022-07-27 23:13:27.886 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 18 | step: 1150 | mle_loss: 1.204025 | cl_loss: 0.027503 | loss: 1.341539
2022-07-27 23:13:45.610 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 18 | step: 1200 | mle_loss: 1.222010 | cl_loss: 0.027518 | loss: 1.359601
2022-07-27 23:14:03.388 | INFO     | processing.dataset:_load_and_cache_examples:43 - Loading examples from cache file data/cache/train_set/train_19.pkl
2022-07-27 23:14:05.796 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 19 | step:    0 | mle_loss: 1.212087 | cl_loss: 0.027576 | loss: 1.349966
2022-07-27 23:14:23.816 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 19 | step:   50 | mle_loss: 1.208831 | cl_loss: 0.030018 | loss: 1.358919
2022-07-27 23:14:41.564 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 19 | step:  100 | mle_loss: 1.186134 | cl_loss: 0.030955 | loss: 1.340911
2022-07-27 23:14:59.404 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 19 | step:  150 | mle_loss: 1.210106 | cl_loss: 0.031386 | loss: 1.367034
2022-07-27 23:15:16.975 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 19 | step:  200 | mle_loss: 1.206015 | cl_loss: 0.030174 | loss: 1.356887
2022-07-27 23:15:34.772 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 19 | step:  250 | mle_loss: 1.177141 | cl_loss: 0.030783 | loss: 1.331056
2022-07-27 23:15:52.632 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 19 | step:  300 | mle_loss: 1.178533 | cl_loss: 0.028985 | loss: 1.323458
2022-07-27 23:16:10.382 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 19 | step:  350 | mle_loss: 1.179573 | cl_loss: 0.030428 | loss: 1.331713
2022-07-27 23:16:28.434 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 19 | step:  400 | mle_loss: 1.183109 | cl_loss: 0.028425 | loss: 1.325234
2022-07-27 23:16:46.444 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 19 | step:  450 | mle_loss: 1.177104 | cl_loss: 0.030474 | loss: 1.329475
2022-07-27 23:17:04.420 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 19 | step:  500 | mle_loss: 1.206947 | cl_loss: 0.030174 | loss: 1.357818
2022-07-27 23:17:22.220 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 19 | step:  550 | mle_loss: 1.172162 | cl_loss: 0.029942 | loss: 1.321874
2022-07-27 23:17:40.020 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 19 | step:  600 | mle_loss: 1.167616 | cl_loss: 0.029140 | loss: 1.313315
2022-07-27 23:17:57.887 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 19 | step:  650 | mle_loss: 1.169122 | cl_loss: 0.028845 | loss: 1.313345
2022-07-27 23:18:15.863 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 19 | step:  700 | mle_loss: 1.174976 | cl_loss: 0.029574 | loss: 1.322844
2022-07-27 23:18:33.228 | INFO     | __main__:evaluate:178 - Generating...
2022-07-27 23:19:56.919 | INFO     | __main__:evaluate:188 - Generation finished.
2022-07-27 23:19:56.920 | INFO     | __main__:evaluate:195 - Rouge scores: {'rouge-1': 0.4038, 'rouge-2': 0.2472, 'rouge-l': 0.358}
2022-07-27 23:19:56.920 | INFO     | __main__:train:137 - Eval loss: 0.0, the best loss: {'loss': 0.0, 'epoch': 0, 'step': 749}
2022-07-27 23:19:56.920 | INFO     | __main__:train:138 - Rouge scores: {'rouge-1': 0.4038, 'rouge-2': 0.2472, 'rouge-l': 0.358}, the best scores: {'rouge-1': 0.4145, 'rouge-2': 0.2508, 'rouge-l': 0.3637, 'epoch': 0, 'step': 749}
2022-07-27 23:19:56.921 | INFO     | __main__:train:143 - Saving model checkpoint to checkpoints/MoCoBart-1-19-749
2022-07-27 23:19:59.467 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 19 | step:  750 | mle_loss: 1.164344 | cl_loss: 0.029202 | loss: 1.310352
2022-07-27 23:20:17.317 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 19 | step:  800 | mle_loss: 1.176734 | cl_loss: 0.030085 | loss: 1.327160
2022-07-27 23:20:35.250 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 19 | step:  850 | mle_loss: 1.171007 | cl_loss: 0.029352 | loss: 1.317768
2022-07-27 23:20:53.263 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 19 | step:  900 | mle_loss: 1.149483 | cl_loss: 0.028846 | loss: 1.293715
2022-07-27 23:21:11.176 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 19 | step:  950 | mle_loss: 1.185723 | cl_loss: 0.029283 | loss: 1.332139
2022-07-27 23:21:28.809 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 19 | step: 1000 | mle_loss: 1.187448 | cl_loss: 0.029455 | loss: 1.334724
2022-07-27 23:21:46.695 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 19 | step: 1050 | mle_loss: 1.192248 | cl_loss: 0.030760 | loss: 1.346047
2022-07-27 23:22:04.646 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 19 | step: 1100 | mle_loss: 1.164079 | cl_loss: 0.029473 | loss: 1.311442
2022-07-27 23:22:22.574 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 19 | step: 1150 | mle_loss: 1.168023 | cl_loss: 0.029146 | loss: 1.313751
2022-07-27 23:22:40.228 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 19 | step: 1200 | mle_loss: 1.177556 | cl_loss: 0.029319 | loss: 1.324154
2022-07-27 23:22:57.916 | INFO     | processing.dataset:_load_and_cache_examples:43 - Loading examples from cache file data/cache/train_set/train_20.pkl
2022-07-27 23:22:59.452 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 20 | step:    0 | mle_loss: 1.173332 | cl_loss: 0.030493 | loss: 1.325796
2022-07-27 23:23:17.120 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 20 | step:   50 | mle_loss: 1.248978 | cl_loss: 0.028954 | loss: 1.393746
2022-07-27 23:23:34.953 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 20 | step:  100 | mle_loss: 1.240739 | cl_loss: 0.029599 | loss: 1.388736
2022-07-27 23:23:52.895 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 20 | step:  150 | mle_loss: 1.254888 | cl_loss: 0.029727 | loss: 1.403524
2022-07-27 23:24:10.869 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 20 | step:  200 | mle_loss: 1.257847 | cl_loss: 0.030196 | loss: 1.408828
2022-07-27 23:24:28.827 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 20 | step:  250 | mle_loss: 1.230877 | cl_loss: 0.029997 | loss: 1.380863
2022-07-27 23:24:46.781 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 20 | step:  300 | mle_loss: 1.238575 | cl_loss: 0.029059 | loss: 1.383868
2022-07-27 23:25:04.519 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 20 | step:  350 | mle_loss: 1.225275 | cl_loss: 0.030220 | loss: 1.376376
2022-07-27 23:25:22.469 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 20 | step:  400 | mle_loss: 1.247136 | cl_loss: 0.030663 | loss: 1.400451
2022-07-27 23:25:39.972 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 20 | step:  450 | mle_loss: 1.272705 | cl_loss: 0.028010 | loss: 1.412754
2022-07-27 23:25:57.836 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 20 | step:  500 | mle_loss: 1.222986 | cl_loss: 0.028377 | loss: 1.364869
2022-07-27 23:26:15.781 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 20 | step:  550 | mle_loss: 1.227845 | cl_loss: 0.028908 | loss: 1.372384
2022-07-27 23:26:33.567 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 20 | step:  600 | mle_loss: 1.225047 | cl_loss: 0.027841 | loss: 1.364250
2022-07-27 23:26:51.427 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 20 | step:  650 | mle_loss: 1.247852 | cl_loss: 0.029073 | loss: 1.393218
2022-07-27 23:27:09.287 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 20 | step:  700 | mle_loss: 1.232121 | cl_loss: 0.030971 | loss: 1.386976
2022-07-27 23:27:27.210 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 20 | step:  750 | mle_loss: 1.219236 | cl_loss: 0.029047 | loss: 1.364472
2022-07-27 23:27:44.919 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 20 | step:  800 | mle_loss: 1.192669 | cl_loss: 0.028350 | loss: 1.334418
2022-07-27 23:28:02.406 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 20 | step:  850 | mle_loss: 1.239802 | cl_loss: 0.028883 | loss: 1.384215
2022-07-27 23:28:20.433 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 20 | step:  900 | mle_loss: 1.231746 | cl_loss: 0.028335 | loss: 1.373422
2022-07-27 23:28:38.050 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 20 | step:  950 | mle_loss: 1.214291 | cl_loss: 0.028803 | loss: 1.358307
2022-07-27 23:28:55.973 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 20 | step: 1000 | mle_loss: 1.214229 | cl_loss: 0.028156 | loss: 1.355011
2022-07-27 23:29:13.786 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 20 | step: 1050 | mle_loss: 1.275210 | cl_loss: 0.028942 | loss: 1.419917
2022-07-27 23:29:31.632 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 20 | step: 1100 | mle_loss: 1.237088 | cl_loss: 0.028955 | loss: 1.381862
2022-07-27 23:29:49.378 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 20 | step: 1150 | mle_loss: 1.221713 | cl_loss: 0.028931 | loss: 1.366370
2022-07-27 23:30:07.284 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 20 | step: 1200 | mle_loss: 1.245819 | cl_loss: 0.031490 | loss: 1.403272
2022-07-27 23:30:25.019 | INFO     | processing.dataset:_load_and_cache_examples:43 - Loading examples from cache file data/cache/train_set/train_21.pkl
2022-07-27 23:30:27.414 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 21 | step:    0 | mle_loss: 1.201891 | cl_loss: 0.028428 | loss: 1.344033
2022-07-27 23:30:45.315 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 21 | step:   50 | mle_loss: 1.252280 | cl_loss: 0.032204 | loss: 1.413298
2022-07-27 23:31:03.303 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 21 | step:  100 | mle_loss: 1.252703 | cl_loss: 0.031560 | loss: 1.410505
2022-07-27 23:31:21.590 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 21 | step:  150 | mle_loss: 1.260130 | cl_loss: 0.032798 | loss: 1.424120
2022-07-27 23:31:39.894 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 21 | step:  200 | mle_loss: 1.221508 | cl_loss: 0.030898 | loss: 1.375999
2022-07-27 23:31:57.555 | INFO     | __main__:evaluate:178 - Generating...
2022-07-27 23:33:18.577 | INFO     | __main__:evaluate:188 - Generation finished.
2022-07-27 23:33:18.577 | INFO     | __main__:evaluate:195 - Rouge scores: {'rouge-1': 0.4075, 'rouge-2': 0.2452, 'rouge-l': 0.3597}
2022-07-27 23:33:18.578 | INFO     | __main__:train:137 - Eval loss: 0.0, the best loss: {'loss': 0.0, 'epoch': 0, 'step': 749}
2022-07-27 23:33:18.578 | INFO     | __main__:train:138 - Rouge scores: {'rouge-1': 0.4075, 'rouge-2': 0.2452, 'rouge-l': 0.3597}, the best scores: {'rouge-1': 0.4145, 'rouge-2': 0.2508, 'rouge-l': 0.3637, 'epoch': 0, 'step': 749}
2022-07-27 23:33:18.578 | INFO     | __main__:train:143 - Saving model checkpoint to checkpoints/MoCoBart-1-21-249
2022-07-27 23:33:21.163 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 21 | step:  250 | mle_loss: 1.220033 | cl_loss: 0.031488 | loss: 1.377472
2022-07-27 23:33:38.749 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 21 | step:  300 | mle_loss: 1.241496 | cl_loss: 0.032724 | loss: 1.405117
2022-07-27 23:33:56.855 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 21 | step:  350 | mle_loss: 1.207446 | cl_loss: 0.030566 | loss: 1.360277
2022-07-27 23:34:14.867 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 21 | step:  400 | mle_loss: 1.231767 | cl_loss: 0.032296 | loss: 1.393249
2022-07-27 23:34:32.552 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 21 | step:  450 | mle_loss: 1.245821 | cl_loss: 0.031956 | loss: 1.405601
2022-07-27 23:34:50.524 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 21 | step:  500 | mle_loss: 1.226255 | cl_loss: 0.031008 | loss: 1.381296
2022-07-27 23:35:08.392 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 21 | step:  550 | mle_loss: 1.251695 | cl_loss: 0.029922 | loss: 1.401305
2022-07-27 23:35:26.642 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 21 | step:  600 | mle_loss: 1.240633 | cl_loss: 0.031865 | loss: 1.399959
2022-07-27 23:35:44.533 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 21 | step:  650 | mle_loss: 1.233233 | cl_loss: 0.032823 | loss: 1.397348
2022-07-27 23:36:02.587 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 21 | step:  700 | mle_loss: 1.227651 | cl_loss: 0.029437 | loss: 1.374835
2022-07-27 23:36:20.597 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 21 | step:  750 | mle_loss: 1.226077 | cl_loss: 0.031308 | loss: 1.382616
2022-07-27 23:36:38.546 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 21 | step:  800 | mle_loss: 1.217174 | cl_loss: 0.031852 | loss: 1.376433
2022-07-27 23:36:56.503 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 21 | step:  850 | mle_loss: 1.216629 | cl_loss: 0.029454 | loss: 1.363900
2022-07-27 23:37:13.993 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 21 | step:  900 | mle_loss: 1.249172 | cl_loss: 0.030484 | loss: 1.401590
2022-07-27 23:37:31.870 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 21 | step:  950 | mle_loss: 1.238491 | cl_loss: 0.031577 | loss: 1.396377
2022-07-27 23:37:49.855 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 21 | step: 1000 | mle_loss: 1.200916 | cl_loss: 0.031590 | loss: 1.358866
2022-07-27 23:38:07.821 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 21 | step: 1050 | mle_loss: 1.225206 | cl_loss: 0.030082 | loss: 1.375614
2022-07-27 23:38:25.726 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 21 | step: 1100 | mle_loss: 1.239809 | cl_loss: 0.028711 | loss: 1.383365
2022-07-27 23:38:43.602 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 21 | step: 1150 | mle_loss: 1.228943 | cl_loss: 0.029559 | loss: 1.376738
2022-07-27 23:39:01.463 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 21 | step: 1200 | mle_loss: 1.204295 | cl_loss: 0.031577 | loss: 1.362178
2022-07-27 23:39:19.031 | INFO     | processing.dataset:_load_and_cache_examples:43 - Loading examples from cache file data/cache/train_set/train_22.pkl
2022-07-27 23:39:21.335 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 22 | step:    0 | mle_loss: 1.256330 | cl_loss: 0.030630 | loss: 1.409482
2022-07-27 23:39:39.273 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 22 | step:   50 | mle_loss: 1.306111 | cl_loss: 0.030663 | loss: 1.459427
2022-07-27 23:39:57.163 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 22 | step:  100 | mle_loss: 1.311066 | cl_loss: 0.030762 | loss: 1.464874
2022-07-27 23:40:15.062 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 22 | step:  150 | mle_loss: 1.291123 | cl_loss: 0.030792 | loss: 1.445081
2022-07-27 23:40:32.980 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 22 | step:  200 | mle_loss: 1.282766 | cl_loss: 0.031132 | loss: 1.438424
2022-07-27 23:40:50.803 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 22 | step:  250 | mle_loss: 1.300695 | cl_loss: 0.031355 | loss: 1.457470
2022-07-27 23:41:08.643 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 22 | step:  300 | mle_loss: 1.301407 | cl_loss: 0.031877 | loss: 1.460792
2022-07-27 23:41:26.560 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 22 | step:  350 | mle_loss: 1.316359 | cl_loss: 0.031359 | loss: 1.473153
2022-07-27 23:41:44.371 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 22 | step:  400 | mle_loss: 1.311712 | cl_loss: 0.030982 | loss: 1.466623
2022-07-27 23:42:02.015 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 22 | step:  450 | mle_loss: 1.306570 | cl_loss: 0.029890 | loss: 1.456021
2022-07-27 23:42:19.761 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 22 | step:  500 | mle_loss: 1.299050 | cl_loss: 0.030439 | loss: 1.451246
2022-07-27 23:42:37.769 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 22 | step:  550 | mle_loss: 1.300717 | cl_loss: 0.031874 | loss: 1.460088
2022-07-27 23:42:55.810 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 22 | step:  600 | mle_loss: 1.321247 | cl_loss: 0.031267 | loss: 1.477582
2022-07-27 23:43:13.680 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 22 | step:  650 | mle_loss: 1.313846 | cl_loss: 0.030569 | loss: 1.466693
2022-07-27 23:43:31.768 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 22 | step:  700 | mle_loss: 1.313031 | cl_loss: 0.030955 | loss: 1.467805
2022-07-27 23:43:49.755 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 22 | step:  750 | mle_loss: 1.308053 | cl_loss: 0.030988 | loss: 1.462992
2022-07-27 23:44:07.422 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 22 | step:  800 | mle_loss: 1.281140 | cl_loss: 0.030492 | loss: 1.433602
2022-07-27 23:44:25.398 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 22 | step:  850 | mle_loss: 1.299828 | cl_loss: 0.029909 | loss: 1.449374
2022-07-27 23:44:43.288 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 22 | step:  900 | mle_loss: 1.283708 | cl_loss: 0.029483 | loss: 1.431125
2022-07-27 23:45:01.166 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 22 | step:  950 | mle_loss: 1.294036 | cl_loss: 0.029756 | loss: 1.442815
2022-07-27 23:45:18.838 | INFO     | __main__:evaluate:178 - Generating...
2022-07-27 23:46:37.888 | INFO     | __main__:evaluate:188 - Generation finished.
2022-07-27 23:46:37.889 | INFO     | __main__:evaluate:195 - Rouge scores: {'rouge-1': 0.3842, 'rouge-2': 0.2279, 'rouge-l': 0.3438}
2022-07-27 23:46:37.889 | INFO     | __main__:train:137 - Eval loss: 0.0, the best loss: {'loss': 0.0, 'epoch': 0, 'step': 749}
2022-07-27 23:46:37.889 | INFO     | __main__:train:138 - Rouge scores: {'rouge-1': 0.3842, 'rouge-2': 0.2279, 'rouge-l': 0.3438}, the best scores: {'rouge-1': 0.4145, 'rouge-2': 0.2508, 'rouge-l': 0.3637, 'epoch': 0, 'step': 749}
2022-07-27 23:46:37.890 | INFO     | __main__:train:143 - Saving model checkpoint to checkpoints/MoCoBart-1-22-999
2022-07-27 23:46:40.064 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 22 | step: 1000 | mle_loss: 1.285042 | cl_loss: 0.031927 | loss: 1.444675
2022-07-27 23:46:57.741 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 22 | step: 1050 | mle_loss: 1.283602 | cl_loss: 0.030989 | loss: 1.438545
2022-07-27 23:47:15.603 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 22 | step: 1100 | mle_loss: 1.279691 | cl_loss: 0.032172 | loss: 1.440549
2022-07-27 23:47:33.413 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 22 | step: 1150 | mle_loss: 1.292094 | cl_loss: 0.029787 | loss: 1.441031
2022-07-27 23:47:51.438 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 22 | step: 1200 | mle_loss: 1.270663 | cl_loss: 0.029036 | loss: 1.415845
2022-07-27 23:48:09.239 | INFO     | processing.dataset:_load_and_cache_examples:43 - Loading examples from cache file data/cache/train_set/train_23.pkl
2022-07-27 23:48:11.192 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 23 | step:    0 | mle_loss: 1.271705 | cl_loss: 0.031004 | loss: 1.426723
2022-07-27 23:48:29.234 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 23 | step:   50 | mle_loss: 1.228820 | cl_loss: 0.031247 | loss: 1.385057
2022-07-27 23:48:47.063 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 23 | step:  100 | mle_loss: 1.215755 | cl_loss: 0.031025 | loss: 1.370881
2022-07-27 23:49:05.210 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 23 | step:  150 | mle_loss: 1.209162 | cl_loss: 0.031208 | loss: 1.365203
2022-07-27 23:49:22.799 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 23 | step:  200 | mle_loss: 1.247369 | cl_loss: 0.030076 | loss: 1.397750
2022-07-27 23:49:40.643 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 23 | step:  250 | mle_loss: 1.239635 | cl_loss: 0.029796 | loss: 1.388616
2022-07-27 23:49:58.481 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 23 | step:  300 | mle_loss: 1.236786 | cl_loss: 0.031272 | loss: 1.393144
2022-07-27 23:50:15.987 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 23 | step:  350 | mle_loss: 1.237940 | cl_loss: 0.030281 | loss: 1.389343
2022-07-27 23:50:33.823 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 23 | step:  400 | mle_loss: 1.237458 | cl_loss: 0.031985 | loss: 1.397384
2022-07-27 23:50:51.783 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 23 | step:  450 | mle_loss: 1.243618 | cl_loss: 0.030472 | loss: 1.395980
2022-07-27 23:51:09.542 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 23 | step:  500 | mle_loss: 1.205347 | cl_loss: 0.030955 | loss: 1.360124
2022-07-27 23:51:27.510 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 23 | step:  550 | mle_loss: 1.201860 | cl_loss: 0.030185 | loss: 1.352785
2022-07-27 23:51:45.447 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 23 | step:  600 | mle_loss: 1.206684 | cl_loss: 0.030110 | loss: 1.357234
2022-07-27 23:52:03.408 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 23 | step:  650 | mle_loss: 1.212043 | cl_loss: 0.030160 | loss: 1.362841
2022-07-27 23:52:21.477 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 23 | step:  700 | mle_loss: 1.190585 | cl_loss: 0.029278 | loss: 1.336976
2022-07-27 23:52:39.187 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 23 | step:  750 | mle_loss: 1.200449 | cl_loss: 0.029193 | loss: 1.346413
2022-07-27 23:52:57.111 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 23 | step:  800 | mle_loss: 1.214414 | cl_loss: 0.031351 | loss: 1.371167
2022-07-27 23:53:15.020 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 23 | step:  850 | mle_loss: 1.224815 | cl_loss: 0.030378 | loss: 1.376708
2022-07-27 23:53:32.854 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 23 | step:  900 | mle_loss: 1.206503 | cl_loss: 0.031193 | loss: 1.362470
2022-07-27 23:53:50.140 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 23 | step:  950 | mle_loss: 1.233019 | cl_loss: 0.029201 | loss: 1.379024
2022-07-27 23:54:07.844 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 23 | step: 1000 | mle_loss: 1.221984 | cl_loss: 0.029573 | loss: 1.369851
2022-07-27 23:54:25.884 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 23 | step: 1050 | mle_loss: 1.191818 | cl_loss: 0.030330 | loss: 1.343467
2022-07-27 23:54:43.968 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 23 | step: 1100 | mle_loss: 1.192204 | cl_loss: 0.031635 | loss: 1.350381
2022-07-27 23:55:01.759 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 23 | step: 1150 | mle_loss: 1.210580 | cl_loss: 0.030766 | loss: 1.364408
2022-07-27 23:55:19.498 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 23 | step: 1200 | mle_loss: 1.211906 | cl_loss: 0.030463 | loss: 1.364222
2022-07-27 23:55:37.312 | INFO     | processing.dataset:_load_and_cache_examples:43 - Loading examples from cache file data/cache/train_set/train_24.pkl
2022-07-27 23:55:39.096 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 24 | step:    0 | mle_loss: 1.190533 | cl_loss: 0.030416 | loss: 1.342612
2022-07-27 23:55:57.092 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 24 | step:   50 | mle_loss: 1.226323 | cl_loss: 0.027695 | loss: 1.364796
2022-07-27 23:56:15.019 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 24 | step:  100 | mle_loss: 1.217202 | cl_loss: 0.028503 | loss: 1.359716
2022-07-27 23:56:33.051 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 24 | step:  150 | mle_loss: 1.205264 | cl_loss: 0.029070 | loss: 1.350615
2022-07-27 23:56:51.139 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 24 | step:  200 | mle_loss: 1.184401 | cl_loss: 0.028686 | loss: 1.327832
2022-07-27 23:57:09.167 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 24 | step:  250 | mle_loss: 1.198206 | cl_loss: 0.028487 | loss: 1.340640
2022-07-27 23:57:27.116 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 24 | step:  300 | mle_loss: 1.205303 | cl_loss: 0.028957 | loss: 1.350091
2022-07-27 23:57:45.206 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 24 | step:  350 | mle_loss: 1.216419 | cl_loss: 0.029991 | loss: 1.366374
2022-07-27 23:58:03.346 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 24 | step:  400 | mle_loss: 1.227209 | cl_loss: 0.029928 | loss: 1.376850
2022-07-27 23:58:21.465 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 24 | step:  450 | mle_loss: 1.198714 | cl_loss: 0.030529 | loss: 1.351361
2022-07-27 23:58:38.757 | INFO     | __main__:evaluate:178 - Generating...
2022-07-27 23:59:58.895 | INFO     | __main__:evaluate:188 - Generation finished.
2022-07-27 23:59:58.895 | INFO     | __main__:evaluate:195 - Rouge scores: {'rouge-1': 0.4175, 'rouge-2': 0.2549, 'rouge-l': 0.3735}
2022-07-27 23:59:58.895 | INFO     | __main__:train:137 - Eval loss: 0.0, the best loss: {'loss': 0.0, 'epoch': 0, 'step': 749}
2022-07-27 23:59:58.896 | INFO     | __main__:train:138 - Rouge scores: {'rouge-1': 0.4175, 'rouge-2': 0.2549, 'rouge-l': 0.3735, 'epoch': 1, 'step': 499}, the best scores: {'rouge-1': 0.4175, 'rouge-2': 0.2549, 'rouge-l': 0.3735, 'epoch': 1, 'step': 499}
2022-07-27 23:59:58.896 | INFO     | __main__:train:143 - Saving model checkpoint to checkpoints/MoCoBart-1-24-499
2022-07-28 00:00:01.353 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 24 | step:  500 | mle_loss: 1.219386 | cl_loss: 0.029189 | loss: 1.365331
2022-07-28 00:00:19.063 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 24 | step:  550 | mle_loss: 1.215517 | cl_loss: 0.029178 | loss: 1.361409
2022-07-28 00:00:37.063 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 24 | step:  600 | mle_loss: 1.216842 | cl_loss: 0.029099 | loss: 1.362337
2022-07-28 00:00:55.103 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 24 | step:  650 | mle_loss: 1.195595 | cl_loss: 0.028937 | loss: 1.340282
2022-07-28 00:01:13.264 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 24 | step:  700 | mle_loss: 1.191839 | cl_loss: 0.029370 | loss: 1.338686
2022-07-28 00:01:31.428 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 24 | step:  750 | mle_loss: 1.198757 | cl_loss: 0.029439 | loss: 1.345953
2022-07-28 00:01:49.460 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 24 | step:  800 | mle_loss: 1.215637 | cl_loss: 0.028581 | loss: 1.358543
2022-07-28 00:02:07.284 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 24 | step:  850 | mle_loss: 1.215397 | cl_loss: 0.028349 | loss: 1.357143
2022-07-28 00:02:25.136 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 24 | step:  900 | mle_loss: 1.219802 | cl_loss: 0.028386 | loss: 1.361732
2022-07-28 00:02:43.096 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 24 | step:  950 | mle_loss: 1.196795 | cl_loss: 0.027690 | loss: 1.335243
2022-07-28 00:03:00.955 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 24 | step: 1000 | mle_loss: 1.184013 | cl_loss: 0.028692 | loss: 1.327470
2022-07-28 00:03:19.026 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 24 | step: 1050 | mle_loss: 1.182836 | cl_loss: 0.030482 | loss: 1.335246
2022-07-28 00:03:37.131 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 24 | step: 1100 | mle_loss: 1.220036 | cl_loss: 0.029053 | loss: 1.365299
2022-07-28 00:03:55.224 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 24 | step: 1150 | mle_loss: 1.194578 | cl_loss: 0.028195 | loss: 1.335553
2022-07-28 00:04:13.203 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 24 | step: 1200 | mle_loss: 1.212021 | cl_loss: 0.029374 | loss: 1.358892
2022-07-28 00:04:30.738 | INFO     | processing.dataset:_load_and_cache_examples:43 - Loading examples from cache file data/cache/train_set/train_25.pkl
2022-07-28 00:04:33.034 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 25 | step:    0 | mle_loss: 1.216034 | cl_loss: 0.029288 | loss: 1.362475
2022-07-28 00:04:50.904 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 25 | step:   50 | mle_loss: 1.267403 | cl_loss: 0.031933 | loss: 1.427068
2022-07-28 00:05:08.858 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 25 | step:  100 | mle_loss: 1.282770 | cl_loss: 0.034340 | loss: 1.454470
2022-07-28 00:05:26.826 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 25 | step:  150 | mle_loss: 1.252765 | cl_loss: 0.034315 | loss: 1.424339
2022-07-28 00:05:44.750 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 25 | step:  200 | mle_loss: 1.243313 | cl_loss: 0.032276 | loss: 1.404692
2022-07-28 00:06:02.564 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 25 | step:  250 | mle_loss: 1.264227 | cl_loss: 0.031584 | loss: 1.422146
2022-07-28 00:06:20.655 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 25 | step:  300 | mle_loss: 1.263517 | cl_loss: 0.032061 | loss: 1.423822
2022-07-28 00:06:38.563 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 25 | step:  350 | mle_loss: 1.251444 | cl_loss: 0.032532 | loss: 1.414106
2022-07-28 00:06:56.259 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 25 | step:  400 | mle_loss: 1.244797 | cl_loss: 0.031542 | loss: 1.402506
2022-07-28 00:07:13.572 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 25 | step:  450 | mle_loss: 1.261166 | cl_loss: 0.031234 | loss: 1.417337
2022-07-28 00:07:31.236 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 25 | step:  500 | mle_loss: 1.231302 | cl_loss: 0.031444 | loss: 1.388522
2022-07-28 00:07:48.968 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 25 | step:  550 | mle_loss: 1.247306 | cl_loss: 0.030633 | loss: 1.400473
2022-07-28 00:08:06.611 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 25 | step:  600 | mle_loss: 1.254282 | cl_loss: 0.030974 | loss: 1.409153
2022-07-28 00:08:24.000 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 25 | step:  650 | mle_loss: 1.265883 | cl_loss: 0.030052 | loss: 1.416144
2022-07-28 00:08:41.468 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 25 | step:  700 | mle_loss: 1.269005 | cl_loss: 0.029942 | loss: 1.418717
2022-07-28 00:08:59.195 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 25 | step:  750 | mle_loss: 1.261112 | cl_loss: 0.029494 | loss: 1.408582
2022-07-28 00:09:16.839 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 25 | step:  800 | mle_loss: 1.216844 | cl_loss: 0.030206 | loss: 1.367874
2022-07-28 00:09:34.446 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 25 | step:  850 | mle_loss: 1.252057 | cl_loss: 0.030949 | loss: 1.406802
2022-07-28 00:09:52.109 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 25 | step:  900 | mle_loss: 1.233073 | cl_loss: 0.030485 | loss: 1.385497
2022-07-28 00:10:09.873 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 25 | step:  950 | mle_loss: 1.243803 | cl_loss: 0.030463 | loss: 1.396120
2022-07-28 00:10:27.646 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 25 | step: 1000 | mle_loss: 1.219733 | cl_loss: 0.029147 | loss: 1.365470
2022-07-28 00:10:45.388 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 25 | step: 1050 | mle_loss: 1.243112 | cl_loss: 0.029400 | loss: 1.390112
2022-07-28 00:11:03.070 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 25 | step: 1100 | mle_loss: 1.243637 | cl_loss: 0.030088 | loss: 1.394078
2022-07-28 00:11:20.760 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 25 | step: 1150 | mle_loss: 1.277415 | cl_loss: 0.030069 | loss: 1.427758
2022-07-28 00:11:38.448 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 25 | step: 1200 | mle_loss: 1.249317 | cl_loss: 0.030658 | loss: 1.402609
2022-07-28 00:11:55.929 | INFO     | __main__:evaluate:178 - Generating...
2022-07-28 00:13:19.559 | INFO     | __main__:evaluate:188 - Generation finished.
2022-07-28 00:13:19.559 | INFO     | __main__:evaluate:195 - Rouge scores: {'rouge-1': 0.4086, 'rouge-2': 0.2501, 'rouge-l': 0.3628}
2022-07-28 00:13:19.559 | INFO     | __main__:train:137 - Eval loss: 0.0, the best loss: {'loss': 0.0, 'epoch': 0, 'step': 749}
2022-07-28 00:13:19.559 | INFO     | __main__:train:138 - Rouge scores: {'rouge-1': 0.4086, 'rouge-2': 0.2501, 'rouge-l': 0.3628}, the best scores: {'rouge-1': 0.4175, 'rouge-2': 0.2549, 'rouge-l': 0.3735, 'epoch': 1, 'step': 499}
2022-07-28 00:13:19.560 | INFO     | __main__:train:143 - Saving model checkpoint to checkpoints/MoCoBart-1-25-1249
2022-07-28 00:13:21.793 | INFO     | processing.dataset:_load_and_cache_examples:43 - Loading examples from cache file data/cache/train_set/train_26.pkl
2022-07-28 00:13:23.747 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 26 | step:    0 | mle_loss: 1.243792 | cl_loss: 0.029299 | loss: 1.390289
2022-07-28 00:13:41.554 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 26 | step:   50 | mle_loss: 1.270044 | cl_loss: 0.034564 | loss: 1.442865
2022-07-28 00:13:59.236 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 26 | step:  100 | mle_loss: 1.276285 | cl_loss: 0.035239 | loss: 1.452477
2022-07-28 00:14:17.259 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 26 | step:  150 | mle_loss: 1.257939 | cl_loss: 0.035720 | loss: 1.436539
2022-07-28 00:14:35.135 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 26 | step:  200 | mle_loss: 1.293647 | cl_loss: 0.036307 | loss: 1.475181
2022-07-28 00:14:53.008 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 26 | step:  250 | mle_loss: 1.273071 | cl_loss: 0.033984 | loss: 1.442991
2022-07-28 00:15:11.019 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 26 | step:  300 | mle_loss: 1.246047 | cl_loss: 0.035089 | loss: 1.421489
2022-07-28 00:15:28.843 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 26 | step:  350 | mle_loss: 1.291826 | cl_loss: 0.033381 | loss: 1.458731
2022-07-28 00:15:46.806 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 26 | step:  400 | mle_loss: 1.221714 | cl_loss: 0.033916 | loss: 1.391292
2022-07-28 00:16:04.791 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 26 | step:  450 | mle_loss: 1.263291 | cl_loss: 0.032882 | loss: 1.427701
2022-07-28 00:16:22.744 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 26 | step:  500 | mle_loss: 1.247433 | cl_loss: 0.034329 | loss: 1.419080
2022-07-28 00:16:40.646 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 26 | step:  550 | mle_loss: 1.241604 | cl_loss: 0.032776 | loss: 1.405486
2022-07-28 00:16:58.600 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 26 | step:  600 | mle_loss: 1.264335 | cl_loss: 0.033602 | loss: 1.432346
2022-07-28 00:17:16.676 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 26 | step:  650 | mle_loss: 1.260731 | cl_loss: 0.033929 | loss: 1.430374
2022-07-28 00:17:34.709 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 26 | step:  700 | mle_loss: 1.245755 | cl_loss: 0.033249 | loss: 1.411998
2022-07-28 00:17:52.615 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 26 | step:  750 | mle_loss: 1.276476 | cl_loss: 0.033355 | loss: 1.443250
2022-07-28 00:18:10.487 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 26 | step:  800 | mle_loss: 1.233008 | cl_loss: 0.033026 | loss: 1.398140
2022-07-28 00:18:28.430 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 26 | step:  850 | mle_loss: 1.246748 | cl_loss: 0.034501 | loss: 1.419253
2022-07-28 00:18:46.222 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 26 | step:  900 | mle_loss: 1.248246 | cl_loss: 0.032328 | loss: 1.409888
2022-07-28 00:19:04.150 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 26 | step:  950 | mle_loss: 1.264041 | cl_loss: 0.033124 | loss: 1.429662
2022-07-28 00:19:21.858 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 26 | step: 1000 | mle_loss: 1.233839 | cl_loss: 0.031899 | loss: 1.393331
2022-07-28 00:19:39.770 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 26 | step: 1050 | mle_loss: 1.264105 | cl_loss: 0.032646 | loss: 1.427337
2022-07-28 00:19:57.969 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 26 | step: 1100 | mle_loss: 1.241431 | cl_loss: 0.032302 | loss: 1.402939
2022-07-28 00:20:16.090 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 26 | step: 1150 | mle_loss: 1.224371 | cl_loss: 0.031406 | loss: 1.381401
2022-07-28 00:20:33.963 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 26 | step: 1200 | mle_loss: 1.244864 | cl_loss: 0.031221 | loss: 1.400970
2022-07-28 00:20:51.669 | INFO     | processing.dataset:_load_and_cache_examples:43 - Loading examples from cache file data/cache/train_set/train_27.pkl
2022-07-28 00:20:53.405 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 27 | step:    0 | mle_loss: 1.253095 | cl_loss: 0.032447 | loss: 1.415330
2022-07-28 00:21:11.238 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 27 | step:   50 | mle_loss: 1.161682 | cl_loss: 0.027195 | loss: 1.297656
2022-07-28 00:21:29.005 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 27 | step:  100 | mle_loss: 1.143631 | cl_loss: 0.028420 | loss: 1.285730
2022-07-28 00:21:46.582 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 27 | step:  150 | mle_loss: 1.159192 | cl_loss: 0.028772 | loss: 1.303050
2022-07-28 00:22:04.714 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 27 | step:  200 | mle_loss: 1.149145 | cl_loss: 0.028600 | loss: 1.292146
2022-07-28 00:22:22.638 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 27 | step:  250 | mle_loss: 1.134661 | cl_loss: 0.029009 | loss: 1.279706
2022-07-28 00:22:40.529 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 27 | step:  300 | mle_loss: 1.124162 | cl_loss: 0.029903 | loss: 1.273678
2022-07-28 00:22:58.541 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 27 | step:  350 | mle_loss: 1.156771 | cl_loss: 0.030249 | loss: 1.308014
2022-07-28 00:23:16.488 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 27 | step:  400 | mle_loss: 1.130166 | cl_loss: 0.029353 | loss: 1.276928
2022-07-28 00:23:34.090 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 27 | step:  450 | mle_loss: 1.126708 | cl_loss: 0.029265 | loss: 1.273033
2022-07-28 00:23:51.919 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 27 | step:  500 | mle_loss: 1.125696 | cl_loss: 0.028764 | loss: 1.269516
2022-07-28 00:24:09.783 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 27 | step:  550 | mle_loss: 1.141621 | cl_loss: 0.028856 | loss: 1.285903
2022-07-28 00:24:27.614 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 27 | step:  600 | mle_loss: 1.144415 | cl_loss: 0.029238 | loss: 1.290603
2022-07-28 00:24:45.530 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 27 | step:  650 | mle_loss: 1.117894 | cl_loss: 0.029940 | loss: 1.267595
2022-07-28 00:25:03.451 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 27 | step:  700 | mle_loss: 1.134897 | cl_loss: 0.028797 | loss: 1.278883
2022-07-28 00:25:20.846 | INFO     | __main__:evaluate:178 - Generating...
2022-07-28 00:26:42.930 | INFO     | __main__:evaluate:188 - Generation finished.
2022-07-28 00:26:42.931 | INFO     | __main__:evaluate:195 - Rouge scores: {'rouge-1': 0.3982, 'rouge-2': 0.2404, 'rouge-l': 0.3552}
2022-07-28 00:26:42.931 | INFO     | __main__:train:137 - Eval loss: 0.0, the best loss: {'loss': 0.0, 'epoch': 0, 'step': 749}
2022-07-28 00:26:42.931 | INFO     | __main__:train:138 - Rouge scores: {'rouge-1': 0.3982, 'rouge-2': 0.2404, 'rouge-l': 0.3552}, the best scores: {'rouge-1': 0.4175, 'rouge-2': 0.2549, 'rouge-l': 0.3735, 'epoch': 1, 'step': 499}
2022-07-28 00:26:42.932 | INFO     | __main__:train:143 - Saving model checkpoint to checkpoints/MoCoBart-1-27-749
2022-07-28 00:26:44.995 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 27 | step:  750 | mle_loss: 1.112907 | cl_loss: 0.029100 | loss: 1.258406
2022-07-28 00:27:02.791 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 27 | step:  800 | mle_loss: 1.132796 | cl_loss: 0.030772 | loss: 1.286656
2022-07-28 00:27:20.349 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 27 | step:  850 | mle_loss: 1.124644 | cl_loss: 0.029099 | loss: 1.270139
2022-07-28 00:27:38.273 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 27 | step:  900 | mle_loss: 1.110720 | cl_loss: 0.027357 | loss: 1.247506
2022-07-28 00:27:56.105 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 27 | step:  950 | mle_loss: 1.100087 | cl_loss: 0.029213 | loss: 1.246154
2022-07-28 00:28:14.016 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 27 | step: 1000 | mle_loss: 1.127046 | cl_loss: 0.028001 | loss: 1.267053
2022-07-28 00:28:31.761 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 27 | step: 1050 | mle_loss: 1.104573 | cl_loss: 0.027757 | loss: 1.243357
2022-07-28 00:28:49.676 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 27 | step: 1100 | mle_loss: 1.102125 | cl_loss: 0.028554 | loss: 1.244895
2022-07-28 00:29:07.768 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 27 | step: 1150 | mle_loss: 1.115974 | cl_loss: 0.028399 | loss: 1.257970
2022-07-28 00:29:25.452 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 27 | step: 1200 | mle_loss: 1.119229 | cl_loss: 0.027910 | loss: 1.258777
2022-07-28 00:29:42.965 | INFO     | processing.dataset:_load_and_cache_examples:43 - Loading examples from cache file data/cache/train_set/train_28.pkl
2022-07-28 00:29:45.449 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 28 | step:    0 | mle_loss: 1.123134 | cl_loss: 0.028277 | loss: 1.264520
2022-07-28 00:30:03.513 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 28 | step:   50 | mle_loss: 1.237877 | cl_loss: 0.029863 | loss: 1.387191
2022-07-28 00:30:21.745 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 28 | step:  100 | mle_loss: 1.186468 | cl_loss: 0.032229 | loss: 1.347613
2022-07-28 00:30:39.935 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 28 | step:  150 | mle_loss: 1.208118 | cl_loss: 0.031667 | loss: 1.366452
2022-07-28 00:30:58.001 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 28 | step:  200 | mle_loss: 1.191460 | cl_loss: 0.028907 | loss: 1.335994
2022-07-28 00:31:16.073 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 28 | step:  250 | mle_loss: 1.213101 | cl_loss: 0.031275 | loss: 1.369477
2022-07-28 00:31:34.279 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 28 | step:  300 | mle_loss: 1.210164 | cl_loss: 0.030839 | loss: 1.364360
2022-07-28 00:31:52.413 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 28 | step:  350 | mle_loss: 1.206781 | cl_loss: 0.030646 | loss: 1.360011
2022-07-28 00:32:10.265 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 28 | step:  400 | mle_loss: 1.199598 | cl_loss: 0.032785 | loss: 1.363520
2022-07-28 00:32:28.405 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 28 | step:  450 | mle_loss: 1.201091 | cl_loss: 0.029336 | loss: 1.347770
2022-07-28 00:32:46.543 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 28 | step:  500 | mle_loss: 1.174691 | cl_loss: 0.028883 | loss: 1.319106
2022-07-28 00:33:04.650 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 28 | step:  550 | mle_loss: 1.224100 | cl_loss: 0.029887 | loss: 1.373536
2022-07-28 00:33:22.804 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 28 | step:  600 | mle_loss: 1.198988 | cl_loss: 0.030894 | loss: 1.353460
2022-07-28 00:33:40.804 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 28 | step:  650 | mle_loss: 1.216982 | cl_loss: 0.030344 | loss: 1.368702
2022-07-28 00:33:58.705 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 28 | step:  700 | mle_loss: 1.178940 | cl_loss: 0.030656 | loss: 1.332218
2022-07-28 00:34:16.884 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 28 | step:  750 | mle_loss: 1.186055 | cl_loss: 0.030440 | loss: 1.338254
2022-07-28 00:34:35.103 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 28 | step:  800 | mle_loss: 1.189807 | cl_loss: 0.029292 | loss: 1.336266
2022-07-28 00:34:52.947 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 28 | step:  850 | mle_loss: 1.200781 | cl_loss: 0.029863 | loss: 1.350096
2022-07-28 00:35:11.161 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 28 | step:  900 | mle_loss: 1.175473 | cl_loss: 0.029732 | loss: 1.324131
2022-07-28 00:35:29.224 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 28 | step:  950 | mle_loss: 1.175335 | cl_loss: 0.030654 | loss: 1.328604
2022-07-28 00:35:47.660 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 28 | step: 1000 | mle_loss: 1.194463 | cl_loss: 0.030558 | loss: 1.347251
2022-07-28 00:36:05.723 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 28 | step: 1050 | mle_loss: 1.181762 | cl_loss: 0.030297 | loss: 1.333248
2022-07-28 00:36:24.182 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 28 | step: 1100 | mle_loss: 1.156361 | cl_loss: 0.030660 | loss: 1.309663
2022-07-28 00:36:42.065 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 28 | step: 1150 | mle_loss: 1.186213 | cl_loss: 0.029925 | loss: 1.335839
2022-07-28 00:37:00.003 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 28 | step: 1200 | mle_loss: 1.178230 | cl_loss: 0.028535 | loss: 1.320905
2022-07-28 00:37:17.827 | INFO     | processing.dataset:_load_and_cache_examples:43 - Loading examples from cache file data/cache/train_set/train_29.pkl
2022-07-28 00:37:19.733 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 29 | step:    0 | mle_loss: 1.191019 | cl_loss: 0.029391 | loss: 1.337975
2022-07-28 00:37:37.430 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 29 | step:   50 | mle_loss: 1.262235 | cl_loss: 0.028588 | loss: 1.405174
2022-07-28 00:37:55.394 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 29 | step:  100 | mle_loss: 1.255300 | cl_loss: 0.029539 | loss: 1.402993
2022-07-28 00:38:12.992 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 29 | step:  150 | mle_loss: 1.274081 | cl_loss: 0.029080 | loss: 1.419481
2022-07-28 00:38:30.523 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 29 | step:  200 | mle_loss: 1.252813 | cl_loss: 0.028020 | loss: 1.392913
2022-07-28 00:38:47.963 | INFO     | __main__:evaluate:178 - Generating...
2022-07-28 00:40:13.094 | INFO     | __main__:evaluate:188 - Generation finished.
2022-07-28 00:40:13.094 | INFO     | __main__:evaluate:195 - Rouge scores: {'rouge-1': 0.4149, 'rouge-2': 0.2546, 'rouge-l': 0.3659}
2022-07-28 00:40:13.095 | INFO     | __main__:train:137 - Eval loss: 0.0, the best loss: {'loss': 0.0, 'epoch': 0, 'step': 749}
2022-07-28 00:40:13.095 | INFO     | __main__:train:138 - Rouge scores: {'rouge-1': 0.4149, 'rouge-2': 0.2546, 'rouge-l': 0.3659}, the best scores: {'rouge-1': 0.4175, 'rouge-2': 0.2549, 'rouge-l': 0.3735, 'epoch': 1, 'step': 499}
2022-07-28 00:40:13.097 | INFO     | __main__:train:143 - Saving model checkpoint to checkpoints/MoCoBart-1-29-249
2022-07-28 00:40:15.864 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 29 | step:  250 | mle_loss: 1.255453 | cl_loss: 0.028941 | loss: 1.400157
2022-07-28 00:40:33.527 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 29 | step:  300 | mle_loss: 1.285263 | cl_loss: 0.029357 | loss: 1.432049
2022-07-28 00:40:51.122 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 29 | step:  350 | mle_loss: 1.251403 | cl_loss: 0.028039 | loss: 1.391599
2022-07-28 00:41:08.997 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 29 | step:  400 | mle_loss: 1.232523 | cl_loss: 0.028098 | loss: 1.373012
2022-07-28 00:41:26.575 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 29 | step:  450 | mle_loss: 1.234213 | cl_loss: 0.027772 | loss: 1.373073
2022-07-28 00:41:44.080 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 29 | step:  500 | mle_loss: 1.250894 | cl_loss: 0.028074 | loss: 1.391267
2022-07-28 00:42:01.724 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 29 | step:  550 | mle_loss: 1.270834 | cl_loss: 0.028699 | loss: 1.414328
2022-07-28 00:42:19.275 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 29 | step:  600 | mle_loss: 1.257469 | cl_loss: 0.028828 | loss: 1.401612
2022-07-28 00:42:37.007 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 29 | step:  650 | mle_loss: 1.261673 | cl_loss: 0.030046 | loss: 1.411904
2022-07-28 00:42:54.611 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 29 | step:  700 | mle_loss: 1.262671 | cl_loss: 0.028229 | loss: 1.403813
2022-07-28 00:43:12.156 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 29 | step:  750 | mle_loss: 1.234368 | cl_loss: 0.027574 | loss: 1.372237
2022-07-28 00:43:29.871 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 29 | step:  800 | mle_loss: 1.260337 | cl_loss: 0.027989 | loss: 1.400280
2022-07-28 00:43:47.344 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 29 | step:  850 | mle_loss: 1.263129 | cl_loss: 0.027114 | loss: 1.398702
2022-07-28 00:44:05.136 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 29 | step:  900 | mle_loss: 1.250806 | cl_loss: 0.028974 | loss: 1.395675
2022-07-28 00:44:22.749 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 29 | step:  950 | mle_loss: 1.259614 | cl_loss: 0.029188 | loss: 1.405556
2022-07-28 00:44:40.393 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 29 | step: 1000 | mle_loss: 1.240917 | cl_loss: 0.027115 | loss: 1.376494
2022-07-28 00:44:58.371 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 29 | step: 1050 | mle_loss: 1.246560 | cl_loss: 0.028885 | loss: 1.390985
2022-07-28 00:45:16.012 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 29 | step: 1100 | mle_loss: 1.240342 | cl_loss: 0.028121 | loss: 1.380946
2022-07-28 00:45:33.518 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 29 | step: 1150 | mle_loss: 1.277703 | cl_loss: 0.027878 | loss: 1.417095
2022-07-28 00:45:51.018 | INFO     | __main__:train:118 - Epoch:  1 | Chunk: 29 | step: 1200 | mle_loss: 1.242180 | cl_loss: 0.026810 | loss: 1.376229
2022-07-28 00:46:08.436 | INFO     | processing.dataset:_load_and_cache_examples:43 - Loading examples from cache file data/cache/train_set/train_0.pkl
2022-07-28 00:46:10.071 | INFO     | __main__:train:118 - Epoch:  2 | Chunk:  0 | step:    0 | mle_loss: 1.215592 | cl_loss: 0.027942 | loss: 1.355304
2022-07-28 00:46:28.052 | INFO     | __main__:train:118 - Epoch:  2 | Chunk:  0 | step:   50 | mle_loss: 1.118428 | cl_loss: 0.025452 | loss: 1.245691
2022-07-28 00:46:46.169 | INFO     | __main__:train:118 - Epoch:  2 | Chunk:  0 | step:  100 | mle_loss: 1.149517 | cl_loss: 0.025691 | loss: 1.277974
2022-07-28 00:47:04.132 | INFO     | __main__:train:118 - Epoch:  2 | Chunk:  0 | step:  150 | mle_loss: 1.120078 | cl_loss: 0.027313 | loss: 1.256641
2022-07-28 00:47:22.013 | INFO     | __main__:train:118 - Epoch:  2 | Chunk:  0 | step:  200 | mle_loss: 1.142245 | cl_loss: 0.026860 | loss: 1.276543
2022-07-28 00:47:40.229 | INFO     | __main__:train:118 - Epoch:  2 | Chunk:  0 | step:  250 | mle_loss: 1.132895 | cl_loss: 0.028474 | loss: 1.275264
2022-07-28 00:47:58.082 | INFO     | __main__:train:118 - Epoch:  2 | Chunk:  0 | step:  300 | mle_loss: 1.146744 | cl_loss: 0.025780 | loss: 1.275646
2022-07-28 00:48:15.890 | INFO     | __main__:train:118 - Epoch:  2 | Chunk:  0 | step:  350 | mle_loss: 1.126355 | cl_loss: 0.027130 | loss: 1.262007
2022-07-28 00:48:33.998 | INFO     | __main__:train:118 - Epoch:  2 | Chunk:  0 | step:  400 | mle_loss: 1.128593 | cl_loss: 0.026626 | loss: 1.261722
2022-07-28 00:48:52.043 | INFO     | __main__:train:118 - Epoch:  2 | Chunk:  0 | step:  450 | mle_loss: 1.140478 | cl_loss: 0.026707 | loss: 1.274015
2022-07-28 00:49:09.712 | INFO     | __main__:train:118 - Epoch:  2 | Chunk:  0 | step:  500 | mle_loss: 1.112268 | cl_loss: 0.025561 | loss: 1.240076
2022-07-28 00:49:27.569 | INFO     | __main__:train:118 - Epoch:  2 | Chunk:  0 | step:  550 | mle_loss: 1.090146 | cl_loss: 0.026256 | loss: 1.221427
2022-07-28 00:49:45.479 | INFO     | __main__:train:118 - Epoch:  2 | Chunk:  0 | step:  600 | mle_loss: 1.103114 | cl_loss: 0.027638 | loss: 1.241304
2022-07-28 00:50:03.345 | INFO     | __main__:train:118 - Epoch:  2 | Chunk:  0 | step:  650 | mle_loss: 1.106366 | cl_loss: 0.025810 | loss: 1.235417
2022-07-28 00:50:21.070 | INFO     | __main__:train:118 - Epoch:  2 | Chunk:  0 | step:  700 | mle_loss: 1.110497 | cl_loss: 0.025888 | loss: 1.239936
2022-07-28 00:50:39.048 | INFO     | __main__:train:118 - Epoch:  2 | Chunk:  0 | step:  750 | mle_loss: 1.125770 | cl_loss: 0.025997 | loss: 1.255755
2022-07-28 00:50:57.132 | INFO     | __main__:train:118 - Epoch:  2 | Chunk:  0 | step:  800 | mle_loss: 1.113500 | cl_loss: 0.027482 | loss: 1.250911
2022-07-28 00:51:15.347 | INFO     | __main__:train:118 - Epoch:  2 | Chunk:  0 | step:  850 | mle_loss: 1.089851 | cl_loss: 0.025845 | loss: 1.219076
2022-07-28 00:51:33.299 | INFO     | __main__:train:118 - Epoch:  2 | Chunk:  0 | step:  900 | mle_loss: 1.115462 | cl_loss: 0.025308 | loss: 1.242005
2022-07-28 00:51:51.152 | INFO     | __main__:train:118 - Epoch:  2 | Chunk:  0 | step:  950 | mle_loss: 1.097423 | cl_loss: 0.027003 | loss: 1.232440
2022-07-28 00:52:08.696 | INFO     | __main__:evaluate:178 - Generating...
2022-07-28 00:53:26.969 | INFO     | __main__:evaluate:188 - Generation finished.
2022-07-28 00:53:26.970 | INFO     | __main__:evaluate:195 - Rouge scores: {'rouge-1': 0.4079, 'rouge-2': 0.2526, 'rouge-l': 0.3655}
2022-07-28 00:53:26.970 | INFO     | __main__:train:137 - Eval loss: 0.0, the best loss: {'loss': 0.0, 'epoch': 0, 'step': 749}
2022-07-28 00:53:26.970 | INFO     | __main__:train:138 - Rouge scores: {'rouge-1': 0.4079, 'rouge-2': 0.2526, 'rouge-l': 0.3655}, the best scores: {'rouge-1': 0.4175, 'rouge-2': 0.2549, 'rouge-l': 0.3735, 'epoch': 1, 'step': 499}
2022-07-28 00:53:26.971 | INFO     | __main__:train:143 - Saving model checkpoint to checkpoints/MoCoBart-2-0-999
2022-07-28 00:53:29.735 | INFO     | __main__:train:118 - Epoch:  2 | Chunk:  0 | step: 1000 | mle_loss: 1.123969 | cl_loss: 0.026202 | loss: 1.254980
2022-07-28 00:53:47.680 | INFO     | __main__:train:118 - Epoch:  2 | Chunk:  0 | step: 1050 | mle_loss: 1.111292 | cl_loss: 0.028065 | loss: 1.251619
2022-07-28 00:54:05.696 | INFO     | __main__:train:118 - Epoch:  2 | Chunk:  0 | step: 1100 | mle_loss: 1.107811 | cl_loss: 0.025965 | loss: 1.237636
2022-07-28 00:54:23.529 | INFO     | __main__:train:118 - Epoch:  2 | Chunk:  0 | step: 1150 | mle_loss: 1.103643 | cl_loss: 0.025628 | loss: 1.231784
2022-07-28 00:54:41.615 | INFO     | __main__:train:118 - Epoch:  2 | Chunk:  0 | step: 1200 | mle_loss: 1.125406 | cl_loss: 0.026285 | loss: 1.256833
2022-07-28 00:54:58.962 | INFO     | processing.dataset:_load_and_cache_examples:43 - Loading examples from cache file data/cache/train_set/train_1.pkl
2022-07-28 00:55:00.929 | INFO     | __main__:train:118 - Epoch:  2 | Chunk:  1 | step:    0 | mle_loss: 1.112276 | cl_loss: 0.025652 | loss: 1.240536
2022-07-28 00:55:18.430 | INFO     | __main__:train:118 - Epoch:  2 | Chunk:  1 | step:   50 | mle_loss: 1.220339 | cl_loss: 0.029724 | loss: 1.368960
2022-07-28 00:55:36.081 | INFO     | __main__:train:118 - Epoch:  2 | Chunk:  1 | step:  100 | mle_loss: 1.211653 | cl_loss: 0.029350 | loss: 1.358404
2022-07-28 00:55:53.926 | INFO     | __main__:train:118 - Epoch:  2 | Chunk:  1 | step:  150 | mle_loss: 1.216852 | cl_loss: 0.029452 | loss: 1.364112
2022-07-28 00:56:11.785 | INFO     | __main__:train:118 - Epoch:  2 | Chunk:  1 | step:  200 | mle_loss: 1.206490 | cl_loss: 0.029044 | loss: 1.351710
2022-07-28 00:56:29.763 | INFO     | __main__:train:118 - Epoch:  2 | Chunk:  1 | step:  250 | mle_loss: 1.209905 | cl_loss: 0.030921 | loss: 1.364510
2022-07-28 00:56:47.519 | INFO     | __main__:train:118 - Epoch:  2 | Chunk:  1 | step:  300 | mle_loss: 1.208859 | cl_loss: 0.028669 | loss: 1.352205
2022-07-28 00:57:05.089 | INFO     | __main__:train:118 - Epoch:  2 | Chunk:  1 | step:  350 | mle_loss: 1.212581 | cl_loss: 0.030658 | loss: 1.365873
2022-07-28 00:57:22.575 | INFO     | __main__:train:118 - Epoch:  2 | Chunk:  1 | step:  400 | mle_loss: 1.211159 | cl_loss: 0.029722 | loss: 1.359771
2022-07-28 00:57:40.231 | INFO     | __main__:train:118 - Epoch:  2 | Chunk:  1 | step:  450 | mle_loss: 1.160804 | cl_loss: 0.029009 | loss: 1.305848
2022-07-28 00:57:57.930 | INFO     | __main__:train:118 - Epoch:  2 | Chunk:  1 | step:  500 | mle_loss: 1.180709 | cl_loss: 0.029718 | loss: 1.329301
2022-07-28 00:58:15.342 | INFO     | __main__:train:118 - Epoch:  2 | Chunk:  1 | step:  550 | mle_loss: 1.203285 | cl_loss: 0.029530 | loss: 1.350934
2022-07-28 00:58:32.804 | INFO     | __main__:train:118 - Epoch:  2 | Chunk:  1 | step:  600 | mle_loss: 1.190762 | cl_loss: 0.030728 | loss: 1.344401
2022-07-28 00:58:50.386 | INFO     | __main__:train:118 - Epoch:  2 | Chunk:  1 | step:  650 | mle_loss: 1.178621 | cl_loss: 0.031443 | loss: 1.335837
2022-07-28 00:59:08.070 | INFO     | __main__:train:118 - Epoch:  2 | Chunk:  1 | step:  700 | mle_loss: 1.210436 | cl_loss: 0.030020 | loss: 1.360538
2022-07-28 00:59:25.743 | INFO     | __main__:train:118 - Epoch:  2 | Chunk:  1 | step:  750 | mle_loss: 1.209860 | cl_loss: 0.030365 | loss: 1.361686
2022-07-28 00:59:43.406 | INFO     | __main__:train:118 - Epoch:  2 | Chunk:  1 | step:  800 | mle_loss: 1.208213 | cl_loss: 0.028875 | loss: 1.352586
2022-07-28 01:00:01.233 | INFO     | __main__:train:118 - Epoch:  2 | Chunk:  1 | step:  850 | mle_loss: 1.205651 | cl_loss: 0.028698 | loss: 1.349141
2022-07-28 01:00:19.047 | INFO     | __main__:train:118 - Epoch:  2 | Chunk:  1 | step:  900 | mle_loss: 1.171191 | cl_loss: 0.031227 | loss: 1.327327
2022-07-28 01:00:36.797 | INFO     | __main__:train:118 - Epoch:  2 | Chunk:  1 | step:  950 | mle_loss: 1.176921 | cl_loss: 0.029457 | loss: 1.324205
2022-07-28 01:00:54.317 | INFO     | __main__:train:118 - Epoch:  2 | Chunk:  1 | step: 1000 | mle_loss: 1.199554 | cl_loss: 0.031113 | loss: 1.355118
2022-07-28 01:01:11.778 | INFO     | __main__:train:118 - Epoch:  2 | Chunk:  1 | step: 1050 | mle_loss: 1.189634 | cl_loss: 0.029833 | loss: 1.338800
2022-07-28 01:01:29.627 | INFO     | __main__:train:118 - Epoch:  2 | Chunk:  1 | step: 1100 | mle_loss: 1.188141 | cl_loss: 0.032546 | loss: 1.350870
2022-07-28 01:01:47.512 | INFO     | __main__:train:118 - Epoch:  2 | Chunk:  1 | step: 1150 | mle_loss: 1.199916 | cl_loss: 0.030971 | loss: 1.354771
2022-07-28 01:02:05.364 | INFO     | __main__:train:118 - Epoch:  2 | Chunk:  1 | step: 1200 | mle_loss: 1.194384 | cl_loss: 0.028896 | loss: 1.338862
2022-07-28 01:02:23.094 | INFO     | processing.dataset:_load_and_cache_examples:43 - Loading examples from cache file data/cache/train_set/train_2.pkl
2022-07-28 01:02:24.986 | INFO     | __main__:train:118 - Epoch:  2 | Chunk:  2 | step:    0 | mle_loss: 1.197807 | cl_loss: 0.031582 | loss: 1.355719
2022-07-28 01:02:42.942 | INFO     | __main__:train:118 - Epoch:  2 | Chunk:  2 | step:   50 | mle_loss: 1.213098 | cl_loss: 0.028730 | loss: 1.356749
2022-07-28 01:03:00.864 | INFO     | __main__:train:118 - Epoch:  2 | Chunk:  2 | step:  100 | mle_loss: 1.215512 | cl_loss: 0.030021 | loss: 1.365616
2022-07-28 01:03:18.638 | INFO     | __main__:train:118 - Epoch:  2 | Chunk:  2 | step:  150 | mle_loss: 1.208119 | cl_loss: 0.029822 | loss: 1.357232
2022-07-28 01:03:36.371 | INFO     | __main__:train:118 - Epoch:  2 | Chunk:  2 | step:  200 | mle_loss: 1.215072 | cl_loss: 0.029824 | loss: 1.364191
2022-07-28 01:03:54.235 | INFO     | __main__:train:118 - Epoch:  2 | Chunk:  2 | step:  250 | mle_loss: 1.219050 | cl_loss: 0.029260 | loss: 1.365352
2022-07-28 01:04:11.697 | INFO     | __main__:train:118 - Epoch:  2 | Chunk:  2 | step:  300 | mle_loss: 1.212686 | cl_loss: 0.029352 | loss: 1.359448
2022-07-28 01:04:29.475 | INFO     | __main__:train:118 - Epoch:  2 | Chunk:  2 | step:  350 | mle_loss: 1.217641 | cl_loss: 0.029661 | loss: 1.365948
2022-07-28 01:04:47.391 | INFO     | __main__:train:118 - Epoch:  2 | Chunk:  2 | step:  400 | mle_loss: 1.195015 | cl_loss: 0.029293 | loss: 1.341480
2022-07-28 01:05:05.147 | INFO     | __main__:train:118 - Epoch:  2 | Chunk:  2 | step:  450 | mle_loss: 1.217525 | cl_loss: 0.029731 | loss: 1.366181
2022-07-28 01:05:22.903 | INFO     | __main__:evaluate:178 - Generating...
2022-07-28 01:06:45.632 | INFO     | __main__:evaluate:188 - Generation finished.
2022-07-28 01:06:45.633 | INFO     | __main__:evaluate:195 - Rouge scores: {'rouge-1': 0.4062, 'rouge-2': 0.2475, 'rouge-l': 0.3611}
2022-07-28 01:06:45.633 | INFO     | __main__:train:137 - Eval loss: 0.0, the best loss: {'loss': 0.0, 'epoch': 0, 'step': 749}
2022-07-28 01:06:45.633 | INFO     | __main__:train:138 - Rouge scores: {'rouge-1': 0.4062, 'rouge-2': 0.2475, 'rouge-l': 0.3611}, the best scores: {'rouge-1': 0.4175, 'rouge-2': 0.2549, 'rouge-l': 0.3735, 'epoch': 1, 'step': 499}
2022-07-28 01:06:45.657 | INFO     | __main__:train:143 - Saving model checkpoint to checkpoints/MoCoBart-2-2-499
2022-07-28 01:06:47.772 | INFO     | __main__:train:118 - Epoch:  2 | Chunk:  2 | step:  500 | mle_loss: 1.196076 | cl_loss: 0.029870 | loss: 1.345428
2022-07-28 01:07:05.427 | INFO     | __main__:train:118 - Epoch:  2 | Chunk:  2 | step:  550 | mle_loss: 1.232696 | cl_loss: 0.030284 | loss: 1.384118
2022-07-28 01:07:23.329 | INFO     | __main__:train:118 - Epoch:  2 | Chunk:  2 | step:  600 | mle_loss: 1.209308 | cl_loss: 0.028508 | loss: 1.351847
2022-07-28 01:07:40.999 | INFO     | __main__:train:118 - Epoch:  2 | Chunk:  2 | step:  650 | mle_loss: 1.187803 | cl_loss: 0.030434 | loss: 1.339975
2022-07-28 01:07:58.813 | INFO     | __main__:train:118 - Epoch:  2 | Chunk:  2 | step:  700 | mle_loss: 1.184442 | cl_loss: 0.029238 | loss: 1.330632
2022-07-28 01:08:16.742 | INFO     | __main__:train:118 - Epoch:  2 | Chunk:  2 | step:  750 | mle_loss: 1.211692 | cl_loss: 0.029726 | loss: 1.360323
2022-07-28 01:08:34.601 | INFO     | __main__:train:118 - Epoch:  2 | Chunk:  2 | step:  800 | mle_loss: 1.206421 | cl_loss: 0.029519 | loss: 1.354017
2022-07-28 01:08:52.687 | INFO     | __main__:train:118 - Epoch:  2 | Chunk:  2 | step:  850 | mle_loss: 1.208584 | cl_loss: 0.028983 | loss: 1.353499
2022-07-28 01:09:10.480 | INFO     | __main__:train:118 - Epoch:  2 | Chunk:  2 | step:  900 | mle_loss: 1.208173 | cl_loss: 0.029497 | loss: 1.355656
2022-07-28 01:09:28.291 | INFO     | __main__:train:118 - Epoch:  2 | Chunk:  2 | step:  950 | mle_loss: 1.194798 | cl_loss: 0.029473 | loss: 1.342164
2022-07-28 01:09:46.161 | INFO     | __main__:train:118 - Epoch:  2 | Chunk:  2 | step: 1000 | mle_loss: 1.189561 | cl_loss: 0.029244 | loss: 1.335783
2022-07-28 01:10:03.989 | INFO     | __main__:train:118 - Epoch:  2 | Chunk:  2 | step: 1050 | mle_loss: 1.197976 | cl_loss: 0.029507 | loss: 1.345512
2022-07-28 01:10:21.708 | INFO     | __main__:train:118 - Epoch:  2 | Chunk:  2 | step: 1100 | mle_loss: 1.194611 | cl_loss: 0.028498 | loss: 1.337099
2022-07-28 01:10:39.594 | INFO     | __main__:train:118 - Epoch:  2 | Chunk:  2 | step: 1150 | mle_loss: 1.211241 | cl_loss: 0.027901 | loss: 1.350748
2022-07-28 01:10:57.481 | INFO     | __main__:train:118 - Epoch:  2 | Chunk:  2 | step: 1200 | mle_loss: 1.213353 | cl_loss: 0.027946 | loss: 1.353082
2022-07-28 01:11:15.027 | INFO     | processing.dataset:_load_and_cache_examples:43 - Loading examples from cache file data/cache/train_set/train_3.pkl
2022-07-28 01:11:17.355 | INFO     | __main__:train:118 - Epoch:  2 | Chunk:  3 | step:    0 | mle_loss: 1.176365 | cl_loss: 0.029870 | loss: 1.325715
2022-07-28 01:11:35.652 | INFO     | __main__:train:118 - Epoch:  2 | Chunk:  3 | step:   50 | mle_loss: 1.162321 | cl_loss: 0.033632 | loss: 1.330480
2022-07-28 01:11:54.131 | INFO     | __main__:train:118 - Epoch:  2 | Chunk:  3 | step:  100 | mle_loss: 1.140397 | cl_loss: 0.033631 | loss: 1.308553
2022-07-28 01:12:12.267 | INFO     | __main__:train:118 - Epoch:  2 | Chunk:  3 | step:  150 | mle_loss: 1.147398 | cl_loss: 0.033147 | loss: 1.313131
2022-07-28 01:12:30.532 | INFO     | __main__:train:118 - Epoch:  2 | Chunk:  3 | step:  200 | mle_loss: 1.119288 | cl_loss: 0.033258 | loss: 1.285579
2022-07-28 01:12:48.579 | INFO     | __main__:train:118 - Epoch:  2 | Chunk:  3 | step:  250 | mle_loss: 1.154055 | cl_loss: 0.033665 | loss: 1.322380
2022-07-28 01:13:06.962 | INFO     | __main__:train:118 - Epoch:  2 | Chunk:  3 | step:  300 | mle_loss: 1.134030 | cl_loss: 0.033618 | loss: 1.302120
2022-07-28 01:13:25.018 | INFO     | __main__:train:118 - Epoch:  2 | Chunk:  3 | step:  350 | mle_loss: 1.125293 | cl_loss: 0.031913 | loss: 1.284859
2022-07-28 01:13:43.070 | INFO     | __main__:train:118 - Epoch:  2 | Chunk:  3 | step:  400 | mle_loss: 1.116917 | cl_loss: 0.032228 | loss: 1.278057
2022-07-28 01:14:01.152 | INFO     | __main__:train:118 - Epoch:  2 | Chunk:  3 | step:  450 | mle_loss: 1.119333 | cl_loss: 0.032349 | loss: 1.281078
2022-07-28 01:14:19.118 | INFO     | __main__:train:118 - Epoch:  2 | Chunk:  3 | step:  500 | mle_loss: 1.128867 | cl_loss: 0.032251 | loss: 1.290122
2022-07-28 01:14:37.137 | INFO     | __main__:train:118 - Epoch:  2 | Chunk:  3 | step:  550 | mle_loss: 1.124448 | cl_loss: 0.032191 | loss: 1.285401
2022-07-28 01:14:55.189 | INFO     | __main__:train:118 - Epoch:  2 | Chunk:  3 | step:  600 | mle_loss: 1.134871 | cl_loss: 0.031443 | loss: 1.292086
2022-07-28 01:15:14.158 | INFO     | __main__:train:118 - Epoch:  2 | Chunk:  3 | step:  650 | mle_loss: 1.133719 | cl_loss: 0.033598 | loss: 1.301710
2022-07-28 01:15:32.486 | INFO     | __main__:train:118 - Epoch:  2 | Chunk:  3 | step:  700 | mle_loss: 1.121340 | cl_loss: 0.030975 | loss: 1.276214
2022-07-28 01:15:50.723 | INFO     | __main__:train:118 - Epoch:  2 | Chunk:  3 | step:  750 | mle_loss: 1.131203 | cl_loss: 0.031406 | loss: 1.288236
2022-07-28 01:16:08.930 | INFO     | __main__:train:118 - Epoch:  2 | Chunk:  3 | step:  800 | mle_loss: 1.118646 | cl_loss: 0.031962 | loss: 1.278454
2022-07-28 01:16:27.075 | INFO     | __main__:train:118 - Epoch:  2 | Chunk:  3 | step:  850 | mle_loss: 1.133352 | cl_loss: 0.033558 | loss: 1.301145
2022-07-28 01:16:45.096 | INFO     | __main__:train:118 - Epoch:  2 | Chunk:  3 | step:  900 | mle_loss: 1.125734 | cl_loss: 0.030886 | loss: 1.280163
2022-07-28 01:17:03.375 | INFO     | __main__:train:118 - Epoch:  2 | Chunk:  3 | step:  950 | mle_loss: 1.135117 | cl_loss: 0.030530 | loss: 1.287766
2022-07-28 01:17:21.652 | INFO     | __main__:train:118 - Epoch:  2 | Chunk:  3 | step: 1000 | mle_loss: 1.119102 | cl_loss: 0.031142 | loss: 1.274813
2022-07-28 01:17:39.862 | INFO     | __main__:train:118 - Epoch:  2 | Chunk:  3 | step: 1050 | mle_loss: 1.118735 | cl_loss: 0.032564 | loss: 1.281555
2022-07-28 01:17:58.091 | INFO     | __main__:train:118 - Epoch:  2 | Chunk:  3 | step: 1100 | mle_loss: 1.132751 | cl_loss: 0.031797 | loss: 1.291738
2022-07-28 01:18:16.189 | INFO     | __main__:train:118 - Epoch:  2 | Chunk:  3 | step: 1150 | mle_loss: 1.152726 | cl_loss: 0.031394 | loss: 1.309697
2022-07-28 01:18:34.365 | INFO     | __main__:train:118 - Epoch:  2 | Chunk:  3 | step: 1200 | mle_loss: 1.136572 | cl_loss: 0.030990 | loss: 1.291523
2022-07-28 01:18:52.196 | INFO     | __main__:evaluate:178 - Generating...
2022-07-28 01:20:14.815 | INFO     | __main__:evaluate:188 - Generation finished.
2022-07-28 01:20:14.816 | INFO     | __main__:evaluate:195 - Rouge scores: {'rouge-1': 0.4161, 'rouge-2': 0.256, 'rouge-l': 0.3713}
2022-07-28 01:20:14.816 | INFO     | __main__:train:137 - Eval loss: 0.0, the best loss: {'loss': 0.0, 'epoch': 0, 'step': 749}
2022-07-28 01:20:14.816 | INFO     | __main__:train:138 - Rouge scores: {'rouge-1': 0.4161, 'rouge-2': 0.256, 'rouge-l': 0.3713}, the best scores: {'rouge-1': 0.4175, 'rouge-2': 0.2549, 'rouge-l': 0.3735, 'epoch': 1, 'step': 499}
2022-07-28 01:20:14.818 | INFO     | __main__:train:143 - Saving model checkpoint to checkpoints/MoCoBart-2-3-1249
2022-07-28 01:20:17.347 | INFO     | processing.dataset:_load_and_cache_examples:43 - Loading examples from cache file data/cache/train_set/train_4.pkl
2022-07-28 01:20:19.226 | INFO     | __main__:train:118 - Epoch:  2 | Chunk:  4 | step:    0 | mle_loss: 1.075669 | cl_loss: 0.030614 | loss: 1.228738
2022-07-28 01:20:36.967 | INFO     | __main__:train:118 - Epoch:  2 | Chunk:  4 | step:   50 | mle_loss: 1.125852 | cl_loss: 0.031131 | loss: 1.281508
2022-07-28 01:20:54.663 | INFO     | __main__:train:118 - Epoch:  2 | Chunk:  4 | step:  100 | mle_loss: 1.125424 | cl_loss: 0.031083 | loss: 1.280840
2022-07-28 01:21:12.328 | INFO     | __main__:train:118 - Epoch:  2 | Chunk:  4 | step:  150 | mle_loss: 1.093629 | cl_loss: 0.031325 | loss: 1.250253
2022-07-28 01:21:30.052 | INFO     | __main__:train:118 - Epoch:  2 | Chunk:  4 | step:  200 | mle_loss: 1.101960 | cl_loss: 0.029776 | loss: 1.250838
2022-07-28 01:21:47.409 | INFO     | __main__:train:118 - Epoch:  2 | Chunk:  4 | step:  250 | mle_loss: 1.109705 | cl_loss: 0.032917 | loss: 1.274289
2022-07-28 01:22:05.032 | INFO     | __main__:train:118 - Epoch:  2 | Chunk:  4 | step:  300 | mle_loss: 1.127974 | cl_loss: 0.028163 | loss: 1.268787
2022-07-28 01:22:22.925 | INFO     | __main__:train:118 - Epoch:  2 | Chunk:  4 | step:  350 | mle_loss: 1.104617 | cl_loss: 0.030841 | loss: 1.258819
2022-07-28 01:22:41.027 | INFO     | __main__:train:118 - Epoch:  2 | Chunk:  4 | step:  400 | mle_loss: 1.071974 | cl_loss: 0.031311 | loss: 1.228530
2022-07-28 01:22:59.800 | INFO     | __main__:train:118 - Epoch:  2 | Chunk:  4 | step:  450 | mle_loss: 1.094710 | cl_loss: 0.029672 | loss: 1.243072
2022-07-28 01:23:17.870 | INFO     | __main__:train:118 - Epoch:  2 | Chunk:  4 | step:  500 | mle_loss: 1.092365 | cl_loss: 0.029541 | loss: 1.240072
2022-07-28 01:23:35.895 | INFO     | __main__:train:118 - Epoch:  2 | Chunk:  4 | step:  550 | mle_loss: 1.054747 | cl_loss: 0.029134 | loss: 1.200415
2022-07-28 01:23:53.829 | INFO     | __main__:train:118 - Epoch:  2 | Chunk:  4 | step:  600 | mle_loss: 1.090967 | cl_loss: 0.029505 | loss: 1.238492
2022-07-28 01:24:11.826 | INFO     | __main__:train:118 - Epoch:  2 | Chunk:  4 | step:  650 | mle_loss: 1.081402 | cl_loss: 0.030505 | loss: 1.233926
2022-07-28 01:24:30.052 | INFO     | __main__:train:118 - Epoch:  2 | Chunk:  4 | step:  700 | mle_loss: 1.071138 | cl_loss: 0.029799 | loss: 1.220133
2022-07-28 01:24:48.022 | INFO     | __main__:train:118 - Epoch:  2 | Chunk:  4 | step:  750 | mle_loss: 1.085858 | cl_loss: 0.030605 | loss: 1.238883
2022-07-28 01:25:05.960 | INFO     | __main__:train:118 - Epoch:  2 | Chunk:  4 | step:  800 | mle_loss: 1.083202 | cl_loss: 0.030756 | loss: 1.236984
2022-07-28 01:25:24.065 | INFO     | __main__:train:118 - Epoch:  2 | Chunk:  4 | step:  850 | mle_loss: 1.078710 | cl_loss: 0.029815 | loss: 1.227786
2022-07-28 01:25:42.986 | INFO     | __main__:train:118 - Epoch:  2 | Chunk:  4 | step:  900 | mle_loss: 1.077926 | cl_loss: 0.029180 | loss: 1.223826
2022-07-28 01:26:00.808 | INFO     | __main__:train:118 - Epoch:  2 | Chunk:  4 | step:  950 | mle_loss: 1.072575 | cl_loss: 0.029783 | loss: 1.221491
2022-07-28 01:26:18.628 | INFO     | __main__:train:118 - Epoch:  2 | Chunk:  4 | step: 1000 | mle_loss: 1.090634 | cl_loss: 0.030667 | loss: 1.243971
2022-07-28 01:26:36.481 | INFO     | __main__:train:118 - Epoch:  2 | Chunk:  4 | step: 1050 | mle_loss: 1.099518 | cl_loss: 0.030817 | loss: 1.253603
2022-07-28 01:26:54.235 | INFO     | __main__:train:118 - Epoch:  2 | Chunk:  4 | step: 1100 | mle_loss: 1.086501 | cl_loss: 0.031806 | loss: 1.245529
2022-07-28 01:27:12.151 | INFO     | __main__:train:118 - Epoch:  2 | Chunk:  4 | step: 1150 | mle_loss: 1.089646 | cl_loss: 0.031810 | loss: 1.248696
2022-07-28 01:27:29.935 | INFO     | __main__:train:118 - Epoch:  2 | Chunk:  4 | step: 1200 | mle_loss: 1.093847 | cl_loss: 0.030902 | loss: 1.248357
2022-07-28 01:27:47.828 | INFO     | processing.dataset:_load_and_cache_examples:43 - Loading examples from cache file data/cache/train_set/train_5.pkl
2022-07-28 01:27:49.694 | INFO     | __main__:train:118 - Epoch:  2 | Chunk:  5 | step:    0 | mle_loss: 1.081683 | cl_loss: 0.027865 | loss: 1.221009
2022-07-28 01:28:08.541 | INFO     | __main__:train:118 - Epoch:  2 | Chunk:  5 | step:   50 | mle_loss: 1.182194 | cl_loss: 0.028097 | loss: 1.322678
2022-07-28 01:28:26.663 | INFO     | __main__:train:118 - Epoch:  2 | Chunk:  5 | step:  100 | mle_loss: 1.179904 | cl_loss: 0.026682 | loss: 1.313313
2022-07-28 01:28:44.973 | INFO     | __main__:train:118 - Epoch:  2 | Chunk:  5 | step:  150 | mle_loss: 1.172128 | cl_loss: 0.026455 | loss: 1.304403
2022-07-28 01:29:03.103 | INFO     | __main__:train:118 - Epoch:  2 | Chunk:  5 | step:  200 | mle_loss: 1.181908 | cl_loss: 0.028084 | loss: 1.322330
2022-07-28 01:29:20.972 | INFO     | __main__:train:118 - Epoch:  2 | Chunk:  5 | step:  250 | mle_loss: 1.196699 | cl_loss: 0.028400 | loss: 1.338700
2022-07-28 01:29:38.998 | INFO     | __main__:train:118 - Epoch:  2 | Chunk:  5 | step:  300 | mle_loss: 1.189717 | cl_loss: 0.028363 | loss: 1.331530
2022-07-28 01:29:57.303 | INFO     | __main__:train:118 - Epoch:  2 | Chunk:  5 | step:  350 | mle_loss: 1.180727 | cl_loss: 0.026519 | loss: 1.313321
2022-07-28 01:30:15.320 | INFO     | __main__:train:118 - Epoch:  2 | Chunk:  5 | step:  400 | mle_loss: 1.173757 | cl_loss: 0.029111 | loss: 1.319310
2022-07-28 01:30:33.396 | INFO     | __main__:train:118 - Epoch:  2 | Chunk:  5 | step:  450 | mle_loss: 1.164248 | cl_loss: 0.028947 | loss: 1.308985
2022-07-28 01:30:51.594 | INFO     | __main__:train:118 - Epoch:  2 | Chunk:  5 | step:  500 | mle_loss: 1.179475 | cl_loss: 0.029507 | loss: 1.327012
2022-07-28 01:31:09.453 | INFO     | __main__:train:118 - Epoch:  2 | Chunk:  5 | step:  550 | mle_loss: 1.180763 | cl_loss: 0.028612 | loss: 1.323822
2022-07-28 01:31:27.487 | INFO     | __main__:train:118 - Epoch:  2 | Chunk:  5 | step:  600 | mle_loss: 1.168253 | cl_loss: 0.026582 | loss: 1.301162
2022-07-28 01:31:45.523 | INFO     | __main__:train:118 - Epoch:  2 | Chunk:  5 | step:  650 | mle_loss: 1.177851 | cl_loss: 0.026955 | loss: 1.312626
2022-07-28 01:32:03.573 | INFO     | __main__:train:118 - Epoch:  2 | Chunk:  5 | step:  700 | mle_loss: 1.171601 | cl_loss: 0.028285 | loss: 1.313028
2022-07-28 01:32:21.273 | INFO     | __main__:evaluate:178 - Generating...
2022-07-28 01:33:45.335 | INFO     | __main__:evaluate:188 - Generation finished.
2022-07-28 01:33:45.336 | INFO     | __main__:evaluate:195 - Rouge scores: {'rouge-1': 0.4049, 'rouge-2': 0.2472, 'rouge-l': 0.3604}
2022-07-28 01:33:45.336 | INFO     | __main__:train:137 - Eval loss: 0.0, the best loss: {'loss': 0.0, 'epoch': 0, 'step': 749}
2022-07-28 01:33:45.336 | INFO     | __main__:train:138 - Rouge scores: {'rouge-1': 0.4049, 'rouge-2': 0.2472, 'rouge-l': 0.3604}, the best scores: {'rouge-1': 0.4175, 'rouge-2': 0.2549, 'rouge-l': 0.3735, 'epoch': 1, 'step': 499}
2022-07-28 01:33:45.337 | INFO     | __main__:train:143 - Saving model checkpoint to checkpoints/MoCoBart-2-5-749
2022-07-28 01:33:47.811 | INFO     | __main__:train:118 - Epoch:  2 | Chunk:  5 | step:  750 | mle_loss: 1.163497 | cl_loss: 0.027703 | loss: 1.302013
2022-07-28 01:34:05.643 | INFO     | __main__:train:118 - Epoch:  2 | Chunk:  5 | step:  800 | mle_loss: 1.167540 | cl_loss: 0.027002 | loss: 1.302550
2022-07-28 01:34:23.604 | INFO     | __main__:train:118 - Epoch:  2 | Chunk:  5 | step:  850 | mle_loss: 1.153450 | cl_loss: 0.027269 | loss: 1.289793
2022-07-28 01:34:41.695 | INFO     | __main__:train:118 - Epoch:  2 | Chunk:  5 | step:  900 | mle_loss: 1.187500 | cl_loss: 0.029021 | loss: 1.332606
2022-07-28 01:34:59.614 | INFO     | __main__:train:118 - Epoch:  2 | Chunk:  5 | step:  950 | mle_loss: 1.195731 | cl_loss: 0.027079 | loss: 1.331128
2022-07-28 01:35:17.698 | INFO     | __main__:train:118 - Epoch:  2 | Chunk:  5 | step: 1000 | mle_loss: 1.178299 | cl_loss: 0.027678 | loss: 1.316689
2022-07-28 01:35:35.792 | INFO     | __main__:train:118 - Epoch:  2 | Chunk:  5 | step: 1050 | mle_loss: 1.162913 | cl_loss: 0.027858 | loss: 1.302204
2022-07-28 01:35:53.879 | INFO     | __main__:train:118 - Epoch:  2 | Chunk:  5 | step: 1100 | mle_loss: 1.187477 | cl_loss: 0.029006 | loss: 1.332508
2022-07-28 01:36:11.973 | INFO     | __main__:train:118 - Epoch:  2 | Chunk:  5 | step: 1150 | mle_loss: 1.161898 | cl_loss: 0.027274 | loss: 1.298270
2022-07-28 01:36:30.146 | INFO     | __main__:train:118 - Epoch:  2 | Chunk:  5 | step: 1200 | mle_loss: 1.154429 | cl_loss: 0.028605 | loss: 1.297455
2022-07-28 01:36:47.774 | INFO     | processing.dataset:_load_and_cache_examples:43 - Loading examples from cache file data/cache/train_set/train_6.pkl
2022-07-28 01:36:49.390 | INFO     | __main__:train:118 - Epoch:  2 | Chunk:  6 | step:    0 | mle_loss: 1.171973 | cl_loss: 0.028177 | loss: 1.312860
2022-07-28 01:37:07.319 | INFO     | __main__:train:118 - Epoch:  2 | Chunk:  6 | step:   50 | mle_loss: 1.218405 | cl_loss: 0.029828 | loss: 1.367546
2022-07-28 01:37:25.324 | INFO     | __main__:train:118 - Epoch:  2 | Chunk:  6 | step:  100 | mle_loss: 1.207923 | cl_loss: 0.030359 | loss: 1.359720
2022-07-28 01:37:43.326 | INFO     | __main__:train:118 - Epoch:  2 | Chunk:  6 | step:  150 | mle_loss: 1.224384 | cl_loss: 0.030259 | loss: 1.375678
2022-07-28 01:38:01.525 | INFO     | __main__:train:118 - Epoch:  2 | Chunk:  6 | step:  200 | mle_loss: 1.202119 | cl_loss: 0.030461 | loss: 1.354425
2022-07-28 01:38:19.679 | INFO     | __main__:train:118 - Epoch:  2 | Chunk:  6 | step:  250 | mle_loss: 1.192954 | cl_loss: 0.030351 | loss: 1.344711
2022-07-28 01:38:37.770 | INFO     | __main__:train:118 - Epoch:  2 | Chunk:  6 | step:  300 | mle_loss: 1.222884 | cl_loss: 0.030311 | loss: 1.374441
2022-07-28 01:38:56.001 | INFO     | __main__:train:118 - Epoch:  2 | Chunk:  6 | step:  350 | mle_loss: 1.188993 | cl_loss: 0.030508 | loss: 1.341534
2022-07-28 01:39:14.236 | INFO     | __main__:train:118 - Epoch:  2 | Chunk:  6 | step:  400 | mle_loss: 1.214415 | cl_loss: 0.029432 | loss: 1.361576
2022-07-28 01:39:32.370 | INFO     | __main__:train:118 - Epoch:  2 | Chunk:  6 | step:  450 | mle_loss: 1.192921 | cl_loss: 0.031240 | loss: 1.349121
2022-07-28 01:39:50.345 | INFO     | __main__:train:118 - Epoch:  2 | Chunk:  6 | step:  500 | mle_loss: 1.193429 | cl_loss: 0.028798 | loss: 1.337418
2022-07-28 01:40:08.374 | INFO     | __main__:train:118 - Epoch:  2 | Chunk:  6 | step:  550 | mle_loss: 1.208577 | cl_loss: 0.029786 | loss: 1.357506
2022-07-28 01:40:26.139 | INFO     | __main__:train:118 - Epoch:  2 | Chunk:  6 | step:  600 | mle_loss: 1.177219 | cl_loss: 0.028479 | loss: 1.319612
2022-07-28 01:40:44.039 | INFO     | __main__:train:118 - Epoch:  2 | Chunk:  6 | step:  650 | mle_loss: 1.188942 | cl_loss: 0.028577 | loss: 1.331828
2022-07-28 01:41:02.056 | INFO     | __main__:train:118 - Epoch:  2 | Chunk:  6 | step:  700 | mle_loss: 1.207193 | cl_loss: 0.029460 | loss: 1.354494
2022-07-28 01:41:20.136 | INFO     | __main__:train:118 - Epoch:  2 | Chunk:  6 | step:  750 | mle_loss: 1.213265 | cl_loss: 0.030233 | loss: 1.364430
2022-07-28 01:41:38.134 | INFO     | __main__:train:118 - Epoch:  2 | Chunk:  6 | step:  800 | mle_loss: 1.192490 | cl_loss: 0.028679 | loss: 1.335886
2022-07-28 01:41:56.318 | INFO     | __main__:train:118 - Epoch:  2 | Chunk:  6 | step:  850 | mle_loss: 1.181624 | cl_loss: 0.030021 | loss: 1.331731
2022-07-28 01:42:14.324 | INFO     | __main__:train:118 - Epoch:  2 | Chunk:  6 | step:  900 | mle_loss: 1.203541 | cl_loss: 0.028910 | loss: 1.348091
2022-07-28 01:42:32.184 | INFO     | __main__:train:118 - Epoch:  2 | Chunk:  6 | step:  950 | mle_loss: 1.194302 | cl_loss: 0.028840 | loss: 1.338501
2022-07-28 01:42:50.331 | INFO     | __main__:train:118 - Epoch:  2 | Chunk:  6 | step: 1000 | mle_loss: 1.175733 | cl_loss: 0.028589 | loss: 1.318678
2022-07-28 01:43:08.473 | INFO     | __main__:train:118 - Epoch:  2 | Chunk:  6 | step: 1050 | mle_loss: 1.187695 | cl_loss: 0.028515 | loss: 1.330272
2022-07-28 01:43:26.614 | INFO     | __main__:train:118 - Epoch:  2 | Chunk:  6 | step: 1100 | mle_loss: 1.177494 | cl_loss: 0.029312 | loss: 1.324054
2022-07-28 01:43:44.776 | INFO     | __main__:train:118 - Epoch:  2 | Chunk:  6 | step: 1150 | mle_loss: 1.221205 | cl_loss: 0.030102 | loss: 1.371713
2022-07-28 01:44:02.931 | INFO     | __main__:train:118 - Epoch:  2 | Chunk:  6 | step: 1200 | mle_loss: 1.222912 | cl_loss: 0.029092 | loss: 1.368371
2022-07-28 01:44:20.587 | INFO     | processing.dataset:_load_and_cache_examples:43 - Loading examples from cache file data/cache/train_set/train_7.pkl
2022-07-28 01:44:22.944 | INFO     | __main__:train:118 - Epoch:  2 | Chunk:  7 | step:    0 | mle_loss: 1.167760 | cl_loss: 0.027444 | loss: 1.304980
2022-07-28 01:44:40.724 | INFO     | __main__:train:118 - Epoch:  2 | Chunk:  7 | step:   50 | mle_loss: 1.346395 | cl_loss: 0.036318 | loss: 1.527983
2022-07-28 01:44:58.518 | INFO     | __main__:train:118 - Epoch:  2 | Chunk:  7 | step:  100 | mle_loss: 1.321971 | cl_loss: 0.037217 | loss: 1.508054
2022-07-28 01:45:16.675 | INFO     | __main__:train:118 - Epoch:  2 | Chunk:  7 | step:  150 | mle_loss: 1.281001 | cl_loss: 0.035109 | loss: 1.456545
2022-07-28 01:45:34.786 | INFO     | __main__:train:118 - Epoch:  2 | Chunk:  7 | step:  200 | mle_loss: 1.324686 | cl_loss: 0.036741 | loss: 1.508393
2022-07-28 01:45:52.388 | INFO     | __main__:evaluate:178 - Generating...
2022-07-28 01:47:16.064 | INFO     | __main__:evaluate:188 - Generation finished.
2022-07-28 01:47:16.065 | INFO     | __main__:evaluate:195 - Rouge scores: {'rouge-1': 0.4062, 'rouge-2': 0.2479, 'rouge-l': 0.3642}
2022-07-28 01:47:16.065 | INFO     | __main__:train:137 - Eval loss: 0.0, the best loss: {'loss': 0.0, 'epoch': 0, 'step': 749}
2022-07-28 01:47:16.065 | INFO     | __main__:train:138 - Rouge scores: {'rouge-1': 0.4062, 'rouge-2': 0.2479, 'rouge-l': 0.3642}, the best scores: {'rouge-1': 0.4175, 'rouge-2': 0.2549, 'rouge-l': 0.3735, 'epoch': 1, 'step': 499}
2022-07-28 01:47:16.066 | INFO     | __main__:train:143 - Saving model checkpoint to checkpoints/MoCoBart-2-7-249
2022-07-28 01:47:18.131 | INFO     | __main__:train:118 - Epoch:  2 | Chunk:  7 | step:  250 | mle_loss: 1.304194 | cl_loss: 0.036358 | loss: 1.485986
2022-07-28 01:47:36.037 | INFO     | __main__:train:118 - Epoch:  2 | Chunk:  7 | step:  300 | mle_loss: 1.318432 | cl_loss: 0.036793 | loss: 1.502399
2022-07-28 01:47:53.911 | INFO     | __main__:train:118 - Epoch:  2 | Chunk:  7 | step:  350 | mle_loss: 1.295037 | cl_loss: 0.035205 | loss: 1.471061
2022-07-28 01:48:11.830 | INFO     | __main__:train:118 - Epoch:  2 | Chunk:  7 | step:  400 | mle_loss: 1.258971 | cl_loss: 0.031698 | loss: 1.417462
2022-07-28 01:48:29.751 | INFO     | __main__:train:118 - Epoch:  2 | Chunk:  7 | step:  450 | mle_loss: 1.284433 | cl_loss: 0.034346 | loss: 1.456164
2022-07-28 01:48:47.750 | INFO     | __main__:train:118 - Epoch:  2 | Chunk:  7 | step:  500 | mle_loss: 1.316981 | cl_loss: 0.035335 | loss: 1.493658
2022-07-28 01:49:05.706 | INFO     | __main__:train:118 - Epoch:  2 | Chunk:  7 | step:  550 | mle_loss: 1.276741 | cl_loss: 0.033876 | loss: 1.446122
2022-07-28 01:49:23.569 | INFO     | __main__:train:118 - Epoch:  2 | Chunk:  7 | step:  600 | mle_loss: 1.289471 | cl_loss: 0.032414 | loss: 1.451542
2022-07-28 01:49:41.511 | INFO     | __main__:train:118 - Epoch:  2 | Chunk:  7 | step:  650 | mle_loss: 1.267217 | cl_loss: 0.031182 | loss: 1.423125
2022-07-28 01:49:59.346 | INFO     | __main__:train:118 - Epoch:  2 | Chunk:  7 | step:  700 | mle_loss: 1.302658 | cl_loss: 0.031865 | loss: 1.461985
2022-07-28 01:50:17.299 | INFO     | __main__:train:118 - Epoch:  2 | Chunk:  7 | step:  750 | mle_loss: 1.255635 | cl_loss: 0.032214 | loss: 1.416707
2022-07-28 01:50:35.071 | INFO     | __main__:train:118 - Epoch:  2 | Chunk:  7 | step:  800 | mle_loss: 1.295961 | cl_loss: 0.032417 | loss: 1.458045
2022-07-28 01:50:52.995 | INFO     | __main__:train:118 - Epoch:  2 | Chunk:  7 | step:  850 | mle_loss: 1.294839 | cl_loss: 0.030896 | loss: 1.449320
2022-07-28 01:51:10.890 | INFO     | __main__:train:118 - Epoch:  2 | Chunk:  7 | step:  900 | mle_loss: 1.296481 | cl_loss: 0.030985 | loss: 1.451406
2022-07-28 01:51:28.933 | INFO     | __main__:train:118 - Epoch:  2 | Chunk:  7 | step:  950 | mle_loss: 1.263208 | cl_loss: 0.030610 | loss: 1.416259
2022-07-28 01:51:47.091 | INFO     | __main__:train:118 - Epoch:  2 | Chunk:  7 | step: 1000 | mle_loss: 1.267811 | cl_loss: 0.031383 | loss: 1.424727
2022-07-28 01:52:05.194 | INFO     | __main__:train:118 - Epoch:  2 | Chunk:  7 | step: 1050 | mle_loss: 1.275819 | cl_loss: 0.030967 | loss: 1.430655
2022-07-28 01:52:23.222 | INFO     | __main__:train:118 - Epoch:  2 | Chunk:  7 | step: 1100 | mle_loss: 1.297071 | cl_loss: 0.030478 | loss: 1.449463
2022-07-28 01:52:41.187 | INFO     | __main__:train:118 - Epoch:  2 | Chunk:  7 | step: 1150 | mle_loss: 1.255532 | cl_loss: 0.030187 | loss: 1.406469
2022-07-28 01:52:58.950 | INFO     | __main__:train:118 - Epoch:  2 | Chunk:  7 | step: 1200 | mle_loss: 1.260508 | cl_loss: 0.030852 | loss: 1.414769
2022-07-28 01:53:16.557 | INFO     | processing.dataset:_load_and_cache_examples:43 - Loading examples from cache file data/cache/train_set/train_8.pkl
2022-07-28 01:53:18.639 | INFO     | __main__:train:118 - Epoch:  2 | Chunk:  8 | step:    0 | mle_loss: 1.271408 | cl_loss: 0.029161 | loss: 1.417213
2022-07-28 01:53:36.575 | INFO     | __main__:train:118 - Epoch:  2 | Chunk:  8 | step:   50 | mle_loss: 1.240465 | cl_loss: 0.025425 | loss: 1.367592
2022-07-28 01:53:54.215 | INFO     | __main__:train:118 - Epoch:  2 | Chunk:  8 | step:  100 | mle_loss: 1.243526 | cl_loss: 0.027091 | loss: 1.378984
2022-07-28 01:54:11.711 | INFO     | __main__:train:118 - Epoch:  2 | Chunk:  8 | step:  150 | mle_loss: 1.237447 | cl_loss: 0.025810 | loss: 1.366495
2022-07-28 01:54:29.500 | INFO     | __main__:train:118 - Epoch:  2 | Chunk:  8 | step:  200 | mle_loss: 1.220438 | cl_loss: 0.025819 | loss: 1.349536
2022-07-28 01:54:47.304 | INFO     | __main__:train:118 - Epoch:  2 | Chunk:  8 | step:  250 | mle_loss: 1.253989 | cl_loss: 0.027738 | loss: 1.392680
2022-07-28 01:55:04.770 | INFO     | __main__:train:118 - Epoch:  2 | Chunk:  8 | step:  300 | mle_loss: 1.237777 | cl_loss: 0.026811 | loss: 1.371834
2022-07-28 01:55:22.841 | INFO     | __main__:train:118 - Epoch:  2 | Chunk:  8 | step:  350 | mle_loss: 1.245736 | cl_loss: 0.027195 | loss: 1.381712
2022-07-28 01:55:40.854 | INFO     | __main__:train:118 - Epoch:  2 | Chunk:  8 | step:  400 | mle_loss: 1.214341 | cl_loss: 0.025380 | loss: 1.341238
2022-07-28 01:55:58.670 | INFO     | __main__:train:118 - Epoch:  2 | Chunk:  8 | step:  450 | mle_loss: 1.211526 | cl_loss: 0.026250 | loss: 1.342778
2022-07-28 01:56:16.643 | INFO     | __main__:train:118 - Epoch:  2 | Chunk:  8 | step:  500 | mle_loss: 1.221383 | cl_loss: 0.025506 | loss: 1.348915
2022-07-28 01:56:34.441 | INFO     | __main__:train:118 - Epoch:  2 | Chunk:  8 | step:  550 | mle_loss: 1.246013 | cl_loss: 0.026130 | loss: 1.376665
2022-07-28 01:56:51.908 | INFO     | __main__:train:118 - Epoch:  2 | Chunk:  8 | step:  600 | mle_loss: 1.204838 | cl_loss: 0.025442 | loss: 1.332047
2022-07-28 01:57:09.871 | INFO     | __main__:train:118 - Epoch:  2 | Chunk:  8 | step:  650 | mle_loss: 1.220909 | cl_loss: 0.025974 | loss: 1.350778
2022-07-28 01:57:28.061 | INFO     | __main__:train:118 - Epoch:  2 | Chunk:  8 | step:  700 | mle_loss: 1.213830 | cl_loss: 0.026214 | loss: 1.344899
2022-07-28 01:57:46.030 | INFO     | __main__:train:118 - Epoch:  2 | Chunk:  8 | step:  750 | mle_loss: 1.206896 | cl_loss: 0.025486 | loss: 1.334327
2022-07-28 01:58:04.029 | INFO     | __main__:train:118 - Epoch:  2 | Chunk:  8 | step:  800 | mle_loss: 1.190261 | cl_loss: 0.025524 | loss: 1.317879
2022-07-28 01:58:22.063 | INFO     | __main__:train:118 - Epoch:  2 | Chunk:  8 | step:  850 | mle_loss: 1.234087 | cl_loss: 0.026326 | loss: 1.365719
2022-07-28 01:58:40.046 | INFO     | __main__:train:118 - Epoch:  2 | Chunk:  8 | step:  900 | mle_loss: 1.198060 | cl_loss: 0.026095 | loss: 1.328534
2022-07-28 01:58:57.892 | INFO     | __main__:train:118 - Epoch:  2 | Chunk:  8 | step:  950 | mle_loss: 1.204194 | cl_loss: 0.025338 | loss: 1.330883
2022-07-28 01:59:15.377 | INFO     | __main__:evaluate:178 - Generating...
2022-07-28 02:00:38.039 | INFO     | __main__:evaluate:188 - Generation finished.
2022-07-28 02:00:38.040 | INFO     | __main__:evaluate:195 - Rouge scores: {'rouge-1': 0.407, 'rouge-2': 0.2475, 'rouge-l': 0.3642}
2022-07-28 02:00:38.040 | INFO     | __main__:train:137 - Eval loss: 0.0, the best loss: {'loss': 0.0, 'epoch': 0, 'step': 749}
2022-07-28 02:00:38.040 | INFO     | __main__:train:138 - Rouge scores: {'rouge-1': 0.407, 'rouge-2': 0.2475, 'rouge-l': 0.3642}, the best scores: {'rouge-1': 0.4175, 'rouge-2': 0.2549, 'rouge-l': 0.3735, 'epoch': 1, 'step': 499}
2022-07-28 02:00:38.041 | INFO     | __main__:train:143 - Saving model checkpoint to checkpoints/MoCoBart-2-8-999
2022-07-28 02:00:40.377 | INFO     | __main__:train:118 - Epoch:  2 | Chunk:  8 | step: 1000 | mle_loss: 1.236873 | cl_loss: 0.024962 | loss: 1.361681
2022-07-28 02:00:58.023 | INFO     | __main__:train:118 - Epoch:  2 | Chunk:  8 | step: 1050 | mle_loss: 1.212398 | cl_loss: 0.025470 | loss: 1.339748
2022-07-28 02:01:15.943 | INFO     | __main__:train:118 - Epoch:  2 | Chunk:  8 | step: 1100 | mle_loss: 1.184720 | cl_loss: 0.026165 | loss: 1.315545
2022-07-28 02:01:33.560 | INFO     | __main__:train:118 - Epoch:  2 | Chunk:  8 | step: 1150 | mle_loss: 1.237337 | cl_loss: 0.026708 | loss: 1.370879
2022-07-28 02:01:51.472 | INFO     | __main__:train:118 - Epoch:  2 | Chunk:  8 | step: 1200 | mle_loss: 1.254727 | cl_loss: 0.026337 | loss: 1.386410
2022-07-28 02:02:09.019 | INFO     | processing.dataset:_load_and_cache_examples:43 - Loading examples from cache file data/cache/train_set/train_9.pkl
2022-07-28 02:02:11.040 | INFO     | __main__:train:118 - Epoch:  2 | Chunk:  9 | step:    0 | mle_loss: 1.196463 | cl_loss: 0.025712 | loss: 1.325025
2022-07-28 02:02:28.795 | INFO     | __main__:train:118 - Epoch:  2 | Chunk:  9 | step:   50 | mle_loss: 1.144949 | cl_loss: 0.026468 | loss: 1.277290
2022-07-28 02:02:46.627 | INFO     | __main__:train:118 - Epoch:  2 | Chunk:  9 | step:  100 | mle_loss: 1.186185 | cl_loss: 0.027895 | loss: 1.325659
2022-07-28 02:03:04.552 | INFO     | __main__:train:118 - Epoch:  2 | Chunk:  9 | step:  150 | mle_loss: 1.190341 | cl_loss: 0.028621 | loss: 1.333447
2022-07-28 02:03:22.469 | INFO     | __main__:train:118 - Epoch:  2 | Chunk:  9 | step:  200 | mle_loss: 1.170231 | cl_loss: 0.027948 | loss: 1.309970
2022-07-28 02:03:40.431 | INFO     | __main__:train:118 - Epoch:  2 | Chunk:  9 | step:  250 | mle_loss: 1.152183 | cl_loss: 0.029236 | loss: 1.298361
2022-07-28 02:03:58.244 | INFO     | __main__:train:118 - Epoch:  2 | Chunk:  9 | step:  300 | mle_loss: 1.172959 | cl_loss: 0.027589 | loss: 1.310903
2022-07-28 02:04:16.283 | INFO     | __main__:train:118 - Epoch:  2 | Chunk:  9 | step:  350 | mle_loss: 1.158682 | cl_loss: 0.026908 | loss: 1.293224
2022-07-28 02:04:34.096 | INFO     | __main__:train:118 - Epoch:  2 | Chunk:  9 | step:  400 | mle_loss: 1.187770 | cl_loss: 0.027311 | loss: 1.324325
2022-07-28 02:04:52.014 | INFO     | __main__:train:118 - Epoch:  2 | Chunk:  9 | step:  450 | mle_loss: 1.174303 | cl_loss: 0.028568 | loss: 1.317143
2022-07-28 02:05:09.916 | INFO     | __main__:train:118 - Epoch:  2 | Chunk:  9 | step:  500 | mle_loss: 1.171765 | cl_loss: 0.028323 | loss: 1.313380
2022-07-28 02:05:27.850 | INFO     | __main__:train:118 - Epoch:  2 | Chunk:  9 | step:  550 | mle_loss: 1.161513 | cl_loss: 0.027759 | loss: 1.300310
2022-07-28 02:05:45.678 | INFO     | __main__:train:118 - Epoch:  2 | Chunk:  9 | step:  600 | mle_loss: 1.163025 | cl_loss: 0.029031 | loss: 1.308178
2022-07-28 02:06:03.451 | INFO     | __main__:train:118 - Epoch:  2 | Chunk:  9 | step:  650 | mle_loss: 1.183079 | cl_loss: 0.026605 | loss: 1.316105
2022-07-28 02:06:21.223 | INFO     | __main__:train:118 - Epoch:  2 | Chunk:  9 | step:  700 | mle_loss: 1.163254 | cl_loss: 0.027354 | loss: 1.300023
2022-07-28 02:06:38.955 | INFO     | __main__:train:118 - Epoch:  2 | Chunk:  9 | step:  750 | mle_loss: 1.163635 | cl_loss: 0.026361 | loss: 1.295439
2022-07-28 02:06:56.675 | INFO     | __main__:train:118 - Epoch:  2 | Chunk:  9 | step:  800 | mle_loss: 1.151482 | cl_loss: 0.026629 | loss: 1.284629
2022-07-28 02:07:14.564 | INFO     | __main__:train:118 - Epoch:  2 | Chunk:  9 | step:  850 | mle_loss: 1.155710 | cl_loss: 0.027262 | loss: 1.292021
2022-07-28 02:07:32.324 | INFO     | __main__:train:118 - Epoch:  2 | Chunk:  9 | step:  900 | mle_loss: 1.174242 | cl_loss: 0.027518 | loss: 1.311830
2022-07-28 02:07:49.913 | INFO     | __main__:train:118 - Epoch:  2 | Chunk:  9 | step:  950 | mle_loss: 1.182326 | cl_loss: 0.027625 | loss: 1.320450
2022-07-28 02:08:07.876 | INFO     | __main__:train:118 - Epoch:  2 | Chunk:  9 | step: 1000 | mle_loss: 1.139169 | cl_loss: 0.027744 | loss: 1.277889
2022-07-28 02:08:25.813 | INFO     | __main__:train:118 - Epoch:  2 | Chunk:  9 | step: 1050 | mle_loss: 1.152883 | cl_loss: 0.028151 | loss: 1.293638
2022-07-28 02:08:43.569 | INFO     | __main__:train:118 - Epoch:  2 | Chunk:  9 | step: 1100 | mle_loss: 1.166151 | cl_loss: 0.027103 | loss: 1.301668
2022-07-28 02:09:01.163 | INFO     | __main__:train:118 - Epoch:  2 | Chunk:  9 | step: 1150 | mle_loss: 1.161145 | cl_loss: 0.026785 | loss: 1.295071
2022-07-28 02:09:20.593 | INFO     | __main__:train:118 - Epoch:  2 | Chunk:  9 | step: 1200 | mle_loss: 1.164043 | cl_loss: 0.027302 | loss: 1.300556
2022-07-28 02:09:38.790 | INFO     | processing.dataset:_load_and_cache_examples:43 - Loading examples from cache file data/cache/train_set/train_10.pkl
2022-07-28 02:09:40.540 | INFO     | __main__:train:118 - Epoch:  2 | Chunk: 10 | step:    0 | mle_loss: 1.174132 | cl_loss: 0.025906 | loss: 1.303664
2022-07-28 02:09:58.279 | INFO     | __main__:train:118 - Epoch:  2 | Chunk: 10 | step:   50 | mle_loss: 1.144519 | cl_loss: 0.026982 | loss: 1.279428
2022-07-28 02:10:16.543 | INFO     | __main__:train:118 - Epoch:  2 | Chunk: 10 | step:  100 | mle_loss: 1.135512 | cl_loss: 0.028537 | loss: 1.278197
2022-07-28 02:10:34.390 | INFO     | __main__:train:118 - Epoch:  2 | Chunk: 10 | step:  150 | mle_loss: 1.146105 | cl_loss: 0.029719 | loss: 1.294697
2022-07-28 02:10:52.404 | INFO     | __main__:train:118 - Epoch:  2 | Chunk: 10 | step:  200 | mle_loss: 1.136346 | cl_loss: 0.030562 | loss: 1.289154
2022-07-28 02:11:10.494 | INFO     | __main__:train:118 - Epoch:  2 | Chunk: 10 | step:  250 | mle_loss: 1.125894 | cl_loss: 0.029177 | loss: 1.271779
2022-07-28 02:11:28.586 | INFO     | __main__:train:118 - Epoch:  2 | Chunk: 10 | step:  300 | mle_loss: 1.103341 | cl_loss: 0.028273 | loss: 1.244706
2022-07-28 02:11:46.664 | INFO     | __main__:train:118 - Epoch:  2 | Chunk: 10 | step:  350 | mle_loss: 1.124129 | cl_loss: 0.028137 | loss: 1.264817
2022-07-28 02:12:04.727 | INFO     | __main__:train:118 - Epoch:  2 | Chunk: 10 | step:  400 | mle_loss: 1.163554 | cl_loss: 0.027897 | loss: 1.303039
2022-07-28 02:12:22.755 | INFO     | __main__:train:118 - Epoch:  2 | Chunk: 10 | step:  450 | mle_loss: 1.147455 | cl_loss: 0.027998 | loss: 1.287446
2022-07-28 02:12:40.018 | INFO     | __main__:evaluate:178 - Generating...
2022-07-28 02:14:03.288 | INFO     | __main__:evaluate:188 - Generation finished.
2022-07-28 02:14:03.289 | INFO     | __main__:evaluate:195 - Rouge scores: {'rouge-1': 0.4082, 'rouge-2': 0.2493, 'rouge-l': 0.3616}
2022-07-28 02:14:03.289 | INFO     | __main__:train:137 - Eval loss: 0.0, the best loss: {'loss': 0.0, 'epoch': 0, 'step': 749}
2022-07-28 02:14:03.289 | INFO     | __main__:train:138 - Rouge scores: {'rouge-1': 0.4082, 'rouge-2': 0.2493, 'rouge-l': 0.3616}, the best scores: {'rouge-1': 0.4175, 'rouge-2': 0.2549, 'rouge-l': 0.3735, 'epoch': 1, 'step': 499}
2022-07-28 02:14:03.290 | INFO     | __main__:train:143 - Saving model checkpoint to checkpoints/MoCoBart-2-10-499
2022-07-28 02:14:05.472 | INFO     | __main__:train:118 - Epoch:  2 | Chunk: 10 | step:  500 | mle_loss: 1.130452 | cl_loss: 0.029650 | loss: 1.278703
2022-07-28 02:14:23.206 | INFO     | __main__:train:118 - Epoch:  2 | Chunk: 10 | step:  550 | mle_loss: 1.118146 | cl_loss: 0.028816 | loss: 1.262228
2022-07-28 02:14:41.093 | INFO     | __main__:train:118 - Epoch:  2 | Chunk: 10 | step:  600 | mle_loss: 1.133489 | cl_loss: 0.027958 | loss: 1.273278
2022-07-28 02:14:58.975 | INFO     | __main__:train:118 - Epoch:  2 | Chunk: 10 | step:  650 | mle_loss: 1.134767 | cl_loss: 0.027538 | loss: 1.272457
2022-07-28 02:15:16.708 | INFO     | __main__:train:118 - Epoch:  2 | Chunk: 10 | step:  700 | mle_loss: 1.135057 | cl_loss: 0.027659 | loss: 1.273353
2022-07-28 02:15:34.618 | INFO     | __main__:train:118 - Epoch:  2 | Chunk: 10 | step:  750 | mle_loss: 1.152617 | cl_loss: 0.030011 | loss: 1.302673
2022-07-28 02:15:52.519 | INFO     | __main__:train:118 - Epoch:  2 | Chunk: 10 | step:  800 | mle_loss: 1.122694 | cl_loss: 0.026615 | loss: 1.255768
2022-07-28 02:16:10.310 | INFO     | __main__:train:118 - Epoch:  2 | Chunk: 10 | step:  850 | mle_loss: 1.122168 | cl_loss: 0.028471 | loss: 1.264523
2022-07-28 02:16:28.307 | INFO     | __main__:train:118 - Epoch:  2 | Chunk: 10 | step:  900 | mle_loss: 1.130529 | cl_loss: 0.027425 | loss: 1.267655
2022-07-28 02:16:46.255 | INFO     | __main__:train:118 - Epoch:  2 | Chunk: 10 | step:  950 | mle_loss: 1.160879 | cl_loss: 0.027642 | loss: 1.299087
2022-07-28 02:17:04.181 | INFO     | __main__:train:118 - Epoch:  2 | Chunk: 10 | step: 1000 | mle_loss: 1.125477 | cl_loss: 0.028755 | loss: 1.269253
2022-07-28 02:17:22.028 | INFO     | __main__:train:118 - Epoch:  2 | Chunk: 10 | step: 1050 | mle_loss: 1.123523 | cl_loss: 0.029366 | loss: 1.270355
2022-07-28 02:17:39.751 | INFO     | __main__:train:118 - Epoch:  2 | Chunk: 10 | step: 1100 | mle_loss: 1.126841 | cl_loss: 0.033388 | loss: 1.293781
2022-07-28 02:17:57.694 | INFO     | __main__:train:118 - Epoch:  2 | Chunk: 10 | step: 1150 | mle_loss: 1.131375 | cl_loss: 0.028379 | loss: 1.273271
2022-07-28 02:18:15.628 | INFO     | __main__:train:118 - Epoch:  2 | Chunk: 10 | step: 1200 | mle_loss: 1.121085 | cl_loss: 0.030672 | loss: 1.274443
2022-07-28 02:18:33.542 | INFO     | processing.dataset:_load_and_cache_examples:43 - Loading examples from cache file data/cache/train_set/train_11.pkl
2022-07-28 02:18:35.528 | INFO     | __main__:train:118 - Epoch:  2 | Chunk: 11 | step:    0 | mle_loss: 1.117867 | cl_loss: 0.027245 | loss: 1.254089
2022-07-28 02:18:53.790 | INFO     | __main__:train:118 - Epoch:  2 | Chunk: 11 | step:   50 | mle_loss: 1.137600 | cl_loss: 0.025870 | loss: 1.266950
2022-07-28 02:19:12.198 | INFO     | __main__:train:118 - Epoch:  2 | Chunk: 11 | step:  100 | mle_loss: 1.146938 | cl_loss: 0.027220 | loss: 1.283038
2022-07-28 02:19:30.271 | INFO     | __main__:train:118 - Epoch:  2 | Chunk: 11 | step:  150 | mle_loss: 1.156479 | cl_loss: 0.027600 | loss: 1.294477
2022-07-28 02:19:48.392 | INFO     | __main__:train:118 - Epoch:  2 | Chunk: 11 | step:  200 | mle_loss: 1.144007 | cl_loss: 0.026405 | loss: 1.276033
2022-07-28 02:20:06.474 | INFO     | __main__:train:118 - Epoch:  2 | Chunk: 11 | step:  250 | mle_loss: 1.162922 | cl_loss: 0.027176 | loss: 1.298803
2022-07-28 02:20:24.772 | INFO     | __main__:train:118 - Epoch:  2 | Chunk: 11 | step:  300 | mle_loss: 1.139544 | cl_loss: 0.027329 | loss: 1.276188
2022-07-28 02:20:42.651 | INFO     | __main__:train:118 - Epoch:  2 | Chunk: 11 | step:  350 | mle_loss: 1.127235 | cl_loss: 0.026726 | loss: 1.260865
2022-07-28 02:21:00.578 | INFO     | __main__:train:118 - Epoch:  2 | Chunk: 11 | step:  400 | mle_loss: 1.141024 | cl_loss: 0.026129 | loss: 1.271668
2022-07-28 02:21:18.828 | INFO     | __main__:train:118 - Epoch:  2 | Chunk: 11 | step:  450 | mle_loss: 1.130344 | cl_loss: 0.028031 | loss: 1.270500
2022-07-28 02:21:37.044 | INFO     | __main__:train:118 - Epoch:  2 | Chunk: 11 | step:  500 | mle_loss: 1.128045 | cl_loss: 0.025588 | loss: 1.255984
2022-07-28 02:21:55.087 | INFO     | __main__:train:118 - Epoch:  2 | Chunk: 11 | step:  550 | mle_loss: 1.104525 | cl_loss: 0.026958 | loss: 1.239314
2022-07-28 02:22:13.132 | INFO     | __main__:train:118 - Epoch:  2 | Chunk: 11 | step:  600 | mle_loss: 1.138928 | cl_loss: 0.026656 | loss: 1.272207
2022-07-28 02:22:31.251 | INFO     | __main__:train:118 - Epoch:  2 | Chunk: 11 | step:  650 | mle_loss: 1.141833 | cl_loss: 0.026680 | loss: 1.275235
2022-07-28 02:22:49.235 | INFO     | __main__:train:118 - Epoch:  2 | Chunk: 11 | step:  700 | mle_loss: 1.120126 | cl_loss: 0.026226 | loss: 1.251256
2022-07-28 02:23:07.285 | INFO     | __main__:train:118 - Epoch:  2 | Chunk: 11 | step:  750 | mle_loss: 1.131009 | cl_loss: 0.026549 | loss: 1.263754
2022-07-28 02:23:25.121 | INFO     | __main__:train:118 - Epoch:  2 | Chunk: 11 | step:  800 | mle_loss: 1.134401 | cl_loss: 0.026540 | loss: 1.267099
2022-07-28 02:23:43.363 | INFO     | __main__:train:118 - Epoch:  2 | Chunk: 11 | step:  850 | mle_loss: 1.119889 | cl_loss: 0.026299 | loss: 1.251384
2022-07-28 02:24:01.182 | INFO     | __main__:train:118 - Epoch:  2 | Chunk: 11 | step:  900 | mle_loss: 1.124527 | cl_loss: 0.026318 | loss: 1.256120
2022-07-28 02:24:19.190 | INFO     | __main__:train:118 - Epoch:  2 | Chunk: 11 | step:  950 | mle_loss: 1.125147 | cl_loss: 0.026714 | loss: 1.258717
2022-07-28 02:24:37.092 | INFO     | __main__:train:118 - Epoch:  2 | Chunk: 11 | step: 1000 | mle_loss: 1.161395 | cl_loss: 0.026700 | loss: 1.294896
2022-07-28 02:24:55.111 | INFO     | __main__:train:118 - Epoch:  2 | Chunk: 11 | step: 1050 | mle_loss: 1.133858 | cl_loss: 0.026612 | loss: 1.266920
2022-07-28 02:25:12.607 | INFO     | __main__:train:118 - Epoch:  2 | Chunk: 11 | step: 1100 | mle_loss: 1.141941 | cl_loss: 0.025866 | loss: 1.271271
2022-07-28 02:25:30.747 | INFO     | __main__:train:118 - Epoch:  2 | Chunk: 11 | step: 1150 | mle_loss: 1.139521 | cl_loss: 0.025640 | loss: 1.267720
2022-07-28 02:25:49.176 | INFO     | __main__:train:118 - Epoch:  2 | Chunk: 11 | step: 1200 | mle_loss: 1.114331 | cl_loss: 0.026856 | loss: 1.248612
2022-07-28 02:26:06.990 | INFO     | __main__:evaluate:178 - Generating...
2022-07-28 02:27:29.769 | INFO     | __main__:evaluate:188 - Generation finished.
2022-07-28 02:27:29.770 | INFO     | __main__:evaluate:195 - Rouge scores: {'rouge-1': 0.4091, 'rouge-2': 0.2516, 'rouge-l': 0.3666}
2022-07-28 02:27:29.770 | INFO     | __main__:train:137 - Eval loss: 0.0, the best loss: {'loss': 0.0, 'epoch': 0, 'step': 749}
2022-07-28 02:27:29.770 | INFO     | __main__:train:138 - Rouge scores: {'rouge-1': 0.4091, 'rouge-2': 0.2516, 'rouge-l': 0.3666}, the best scores: {'rouge-1': 0.4175, 'rouge-2': 0.2549, 'rouge-l': 0.3735, 'epoch': 1, 'step': 499}
2022-07-28 02:27:29.771 | INFO     | __main__:train:143 - Saving model checkpoint to checkpoints/MoCoBart-2-11-1249
2022-07-28 02:27:31.652 | INFO     | processing.dataset:_load_and_cache_examples:43 - Loading examples from cache file data/cache/train_set/train_12.pkl
2022-07-28 02:27:33.638 | INFO     | __main__:train:118 - Epoch:  2 | Chunk: 12 | step:    0 | mle_loss: 1.127156 | cl_loss: 0.026501 | loss: 1.259660
2022-07-28 02:27:51.783 | INFO     | __main__:train:118 - Epoch:  2 | Chunk: 12 | step:   50 | mle_loss: 1.180254 | cl_loss: 0.029837 | loss: 1.329441
2022-07-28 02:28:09.340 | INFO     | __main__:train:118 - Epoch:  2 | Chunk: 12 | step:  100 | mle_loss: 1.195079 | cl_loss: 0.028715 | loss: 1.338655
2022-07-28 02:28:27.247 | INFO     | __main__:train:118 - Epoch:  2 | Chunk: 12 | step:  150 | mle_loss: 1.165805 | cl_loss: 0.028758 | loss: 1.309595
2022-07-28 02:28:44.918 | INFO     | __main__:train:118 - Epoch:  2 | Chunk: 12 | step:  200 | mle_loss: 1.166459 | cl_loss: 0.029119 | loss: 1.312055
2022-07-28 02:29:02.895 | INFO     | __main__:train:118 - Epoch:  2 | Chunk: 12 | step:  250 | mle_loss: 1.179304 | cl_loss: 0.027577 | loss: 1.317187
2022-07-28 02:29:20.804 | INFO     | __main__:train:118 - Epoch:  2 | Chunk: 12 | step:  300 | mle_loss: 1.162245 | cl_loss: 0.028708 | loss: 1.305783
2022-07-28 02:29:38.511 | INFO     | __main__:train:118 - Epoch:  2 | Chunk: 12 | step:  350 | mle_loss: 1.165002 | cl_loss: 0.029210 | loss: 1.311055
2022-07-28 02:29:56.215 | INFO     | __main__:train:118 - Epoch:  2 | Chunk: 12 | step:  400 | mle_loss: 1.178239 | cl_loss: 0.029375 | loss: 1.325114
2022-07-28 02:30:14.143 | INFO     | __main__:train:118 - Epoch:  2 | Chunk: 12 | step:  450 | mle_loss: 1.161797 | cl_loss: 0.028143 | loss: 1.302513
2022-07-28 02:30:31.970 | INFO     | __main__:train:118 - Epoch:  2 | Chunk: 12 | step:  500 | mle_loss: 1.170810 | cl_loss: 0.027586 | loss: 1.308739
2022-07-28 02:30:49.719 | INFO     | __main__:train:118 - Epoch:  2 | Chunk: 12 | step:  550 | mle_loss: 1.167747 | cl_loss: 0.027472 | loss: 1.305110
2022-07-28 02:31:07.641 | INFO     | __main__:train:118 - Epoch:  2 | Chunk: 12 | step:  600 | mle_loss: 1.132483 | cl_loss: 0.027986 | loss: 1.272411
2022-07-28 02:31:25.638 | INFO     | __main__:train:118 - Epoch:  2 | Chunk: 12 | step:  650 | mle_loss: 1.200113 | cl_loss: 0.027093 | loss: 1.335577
2022-07-28 02:31:43.553 | INFO     | __main__:train:118 - Epoch:  2 | Chunk: 12 | step:  700 | mle_loss: 1.146408 | cl_loss: 0.027912 | loss: 1.285965
2022-07-28 02:32:01.439 | INFO     | __main__:train:118 - Epoch:  2 | Chunk: 12 | step:  750 | mle_loss: 1.168184 | cl_loss: 0.029574 | loss: 1.316055
2022-07-28 02:32:19.216 | INFO     | __main__:train:118 - Epoch:  2 | Chunk: 12 | step:  800 | mle_loss: 1.152461 | cl_loss: 0.027391 | loss: 1.289416
2022-07-28 02:32:36.824 | INFO     | __main__:train:118 - Epoch:  2 | Chunk: 12 | step:  850 | mle_loss: 1.142368 | cl_loss: 0.027992 | loss: 1.282328
2022-07-28 02:32:54.699 | INFO     | __main__:train:118 - Epoch:  2 | Chunk: 12 | step:  900 | mle_loss: 1.168133 | cl_loss: 0.028446 | loss: 1.310362
2022-07-28 02:33:12.294 | INFO     | __main__:train:118 - Epoch:  2 | Chunk: 12 | step:  950 | mle_loss: 1.144398 | cl_loss: 0.028808 | loss: 1.288439
2022-07-28 02:33:29.629 | INFO     | __main__:train:118 - Epoch:  2 | Chunk: 12 | step: 1000 | mle_loss: 1.141528 | cl_loss: 0.026852 | loss: 1.275790
2022-07-28 02:33:47.666 | INFO     | __main__:train:118 - Epoch:  2 | Chunk: 12 | step: 1050 | mle_loss: 1.132339 | cl_loss: 0.026999 | loss: 1.267335
2022-07-28 02:34:05.736 | INFO     | __main__:train:118 - Epoch:  2 | Chunk: 12 | step: 1100 | mle_loss: 1.140648 | cl_loss: 0.028518 | loss: 1.283240
2022-07-28 02:34:23.559 | INFO     | __main__:train:118 - Epoch:  2 | Chunk: 12 | step: 1150 | mle_loss: 1.144365 | cl_loss: 0.028028 | loss: 1.284505
2022-07-28 02:34:41.438 | INFO     | __main__:train:118 - Epoch:  2 | Chunk: 12 | step: 1200 | mle_loss: 1.139132 | cl_loss: 0.027560 | loss: 1.276931
2022-07-28 02:34:58.873 | INFO     | processing.dataset:_load_and_cache_examples:43 - Loading examples from cache file data/cache/train_set/train_13.pkl
2022-07-28 02:35:00.637 | INFO     | __main__:train:118 - Epoch:  2 | Chunk: 13 | step:    0 | mle_loss: 1.153679 | cl_loss: 0.027986 | loss: 1.293609
2022-07-28 02:35:18.688 | INFO     | __main__:train:118 - Epoch:  2 | Chunk: 13 | step:   50 | mle_loss: 1.230470 | cl_loss: 0.034650 | loss: 1.403721
2022-07-28 02:35:36.891 | INFO     | __main__:train:118 - Epoch:  2 | Chunk: 13 | step:  100 | mle_loss: 1.225381 | cl_loss: 0.033284 | loss: 1.391801
2022-07-28 02:35:54.594 | INFO     | __main__:train:118 - Epoch:  2 | Chunk: 13 | step:  150 | mle_loss: 1.233389 | cl_loss: 0.032297 | loss: 1.394875
2022-07-28 02:36:12.665 | INFO     | __main__:train:118 - Epoch:  2 | Chunk: 13 | step:  200 | mle_loss: 1.201724 | cl_loss: 0.033792 | loss: 1.370683
2022-07-28 02:36:30.916 | INFO     | __main__:train:118 - Epoch:  2 | Chunk: 13 | step:  250 | mle_loss: 1.228812 | cl_loss: 0.034963 | loss: 1.403629
2022-07-28 02:36:49.284 | INFO     | __main__:train:118 - Epoch:  2 | Chunk: 13 | step:  300 | mle_loss: 1.180333 | cl_loss: 0.033907 | loss: 1.349869
2022-07-28 02:37:07.515 | INFO     | __main__:train:118 - Epoch:  2 | Chunk: 13 | step:  350 | mle_loss: 1.167319 | cl_loss: 0.032976 | loss: 1.332202
2022-07-28 02:37:25.714 | INFO     | __main__:train:118 - Epoch:  2 | Chunk: 13 | step:  400 | mle_loss: 1.186843 | cl_loss: 0.035070 | loss: 1.362195
2022-07-28 02:37:44.036 | INFO     | __main__:train:118 - Epoch:  2 | Chunk: 13 | step:  450 | mle_loss: 1.196224 | cl_loss: 0.034191 | loss: 1.367177
2022-07-28 02:38:02.445 | INFO     | __main__:train:118 - Epoch:  2 | Chunk: 13 | step:  500 | mle_loss: 1.177583 | cl_loss: 0.034520 | loss: 1.350184
2022-07-28 02:38:20.556 | INFO     | __main__:train:118 - Epoch:  2 | Chunk: 13 | step:  550 | mle_loss: 1.182032 | cl_loss: 0.033034 | loss: 1.347203
2022-07-28 02:38:38.787 | INFO     | __main__:train:118 - Epoch:  2 | Chunk: 13 | step:  600 | mle_loss: 1.207876 | cl_loss: 0.033436 | loss: 1.375058
2022-07-28 02:38:57.087 | INFO     | __main__:train:118 - Epoch:  2 | Chunk: 13 | step:  650 | mle_loss: 1.182454 | cl_loss: 0.031043 | loss: 1.337669
2022-07-28 02:39:15.389 | INFO     | __main__:train:118 - Epoch:  2 | Chunk: 13 | step:  700 | mle_loss: 1.184840 | cl_loss: 0.031011 | loss: 1.339895
2022-07-28 02:39:33.040 | INFO     | __main__:evaluate:178 - Generating...
2022-07-28 02:40:57.622 | INFO     | __main__:evaluate:188 - Generation finished.
2022-07-28 02:40:57.623 | INFO     | __main__:evaluate:195 - Rouge scores: {'rouge-1': 0.4165, 'rouge-2': 0.258, 'rouge-l': 0.3727}
2022-07-28 02:40:57.623 | INFO     | __main__:train:137 - Eval loss: 0.0, the best loss: {'loss': 0.0, 'epoch': 0, 'step': 749}
2022-07-28 02:40:57.623 | INFO     | __main__:train:138 - Rouge scores: {'rouge-1': 0.4165, 'rouge-2': 0.258, 'rouge-l': 0.3727}, the best scores: {'rouge-1': 0.4175, 'rouge-2': 0.2549, 'rouge-l': 0.3735, 'epoch': 1, 'step': 499}
2022-07-28 02:40:57.623 | INFO     | __main__:train:143 - Saving model checkpoint to checkpoints/MoCoBart-2-13-749
2022-07-28 02:40:59.698 | INFO     | __main__:train:118 - Epoch:  2 | Chunk: 13 | step:  750 | mle_loss: 1.211004 | cl_loss: 0.030593 | loss: 1.363967
2022-07-28 02:41:17.827 | INFO     | __main__:train:118 - Epoch:  2 | Chunk: 13 | step:  800 | mle_loss: 1.181684 | cl_loss: 0.034307 | loss: 1.353217
2022-07-28 02:41:35.960 | INFO     | __main__:train:118 - Epoch:  2 | Chunk: 13 | step:  850 | mle_loss: 1.188111 | cl_loss: 0.034925 | loss: 1.362734
2022-07-28 02:41:54.195 | INFO     | __main__:train:118 - Epoch:  2 | Chunk: 13 | step:  900 | mle_loss: 1.183661 | cl_loss: 0.032052 | loss: 1.343918
2022-07-28 02:42:12.251 | INFO     | __main__:train:118 - Epoch:  2 | Chunk: 13 | step:  950 | mle_loss: 1.190242 | cl_loss: 0.034845 | loss: 1.364467
2022-07-28 02:42:30.344 | INFO     | __main__:train:118 - Epoch:  2 | Chunk: 13 | step: 1000 | mle_loss: 1.191829 | cl_loss: 0.032130 | loss: 1.352479
2022-07-28 02:42:48.695 | INFO     | __main__:train:118 - Epoch:  2 | Chunk: 13 | step: 1050 | mle_loss: 1.172272 | cl_loss: 0.033651 | loss: 1.340526
2022-07-28 02:43:06.773 | INFO     | __main__:train:118 - Epoch:  2 | Chunk: 13 | step: 1100 | mle_loss: 1.170555 | cl_loss: 0.030812 | loss: 1.324615
2022-07-28 02:43:24.849 | INFO     | __main__:train:118 - Epoch:  2 | Chunk: 13 | step: 1150 | mle_loss: 1.207880 | cl_loss: 0.031594 | loss: 1.365851
2022-07-28 02:43:43.036 | INFO     | __main__:train:118 - Epoch:  2 | Chunk: 13 | step: 1200 | mle_loss: 1.167883 | cl_loss: 0.032759 | loss: 1.331676
2022-07-28 02:44:00.855 | INFO     | processing.dataset:_load_and_cache_examples:43 - Loading examples from cache file data/cache/train_set/train_14.pkl
2022-07-28 02:44:03.044 | INFO     | __main__:train:118 - Epoch:  2 | Chunk: 14 | step:    0 | mle_loss: 1.209159 | cl_loss: 0.032696 | loss: 1.372640
2022-07-28 02:44:21.023 | INFO     | __main__:train:118 - Epoch:  2 | Chunk: 14 | step:   50 | mle_loss: 1.198194 | cl_loss: 0.025032 | loss: 1.323355
2022-07-28 02:44:39.615 | INFO     | __main__:train:118 - Epoch:  2 | Chunk: 14 | step:  100 | mle_loss: 1.181155 | cl_loss: 0.025691 | loss: 1.309608
2022-07-28 02:44:57.756 | INFO     | __main__:train:118 - Epoch:  2 | Chunk: 14 | step:  150 | mle_loss: 1.192163 | cl_loss: 0.025719 | loss: 1.320758
2022-07-28 02:45:16.162 | INFO     | __main__:train:118 - Epoch:  2 | Chunk: 14 | step:  200 | mle_loss: 1.186546 | cl_loss: 0.024904 | loss: 1.311068
2022-07-28 02:45:34.251 | INFO     | __main__:train:118 - Epoch:  2 | Chunk: 14 | step:  250 | mle_loss: 1.169434 | cl_loss: 0.026063 | loss: 1.299747
2022-07-28 02:45:52.398 | INFO     | __main__:train:118 - Epoch:  2 | Chunk: 14 | step:  300 | mle_loss: 1.186056 | cl_loss: 0.026004 | loss: 1.316075
2022-07-28 02:46:10.292 | INFO     | __main__:train:118 - Epoch:  2 | Chunk: 14 | step:  350 | mle_loss: 1.171587 | cl_loss: 0.025064 | loss: 1.296907
2022-07-28 02:46:28.046 | INFO     | __main__:train:118 - Epoch:  2 | Chunk: 14 | step:  400 | mle_loss: 1.211288 | cl_loss: 0.025993 | loss: 1.341255
2022-07-28 02:46:46.158 | INFO     | __main__:train:118 - Epoch:  2 | Chunk: 14 | step:  450 | mle_loss: 1.211965 | cl_loss: 0.026197 | loss: 1.342950
2022-07-28 02:47:04.398 | INFO     | __main__:train:118 - Epoch:  2 | Chunk: 14 | step:  500 | mle_loss: 1.186371 | cl_loss: 0.025344 | loss: 1.313090
2022-07-28 02:47:22.600 | INFO     | __main__:train:118 - Epoch:  2 | Chunk: 14 | step:  550 | mle_loss: 1.173001 | cl_loss: 0.025795 | loss: 1.301973
2022-07-28 02:47:40.578 | INFO     | __main__:train:118 - Epoch:  2 | Chunk: 14 | step:  600 | mle_loss: 1.170286 | cl_loss: 0.025904 | loss: 1.299805
2022-07-28 02:47:58.692 | INFO     | __main__:train:118 - Epoch:  2 | Chunk: 14 | step:  650 | mle_loss: 1.189123 | cl_loss: 0.025665 | loss: 1.317449
2022-07-28 02:48:16.979 | INFO     | __main__:train:118 - Epoch:  2 | Chunk: 14 | step:  700 | mle_loss: 1.163716 | cl_loss: 0.025955 | loss: 1.293490
2022-07-28 02:48:35.034 | INFO     | __main__:train:118 - Epoch:  2 | Chunk: 14 | step:  750 | mle_loss: 1.201467 | cl_loss: 0.026768 | loss: 1.335308
2022-07-28 02:48:53.116 | INFO     | __main__:train:118 - Epoch:  2 | Chunk: 14 | step:  800 | mle_loss: 1.157092 | cl_loss: 0.024655 | loss: 1.280366
2022-07-28 02:49:11.443 | INFO     | __main__:train:118 - Epoch:  2 | Chunk: 14 | step:  850 | mle_loss: 1.176670 | cl_loss: 0.025243 | loss: 1.302885
2022-07-28 02:49:29.318 | INFO     | __main__:train:118 - Epoch:  2 | Chunk: 14 | step:  900 | mle_loss: 1.182304 | cl_loss: 0.025462 | loss: 1.309613
2022-07-28 02:49:47.321 | INFO     | __main__:train:118 - Epoch:  2 | Chunk: 14 | step:  950 | mle_loss: 1.178616 | cl_loss: 0.025921 | loss: 1.308223
2022-07-28 02:50:05.355 | INFO     | __main__:train:118 - Epoch:  2 | Chunk: 14 | step: 1000 | mle_loss: 1.194787 | cl_loss: 0.025805 | loss: 1.323814
2022-07-28 02:50:23.451 | INFO     | __main__:train:118 - Epoch:  2 | Chunk: 14 | step: 1050 | mle_loss: 1.160155 | cl_loss: 0.025092 | loss: 1.285615
2022-07-28 02:50:41.311 | INFO     | __main__:train:118 - Epoch:  2 | Chunk: 14 | step: 1100 | mle_loss: 1.193398 | cl_loss: 0.025144 | loss: 1.319120
2022-07-28 02:50:59.572 | INFO     | __main__:train:118 - Epoch:  2 | Chunk: 14 | step: 1150 | mle_loss: 1.194566 | cl_loss: 0.025128 | loss: 1.320208
2022-07-28 02:51:17.720 | INFO     | __main__:train:118 - Epoch:  2 | Chunk: 14 | step: 1200 | mle_loss: 1.200662 | cl_loss: 0.024883 | loss: 1.325077
2022-07-28 02:51:35.669 | INFO     | processing.dataset:_load_and_cache_examples:43 - Loading examples from cache file data/cache/train_set/train_15.pkl
2022-07-28 02:51:38.037 | INFO     | __main__:train:118 - Epoch:  2 | Chunk: 15 | step:    0 | mle_loss: 1.183083 | cl_loss: 0.025612 | loss: 1.311145
2022-07-28 02:51:56.158 | INFO     | __main__:train:118 - Epoch:  2 | Chunk: 15 | step:   50 | mle_loss: 1.139966 | cl_loss: 0.025034 | loss: 1.265136
2022-07-28 02:52:14.300 | INFO     | __main__:train:118 - Epoch:  2 | Chunk: 15 | step:  100 | mle_loss: 1.108416 | cl_loss: 0.025407 | loss: 1.235453
2022-07-28 02:52:32.415 | INFO     | __main__:train:118 - Epoch:  2 | Chunk: 15 | step:  150 | mle_loss: 1.097047 | cl_loss: 0.025945 | loss: 1.226774
2022-07-28 02:52:50.727 | INFO     | __main__:train:118 - Epoch:  2 | Chunk: 15 | step:  200 | mle_loss: 1.109813 | cl_loss: 0.025230 | loss: 1.235964
2022-07-28 02:53:08.635 | INFO     | __main__:evaluate:178 - Generating...
2022-07-28 02:54:34.159 | INFO     | __main__:evaluate:188 - Generation finished.
2022-07-28 02:54:34.159 | INFO     | __main__:evaluate:195 - Rouge scores: {'rouge-1': 0.4211, 'rouge-2': 0.2666, 'rouge-l': 0.3766}
2022-07-28 02:54:34.159 | INFO     | __main__:train:137 - Eval loss: 0.0, the best loss: {'loss': 0.0, 'epoch': 0, 'step': 749}
2022-07-28 02:54:34.159 | INFO     | __main__:train:138 - Rouge scores: {'rouge-1': 0.4211, 'rouge-2': 0.2666, 'rouge-l': 0.3766, 'epoch': 2, 'step': 249}, the best scores: {'rouge-1': 0.4211, 'rouge-2': 0.2666, 'rouge-l': 0.3766, 'epoch': 2, 'step': 249}
2022-07-28 02:54:34.160 | INFO     | __main__:train:143 - Saving model checkpoint to checkpoints/MoCoBart-2-15-249
2022-07-28 02:54:36.923 | INFO     | __main__:train:118 - Epoch:  2 | Chunk: 15 | step:  250 | mle_loss: 1.089993 | cl_loss: 0.025880 | loss: 1.219393
2022-07-28 02:54:54.994 | INFO     | __main__:train:118 - Epoch:  2 | Chunk: 15 | step:  300 | mle_loss: 1.092227 | cl_loss: 0.025243 | loss: 1.218443
2022-07-28 02:55:13.032 | INFO     | __main__:train:118 - Epoch:  2 | Chunk: 15 | step:  350 | mle_loss: 1.124802 | cl_loss: 0.026737 | loss: 1.258488
2022-07-28 02:55:31.130 | INFO     | __main__:train:118 - Epoch:  2 | Chunk: 15 | step:  400 | mle_loss: 1.109085 | cl_loss: 0.024958 | loss: 1.233876
2022-07-28 02:55:49.288 | INFO     | __main__:train:118 - Epoch:  2 | Chunk: 15 | step:  450 | mle_loss: 1.094151 | cl_loss: 0.025855 | loss: 1.223427
2022-07-28 02:56:07.290 | INFO     | __main__:train:118 - Epoch:  2 | Chunk: 15 | step:  500 | mle_loss: 1.098850 | cl_loss: 0.025738 | loss: 1.227542
2022-07-28 02:56:25.533 | INFO     | __main__:train:118 - Epoch:  2 | Chunk: 15 | step:  550 | mle_loss: 1.118551 | cl_loss: 0.024851 | loss: 1.242806
2022-07-28 02:56:43.606 | INFO     | __main__:train:118 - Epoch:  2 | Chunk: 15 | step:  600 | mle_loss: 1.107119 | cl_loss: 0.025428 | loss: 1.234258
2022-07-28 02:57:01.859 | INFO     | __main__:train:118 - Epoch:  2 | Chunk: 15 | step:  650 | mle_loss: 1.098113 | cl_loss: 0.025731 | loss: 1.226766
2022-07-28 02:57:19.941 | INFO     | __main__:train:118 - Epoch:  2 | Chunk: 15 | step:  700 | mle_loss: 1.103432 | cl_loss: 0.025126 | loss: 1.229061
2022-07-28 02:57:37.880 | INFO     | __main__:train:118 - Epoch:  2 | Chunk: 15 | step:  750 | mle_loss: 1.090347 | cl_loss: 0.025298 | loss: 1.216838
2022-07-28 02:57:55.973 | INFO     | __main__:train:118 - Epoch:  2 | Chunk: 15 | step:  800 | mle_loss: 1.077241 | cl_loss: 0.026364 | loss: 1.209064
2022-07-28 02:58:13.990 | INFO     | __main__:train:118 - Epoch:  2 | Chunk: 15 | step:  850 | mle_loss: 1.058244 | cl_loss: 0.024535 | loss: 1.180919
2022-07-28 02:58:32.126 | INFO     | __main__:train:118 - Epoch:  2 | Chunk: 15 | step:  900 | mle_loss: 1.092692 | cl_loss: 0.025069 | loss: 1.218036
2022-07-28 02:58:50.068 | INFO     | __main__:train:118 - Epoch:  2 | Chunk: 15 | step:  950 | mle_loss: 1.074925 | cl_loss: 0.024906 | loss: 1.199456
2022-07-28 02:59:08.179 | INFO     | __main__:train:118 - Epoch:  2 | Chunk: 15 | step: 1000 | mle_loss: 1.060966 | cl_loss: 0.025533 | loss: 1.188629
2022-07-28 02:59:26.104 | INFO     | __main__:train:118 - Epoch:  2 | Chunk: 15 | step: 1050 | mle_loss: 1.093031 | cl_loss: 0.024149 | loss: 1.213774
2022-07-28 02:59:44.245 | INFO     | __main__:train:118 - Epoch:  2 | Chunk: 15 | step: 1100 | mle_loss: 1.098358 | cl_loss: 0.024974 | loss: 1.223227
2022-07-28 03:00:02.278 | INFO     | __main__:train:118 - Epoch:  2 | Chunk: 15 | step: 1150 | mle_loss: 1.101566 | cl_loss: 0.024643 | loss: 1.224779
2022-07-28 03:00:21.760 | INFO     | __main__:train:118 - Epoch:  2 | Chunk: 15 | step: 1200 | mle_loss: 1.122979 | cl_loss: 0.025647 | loss: 1.251213
2022-07-28 03:00:40.448 | INFO     | processing.dataset:_load_and_cache_examples:43 - Loading examples from cache file data/cache/train_set/train_16.pkl
2022-07-28 03:00:42.330 | INFO     | __main__:train:118 - Epoch:  2 | Chunk: 16 | step:    0 | mle_loss: 1.075613 | cl_loss: 0.024303 | loss: 1.197129
2022-07-28 03:01:00.683 | INFO     | __main__:train:118 - Epoch:  2 | Chunk: 16 | step:   50 | mle_loss: 1.150635 | cl_loss: 0.025721 | loss: 1.279239
2022-07-28 03:01:18.920 | INFO     | __main__:train:118 - Epoch:  2 | Chunk: 16 | step:  100 | mle_loss: 1.132397 | cl_loss: 0.025785 | loss: 1.261323
2022-07-28 03:01:36.740 | INFO     | __main__:train:118 - Epoch:  2 | Chunk: 16 | step:  150 | mle_loss: 1.136104 | cl_loss: 0.026568 | loss: 1.268945
2022-07-28 03:01:54.702 | INFO     | __main__:train:118 - Epoch:  2 | Chunk: 16 | step:  200 | mle_loss: 1.141429 | cl_loss: 0.027279 | loss: 1.277824
2022-07-28 03:02:13.650 | INFO     | __main__:train:118 - Epoch:  2 | Chunk: 16 | step:  250 | mle_loss: 1.116043 | cl_loss: 0.024292 | loss: 1.237504
2022-07-28 03:02:32.440 | INFO     | __main__:train:118 - Epoch:  2 | Chunk: 16 | step:  300 | mle_loss: 1.101270 | cl_loss: 0.024439 | loss: 1.223463
2022-07-28 03:02:51.178 | INFO     | __main__:train:118 - Epoch:  2 | Chunk: 16 | step:  350 | mle_loss: 1.125880 | cl_loss: 0.024724 | loss: 1.249498
2022-07-28 03:03:09.086 | INFO     | __main__:train:118 - Epoch:  2 | Chunk: 16 | step:  400 | mle_loss: 1.100062 | cl_loss: 0.025132 | loss: 1.225721
2022-07-28 03:03:27.002 | INFO     | __main__:train:118 - Epoch:  2 | Chunk: 16 | step:  450 | mle_loss: 1.114134 | cl_loss: 0.027744 | loss: 1.252852
2022-07-28 03:03:44.863 | INFO     | __main__:train:118 - Epoch:  2 | Chunk: 16 | step:  500 | mle_loss: 1.114981 | cl_loss: 0.024944 | loss: 1.239701
2022-07-28 03:04:02.805 | INFO     | __main__:train:118 - Epoch:  2 | Chunk: 16 | step:  550 | mle_loss: 1.128302 | cl_loss: 0.026206 | loss: 1.259335
2022-07-28 03:04:20.736 | INFO     | __main__:train:118 - Epoch:  2 | Chunk: 16 | step:  600 | mle_loss: 1.125898 | cl_loss: 0.027833 | loss: 1.265065
2022-07-28 03:04:38.652 | INFO     | __main__:train:118 - Epoch:  2 | Chunk: 16 | step:  650 | mle_loss: 1.132205 | cl_loss: 0.024530 | loss: 1.254854
2022-07-28 03:04:57.384 | INFO     | __main__:train:118 - Epoch:  2 | Chunk: 16 | step:  700 | mle_loss: 1.110265 | cl_loss: 0.024482 | loss: 1.232673
2022-07-28 03:05:15.528 | INFO     | __main__:train:118 - Epoch:  2 | Chunk: 16 | step:  750 | mle_loss: 1.099670 | cl_loss: 0.025113 | loss: 1.225235
2022-07-28 03:05:33.621 | INFO     | __main__:train:118 - Epoch:  2 | Chunk: 16 | step:  800 | mle_loss: 1.108553 | cl_loss: 0.024558 | loss: 1.231342
2022-07-28 03:05:51.339 | INFO     | __main__:train:118 - Epoch:  2 | Chunk: 16 | step:  850 | mle_loss: 1.162832 | cl_loss: 0.025594 | loss: 1.290801
2022-07-28 03:06:09.848 | INFO     | __main__:train:118 - Epoch:  2 | Chunk: 16 | step:  900 | mle_loss: 1.129472 | cl_loss: 0.025771 | loss: 1.258324
2022-07-28 03:06:28.066 | INFO     | __main__:train:118 - Epoch:  2 | Chunk: 16 | step:  950 | mle_loss: 1.123751 | cl_loss: 0.026330 | loss: 1.255402
2022-07-28 03:06:45.862 | INFO     | __main__:evaluate:178 - Generating...
2022-07-28 03:08:12.050 | INFO     | __main__:evaluate:188 - Generation finished.
2022-07-28 03:08:12.050 | INFO     | __main__:evaluate:195 - Rouge scores: {'rouge-1': 0.4178, 'rouge-2': 0.2576, 'rouge-l': 0.3719}
2022-07-28 03:08:12.050 | INFO     | __main__:train:137 - Eval loss: 0.0, the best loss: {'loss': 0.0, 'epoch': 0, 'step': 749}
2022-07-28 03:08:12.051 | INFO     | __main__:train:138 - Rouge scores: {'rouge-1': 0.4178, 'rouge-2': 0.2576, 'rouge-l': 0.3719}, the best scores: {'rouge-1': 0.4211, 'rouge-2': 0.2666, 'rouge-l': 0.3766, 'epoch': 2, 'step': 249}
2022-07-28 03:08:12.051 | INFO     | __main__:train:143 - Saving model checkpoint to checkpoints/MoCoBart-2-16-999
2022-07-28 03:08:14.837 | INFO     | __main__:train:118 - Epoch:  2 | Chunk: 16 | step: 1000 | mle_loss: 1.107885 | cl_loss: 0.027591 | loss: 1.245839
2022-07-28 03:08:32.712 | INFO     | __main__:train:118 - Epoch:  2 | Chunk: 16 | step: 1050 | mle_loss: 1.107170 | cl_loss: 0.025802 | loss: 1.236180
2022-07-28 03:08:50.401 | INFO     | __main__:train:118 - Epoch:  2 | Chunk: 16 | step: 1100 | mle_loss: 1.135716 | cl_loss: 0.025549 | loss: 1.263460
2022-07-28 03:09:08.192 | INFO     | __main__:train:118 - Epoch:  2 | Chunk: 16 | step: 1150 | mle_loss: 1.126632 | cl_loss: 0.026614 | loss: 1.259702
2022-07-28 03:09:26.160 | INFO     | __main__:train:118 - Epoch:  2 | Chunk: 16 | step: 1200 | mle_loss: 1.105916 | cl_loss: 0.027013 | loss: 1.240982
2022-07-28 03:09:43.779 | INFO     | processing.dataset:_load_and_cache_examples:43 - Loading examples from cache file data/cache/train_set/train_17.pkl
2022-07-28 03:09:46.259 | INFO     | __main__:train:118 - Epoch:  2 | Chunk: 17 | step:    0 | mle_loss: 1.120486 | cl_loss: 0.025762 | loss: 1.249296
2022-07-28 03:10:04.232 | INFO     | __main__:train:118 - Epoch:  2 | Chunk: 17 | step:   50 | mle_loss: 1.191902 | cl_loss: 0.033057 | loss: 1.357189
2022-07-28 03:10:22.346 | INFO     | __main__:train:118 - Epoch:  2 | Chunk: 17 | step:  100 | mle_loss: 1.199800 | cl_loss: 0.031251 | loss: 1.356057
2022-07-28 03:10:40.371 | INFO     | __main__:train:118 - Epoch:  2 | Chunk: 17 | step:  150 | mle_loss: 1.197966 | cl_loss: 0.028119 | loss: 1.338562
2022-07-28 03:10:58.503 | INFO     | __main__:train:118 - Epoch:  2 | Chunk: 17 | step:  200 | mle_loss: 1.170882 | cl_loss: 0.030582 | loss: 1.323793
2022-07-28 03:11:16.499 | INFO     | __main__:train:118 - Epoch:  2 | Chunk: 17 | step:  250 | mle_loss: 1.155943 | cl_loss: 0.028732 | loss: 1.299604
2022-07-28 03:11:34.752 | INFO     | __main__:train:118 - Epoch:  2 | Chunk: 17 | step:  300 | mle_loss: 1.221070 | cl_loss: 0.028687 | loss: 1.364504
2022-07-28 03:11:52.934 | INFO     | __main__:train:118 - Epoch:  2 | Chunk: 17 | step:  350 | mle_loss: 1.187090 | cl_loss: 0.030875 | loss: 1.341464
2022-07-28 03:12:10.892 | INFO     | __main__:train:118 - Epoch:  2 | Chunk: 17 | step:  400 | mle_loss: 1.217247 | cl_loss: 0.030625 | loss: 1.370371
2022-07-28 03:12:29.235 | INFO     | __main__:train:118 - Epoch:  2 | Chunk: 17 | step:  450 | mle_loss: 1.187934 | cl_loss: 0.031230 | loss: 1.344084
2022-07-28 03:12:47.605 | INFO     | __main__:train:118 - Epoch:  2 | Chunk: 17 | step:  500 | mle_loss: 1.176064 | cl_loss: 0.032740 | loss: 1.339765
2022-07-28 03:13:05.642 | INFO     | __main__:train:118 - Epoch:  2 | Chunk: 17 | step:  550 | mle_loss: 1.202101 | cl_loss: 0.030508 | loss: 1.354641
2022-07-28 03:13:23.717 | INFO     | __main__:train:118 - Epoch:  2 | Chunk: 17 | step:  600 | mle_loss: 1.196531 | cl_loss: 0.028418 | loss: 1.338621
2022-07-28 03:13:41.892 | INFO     | __main__:train:118 - Epoch:  2 | Chunk: 17 | step:  650 | mle_loss: 1.187423 | cl_loss: 0.030208 | loss: 1.338466
2022-07-28 03:13:59.996 | INFO     | __main__:train:118 - Epoch:  2 | Chunk: 17 | step:  700 | mle_loss: 1.195459 | cl_loss: 0.029562 | loss: 1.343268
2022-07-28 03:14:18.263 | INFO     | __main__:train:118 - Epoch:  2 | Chunk: 17 | step:  750 | mle_loss: 1.170943 | cl_loss: 0.028312 | loss: 1.312503
2022-07-28 03:14:36.458 | INFO     | __main__:train:118 - Epoch:  2 | Chunk: 17 | step:  800 | mle_loss: 1.188671 | cl_loss: 0.028727 | loss: 1.332306
2022-07-28 03:14:54.623 | INFO     | __main__:train:118 - Epoch:  2 | Chunk: 17 | step:  850 | mle_loss: 1.154649 | cl_loss: 0.030168 | loss: 1.305488
2022-07-28 03:15:12.836 | INFO     | __main__:train:118 - Epoch:  2 | Chunk: 17 | step:  900 | mle_loss: 1.162165 | cl_loss: 0.029048 | loss: 1.307405
2022-07-28 03:15:30.909 | INFO     | __main__:train:118 - Epoch:  2 | Chunk: 17 | step:  950 | mle_loss: 1.213354 | cl_loss: 0.028858 | loss: 1.357642
2022-07-28 03:15:48.882 | INFO     | __main__:train:118 - Epoch:  2 | Chunk: 17 | step: 1000 | mle_loss: 1.200083 | cl_loss: 0.028371 | loss: 1.341938
2022-07-28 03:16:07.012 | INFO     | __main__:train:118 - Epoch:  2 | Chunk: 17 | step: 1050 | mle_loss: 1.193845 | cl_loss: 0.029021 | loss: 1.338948
2022-07-28 03:16:25.122 | INFO     | __main__:train:118 - Epoch:  2 | Chunk: 17 | step: 1100 | mle_loss: 1.187369 | cl_loss: 0.026956 | loss: 1.322149
2022-07-28 03:16:43.472 | INFO     | __main__:train:118 - Epoch:  2 | Chunk: 17 | step: 1150 | mle_loss: 1.177513 | cl_loss: 0.030942 | loss: 1.332222
2022-07-28 03:17:01.852 | INFO     | __main__:train:118 - Epoch:  2 | Chunk: 17 | step: 1200 | mle_loss: 1.186628 | cl_loss: 0.030692 | loss: 1.340087
2022-07-28 03:17:19.646 | INFO     | processing.dataset:_load_and_cache_examples:43 - Loading examples from cache file data/cache/train_set/train_18.pkl
2022-07-28 03:17:21.613 | INFO     | __main__:train:118 - Epoch:  2 | Chunk: 18 | step:    0 | mle_loss: 1.203663 | cl_loss: 0.029560 | loss: 1.351463
2022-07-28 03:17:39.539 | INFO     | __main__:train:118 - Epoch:  2 | Chunk: 18 | step:   50 | mle_loss: 1.142343 | cl_loss: 0.023108 | loss: 1.257883
2022-07-28 03:17:57.437 | INFO     | __main__:train:118 - Epoch:  2 | Chunk: 18 | step:  100 | mle_loss: 1.170906 | cl_loss: 0.024549 | loss: 1.293649
2022-07-28 03:18:15.560 | INFO     | __main__:train:118 - Epoch:  2 | Chunk: 18 | step:  150 | mle_loss: 1.145634 | cl_loss: 0.025054 | loss: 1.270905
2022-07-28 03:18:33.766 | INFO     | __main__:train:118 - Epoch:  2 | Chunk: 18 | step:  200 | mle_loss: 1.146440 | cl_loss: 0.024297 | loss: 1.267924
2022-07-28 03:18:51.811 | INFO     | __main__:train:118 - Epoch:  2 | Chunk: 18 | step:  250 | mle_loss: 1.133733 | cl_loss: 0.024462 | loss: 1.256045
2022-07-28 03:19:09.790 | INFO     | __main__:train:118 - Epoch:  2 | Chunk: 18 | step:  300 | mle_loss: 1.105280 | cl_loss: 0.025494 | loss: 1.232752
2022-07-28 03:19:27.839 | INFO     | __main__:train:118 - Epoch:  2 | Chunk: 18 | step:  350 | mle_loss: 1.108238 | cl_loss: 0.024208 | loss: 1.229280
2022-07-28 03:19:45.848 | INFO     | __main__:train:118 - Epoch:  2 | Chunk: 18 | step:  400 | mle_loss: 1.134503 | cl_loss: 0.024551 | loss: 1.257256
2022-07-28 03:20:03.633 | INFO     | __main__:train:118 - Epoch:  2 | Chunk: 18 | step:  450 | mle_loss: 1.150854 | cl_loss: 0.025446 | loss: 1.278083
2022-07-28 03:20:21.741 | INFO     | __main__:evaluate:178 - Generating...
2022-07-28 03:21:46.837 | INFO     | __main__:evaluate:188 - Generation finished.
2022-07-28 03:21:46.838 | INFO     | __main__:evaluate:195 - Rouge scores: {'rouge-1': 0.4159, 'rouge-2': 0.254, 'rouge-l': 0.3709}
2022-07-28 03:21:46.838 | INFO     | __main__:train:137 - Eval loss: 0.0, the best loss: {'loss': 0.0, 'epoch': 0, 'step': 749}
2022-07-28 03:21:46.838 | INFO     | __main__:train:138 - Rouge scores: {'rouge-1': 0.4159, 'rouge-2': 0.254, 'rouge-l': 0.3709}, the best scores: {'rouge-1': 0.4211, 'rouge-2': 0.2666, 'rouge-l': 0.3766, 'epoch': 2, 'step': 249}
2022-07-28 03:21:46.839 | INFO     | __main__:train:143 - Saving model checkpoint to checkpoints/MoCoBart-2-18-499
2022-07-28 03:21:48.891 | INFO     | __main__:train:118 - Epoch:  2 | Chunk: 18 | step:  500 | mle_loss: 1.141595 | cl_loss: 0.025424 | loss: 1.268713
2022-07-28 03:22:07.112 | INFO     | __main__:train:118 - Epoch:  2 | Chunk: 18 | step:  550 | mle_loss: 1.118681 | cl_loss: 0.024255 | loss: 1.239958
2022-07-28 03:22:26.659 | INFO     | __main__:train:118 - Epoch:  2 | Chunk: 18 | step:  600 | mle_loss: 1.135967 | cl_loss: 0.023478 | loss: 1.253358
2022-07-28 03:22:44.837 | INFO     | __main__:train:118 - Epoch:  2 | Chunk: 18 | step:  650 | mle_loss: 1.119271 | cl_loss: 0.025033 | loss: 1.244436
2022-07-28 03:23:02.924 | INFO     | __main__:train:118 - Epoch:  2 | Chunk: 18 | step:  700 | mle_loss: 1.145571 | cl_loss: 0.025049 | loss: 1.270814
2022-07-28 03:23:21.133 | INFO     | __main__:train:118 - Epoch:  2 | Chunk: 18 | step:  750 | mle_loss: 1.130336 | cl_loss: 0.025770 | loss: 1.259187
2022-07-28 03:23:40.824 | INFO     | __main__:train:118 - Epoch:  2 | Chunk: 18 | step:  800 | mle_loss: 1.123901 | cl_loss: 0.024400 | loss: 1.245903
2022-07-28 03:23:58.942 | INFO     | __main__:train:118 - Epoch:  2 | Chunk: 18 | step:  850 | mle_loss: 1.141477 | cl_loss: 0.024042 | loss: 1.261688
2022-07-28 03:24:17.084 | INFO     | __main__:train:118 - Epoch:  2 | Chunk: 18 | step:  900 | mle_loss: 1.128963 | cl_loss: 0.023643 | loss: 1.247177
2022-07-28 03:24:35.790 | INFO     | __main__:train:118 - Epoch:  2 | Chunk: 18 | step:  950 | mle_loss: 1.155821 | cl_loss: 0.024767 | loss: 1.279654
2022-07-28 03:24:54.730 | INFO     | __main__:train:118 - Epoch:  2 | Chunk: 18 | step: 1000 | mle_loss: 1.111462 | cl_loss: 0.024292 | loss: 1.232920
2022-07-28 03:25:12.913 | INFO     | __main__:train:118 - Epoch:  2 | Chunk: 18 | step: 1050 | mle_loss: 1.133540 | cl_loss: 0.024108 | loss: 1.254077
2022-07-28 03:25:32.873 | INFO     | __main__:train:118 - Epoch:  2 | Chunk: 18 | step: 1100 | mle_loss: 1.138580 | cl_loss: 0.025276 | loss: 1.264958
2022-07-28 03:25:50.925 | INFO     | __main__:train:118 - Epoch:  2 | Chunk: 18 | step: 1150 | mle_loss: 1.101037 | cl_loss: 0.023540 | loss: 1.218738
2022-07-28 03:26:08.778 | INFO     | __main__:train:118 - Epoch:  2 | Chunk: 18 | step: 1200 | mle_loss: 1.107063 | cl_loss: 0.023371 | loss: 1.223920
2022-07-28 03:26:26.665 | INFO     | processing.dataset:_load_and_cache_examples:43 - Loading examples from cache file data/cache/train_set/train_19.pkl
2022-07-28 03:26:28.809 | INFO     | __main__:train:118 - Epoch:  2 | Chunk: 19 | step:    0 | mle_loss: 1.120772 | cl_loss: 0.023793 | loss: 1.239738
2022-07-28 03:26:47.959 | INFO     | __main__:train:118 - Epoch:  2 | Chunk: 19 | step:   50 | mle_loss: 1.080980 | cl_loss: 0.024885 | loss: 1.205407
2022-07-28 03:27:05.997 | INFO     | __main__:train:118 - Epoch:  2 | Chunk: 19 | step:  100 | mle_loss: 1.097457 | cl_loss: 0.025365 | loss: 1.224280
2022-07-28 03:27:24.063 | INFO     | __main__:train:118 - Epoch:  2 | Chunk: 19 | step:  150 | mle_loss: 1.102990 | cl_loss: 0.024983 | loss: 1.227908
2022-07-28 03:27:42.083 | INFO     | __main__:train:118 - Epoch:  2 | Chunk: 19 | step:  200 | mle_loss: 1.092477 | cl_loss: 0.024611 | loss: 1.215534
2022-07-28 03:28:00.455 | INFO     | __main__:train:118 - Epoch:  2 | Chunk: 19 | step:  250 | mle_loss: 1.071449 | cl_loss: 0.025121 | loss: 1.197056
2022-07-28 03:28:18.570 | INFO     | __main__:train:118 - Epoch:  2 | Chunk: 19 | step:  300 | mle_loss: 1.068406 | cl_loss: 0.025129 | loss: 1.194051
2022-07-28 03:28:36.437 | INFO     | __main__:train:118 - Epoch:  2 | Chunk: 19 | step:  350 | mle_loss: 1.081730 | cl_loss: 0.026193 | loss: 1.212697
2022-07-28 03:28:55.121 | INFO     | __main__:train:118 - Epoch:  2 | Chunk: 19 | step:  400 | mle_loss: 1.083862 | cl_loss: 0.026335 | loss: 1.215535
2022-07-28 03:29:13.157 | INFO     | __main__:train:118 - Epoch:  2 | Chunk: 19 | step:  450 | mle_loss: 1.074365 | cl_loss: 0.025902 | loss: 1.203877
2022-07-28 03:29:31.228 | INFO     | __main__:train:118 - Epoch:  2 | Chunk: 19 | step:  500 | mle_loss: 1.076594 | cl_loss: 0.024890 | loss: 1.201045
2022-07-28 03:29:49.434 | INFO     | __main__:train:118 - Epoch:  2 | Chunk: 19 | step:  550 | mle_loss: 1.077587 | cl_loss: 0.025783 | loss: 1.206500
2022-07-28 03:30:07.879 | INFO     | __main__:train:118 - Epoch:  2 | Chunk: 19 | step:  600 | mle_loss: 1.066659 | cl_loss: 0.025488 | loss: 1.194096
2022-07-28 03:30:25.752 | INFO     | __main__:train:118 - Epoch:  2 | Chunk: 19 | step:  650 | mle_loss: 1.099797 | cl_loss: 0.025003 | loss: 1.224813
2022-07-28 03:30:44.109 | INFO     | __main__:train:118 - Epoch:  2 | Chunk: 19 | step:  700 | mle_loss: 1.090442 | cl_loss: 0.025580 | loss: 1.218341
2022-07-28 03:31:02.118 | INFO     | __main__:train:118 - Epoch:  2 | Chunk: 19 | step:  750 | mle_loss: 1.080985 | cl_loss: 0.025045 | loss: 1.206210
2022-07-28 03:31:20.219 | INFO     | __main__:train:118 - Epoch:  2 | Chunk: 19 | step:  800 | mle_loss: 1.087268 | cl_loss: 0.025083 | loss: 1.212685
2022-07-28 03:31:38.541 | INFO     | __main__:train:118 - Epoch:  2 | Chunk: 19 | step:  850 | mle_loss: 1.082887 | cl_loss: 0.025823 | loss: 1.212002
2022-07-28 03:31:56.384 | INFO     | __main__:train:118 - Epoch:  2 | Chunk: 19 | step:  900 | mle_loss: 1.080988 | cl_loss: 0.024417 | loss: 1.203071
2022-07-28 03:32:14.496 | INFO     | __main__:train:118 - Epoch:  2 | Chunk: 19 | step:  950 | mle_loss: 1.094925 | cl_loss: 0.025507 | loss: 1.222462
2022-07-28 03:32:32.555 | INFO     | __main__:train:118 - Epoch:  2 | Chunk: 19 | step: 1000 | mle_loss: 1.082630 | cl_loss: 0.025424 | loss: 1.209752
2022-07-28 03:32:50.399 | INFO     | __main__:train:118 - Epoch:  2 | Chunk: 19 | step: 1050 | mle_loss: 1.086427 | cl_loss: 0.025008 | loss: 1.211469
2022-07-28 03:33:08.666 | INFO     | __main__:train:118 - Epoch:  2 | Chunk: 19 | step: 1100 | mle_loss: 1.081280 | cl_loss: 0.024611 | loss: 1.204332
2022-07-28 03:33:26.578 | INFO     | __main__:train:118 - Epoch:  2 | Chunk: 19 | step: 1150 | mle_loss: 1.110775 | cl_loss: 0.025366 | loss: 1.237603
2022-07-28 03:33:44.575 | INFO     | __main__:train:118 - Epoch:  2 | Chunk: 19 | step: 1200 | mle_loss: 1.080487 | cl_loss: 0.025508 | loss: 1.208025
2022-07-28 03:34:02.401 | INFO     | __main__:evaluate:178 - Generating...
2022-07-28 03:35:26.095 | INFO     | __main__:evaluate:188 - Generation finished.
2022-07-28 03:35:26.095 | INFO     | __main__:evaluate:195 - Rouge scores: {'rouge-1': 0.4178, 'rouge-2': 0.2557, 'rouge-l': 0.3732}
2022-07-28 03:35:26.095 | INFO     | __main__:train:137 - Eval loss: 0.0, the best loss: {'loss': 0.0, 'epoch': 0, 'step': 749}
2022-07-28 03:35:26.096 | INFO     | __main__:train:138 - Rouge scores: {'rouge-1': 0.4178, 'rouge-2': 0.2557, 'rouge-l': 0.3732}, the best scores: {'rouge-1': 0.4211, 'rouge-2': 0.2666, 'rouge-l': 0.3766, 'epoch': 2, 'step': 249}
2022-07-28 03:35:26.104 | INFO     | __main__:train:143 - Saving model checkpoint to checkpoints/MoCoBart-2-19-1249
2022-07-28 03:35:28.530 | INFO     | processing.dataset:_load_and_cache_examples:43 - Loading examples from cache file data/cache/train_set/train_20.pkl
2022-07-28 03:35:30.575 | INFO     | __main__:train:118 - Epoch:  2 | Chunk: 20 | step:    0 | mle_loss: 1.075959 | cl_loss: 0.024385 | loss: 1.197885
2022-07-28 03:35:48.337 | INFO     | __main__:train:118 - Epoch:  2 | Chunk: 20 | step:   50 | mle_loss: 1.120199 | cl_loss: 0.024983 | loss: 1.245112
2022-07-28 03:36:06.482 | INFO     | __main__:train:118 - Epoch:  2 | Chunk: 20 | step:  100 | mle_loss: 1.145528 | cl_loss: 0.025725 | loss: 1.274155
2022-07-28 03:36:24.322 | INFO     | __main__:train:118 - Epoch:  2 | Chunk: 20 | step:  150 | mle_loss: 1.145812 | cl_loss: 0.024065 | loss: 1.266138
2022-07-28 03:36:42.408 | INFO     | __main__:train:118 - Epoch:  2 | Chunk: 20 | step:  200 | mle_loss: 1.105807 | cl_loss: 0.025168 | loss: 1.231646
2022-07-28 03:37:00.559 | INFO     | __main__:train:118 - Epoch:  2 | Chunk: 20 | step:  250 | mle_loss: 1.128433 | cl_loss: 0.025466 | loss: 1.255760
2022-07-28 03:37:18.545 | INFO     | __main__:train:118 - Epoch:  2 | Chunk: 20 | step:  300 | mle_loss: 1.152160 | cl_loss: 0.025773 | loss: 1.281025
2022-07-28 03:37:36.572 | INFO     | __main__:train:118 - Epoch:  2 | Chunk: 20 | step:  350 | mle_loss: 1.115888 | cl_loss: 0.025664 | loss: 1.244207
2022-07-28 03:37:54.772 | INFO     | __main__:train:118 - Epoch:  2 | Chunk: 20 | step:  400 | mle_loss: 1.103307 | cl_loss: 0.024282 | loss: 1.224719
2022-07-28 03:38:12.813 | INFO     | __main__:train:118 - Epoch:  2 | Chunk: 20 | step:  450 | mle_loss: 1.120416 | cl_loss: 0.024017 | loss: 1.240502
2022-07-28 03:38:30.892 | INFO     | __main__:train:118 - Epoch:  2 | Chunk: 20 | step:  500 | mle_loss: 1.118182 | cl_loss: 0.025154 | loss: 1.243950
2022-07-28 03:38:49.073 | INFO     | __main__:train:118 - Epoch:  2 | Chunk: 20 | step:  550 | mle_loss: 1.111260 | cl_loss: 0.024647 | loss: 1.234495
2022-07-28 03:39:07.399 | INFO     | __main__:train:118 - Epoch:  2 | Chunk: 20 | step:  600 | mle_loss: 1.115864 | cl_loss: 0.025337 | loss: 1.242547
2022-07-28 03:39:25.593 | INFO     | __main__:train:118 - Epoch:  2 | Chunk: 20 | step:  650 | mle_loss: 1.124602 | cl_loss: 0.024321 | loss: 1.246208
2022-07-28 03:39:43.686 | INFO     | __main__:train:118 - Epoch:  2 | Chunk: 20 | step:  700 | mle_loss: 1.115664 | cl_loss: 0.025216 | loss: 1.241742
2022-07-28 03:40:01.628 | INFO     | __main__:train:118 - Epoch:  2 | Chunk: 20 | step:  750 | mle_loss: 1.103123 | cl_loss: 0.024406 | loss: 1.225150
2022-07-28 03:40:20.176 | INFO     | __main__:train:118 - Epoch:  2 | Chunk: 20 | step:  800 | mle_loss: 1.125554 | cl_loss: 0.024354 | loss: 1.247325
2022-07-28 03:40:38.353 | INFO     | __main__:train:118 - Epoch:  2 | Chunk: 20 | step:  850 | mle_loss: 1.112612 | cl_loss: 0.024763 | loss: 1.236425
2022-07-28 03:40:56.521 | INFO     | __main__:train:118 - Epoch:  2 | Chunk: 20 | step:  900 | mle_loss: 1.140363 | cl_loss: 0.024445 | loss: 1.262587
2022-07-28 03:41:14.365 | INFO     | __main__:train:118 - Epoch:  2 | Chunk: 20 | step:  950 | mle_loss: 1.128391 | cl_loss: 0.024105 | loss: 1.248914
2022-07-28 03:41:32.164 | INFO     | __main__:train:118 - Epoch:  2 | Chunk: 20 | step: 1000 | mle_loss: 1.145642 | cl_loss: 0.023958 | loss: 1.265433
2022-07-28 03:41:50.174 | INFO     | __main__:train:118 - Epoch:  2 | Chunk: 20 | step: 1050 | mle_loss: 1.134605 | cl_loss: 0.023815 | loss: 1.253681
2022-07-28 03:42:08.392 | INFO     | __main__:train:118 - Epoch:  2 | Chunk: 20 | step: 1100 | mle_loss: 1.141964 | cl_loss: 0.023704 | loss: 1.260484
2022-07-28 03:42:26.500 | INFO     | __main__:train:118 - Epoch:  2 | Chunk: 20 | step: 1150 | mle_loss: 1.123337 | cl_loss: 0.024544 | loss: 1.246058
2022-07-28 03:42:44.520 | INFO     | __main__:train:118 - Epoch:  2 | Chunk: 20 | step: 1200 | mle_loss: 1.130399 | cl_loss: 0.024457 | loss: 1.252685
2022-07-28 03:43:02.373 | INFO     | processing.dataset:_load_and_cache_examples:43 - Loading examples from cache file data/cache/train_set/train_21.pkl
2022-07-28 03:43:04.369 | INFO     | __main__:train:118 - Epoch:  2 | Chunk: 21 | step:    0 | mle_loss: 1.099589 | cl_loss: 0.025503 | loss: 1.227106
2022-07-28 03:43:22.440 | INFO     | __main__:train:118 - Epoch:  2 | Chunk: 21 | step:   50 | mle_loss: 1.154648 | cl_loss: 0.026677 | loss: 1.288031
2022-07-28 03:43:40.336 | INFO     | __main__:train:118 - Epoch:  2 | Chunk: 21 | step:  100 | mle_loss: 1.167656 | cl_loss: 0.026646 | loss: 1.300884
2022-07-28 03:43:58.576 | INFO     | __main__:train:118 - Epoch:  2 | Chunk: 21 | step:  150 | mle_loss: 1.145466 | cl_loss: 0.026933 | loss: 1.280133
2022-07-28 03:44:16.661 | INFO     | __main__:train:118 - Epoch:  2 | Chunk: 21 | step:  200 | mle_loss: 1.156897 | cl_loss: 0.026289 | loss: 1.288342
2022-07-28 03:44:34.764 | INFO     | __main__:train:118 - Epoch:  2 | Chunk: 21 | step:  250 | mle_loss: 1.136636 | cl_loss: 0.024637 | loss: 1.259823
2022-07-28 03:44:52.920 | INFO     | __main__:train:118 - Epoch:  2 | Chunk: 21 | step:  300 | mle_loss: 1.178190 | cl_loss: 0.026421 | loss: 1.310294
2022-07-28 03:45:17.088 | INFO     | __main__:train:118 - Epoch:  2 | Chunk: 21 | step:  350 | mle_loss: 1.142806 | cl_loss: 0.026975 | loss: 1.277681
2022-07-28 03:45:35.254 | INFO     | __main__:train:118 - Epoch:  2 | Chunk: 21 | step:  400 | mle_loss: 1.135524 | cl_loss: 0.026916 | loss: 1.270105
2022-07-28 03:45:53.477 | INFO     | __main__:train:118 - Epoch:  2 | Chunk: 21 | step:  450 | mle_loss: 1.119941 | cl_loss: 0.026071 | loss: 1.250295
2022-07-28 03:46:11.855 | INFO     | __main__:train:118 - Epoch:  2 | Chunk: 21 | step:  500 | mle_loss: 1.153851 | cl_loss: 0.026869 | loss: 1.288194
2022-07-28 03:46:30.094 | INFO     | __main__:train:118 - Epoch:  2 | Chunk: 21 | step:  550 | mle_loss: 1.133434 | cl_loss: 0.026095 | loss: 1.263909
2022-07-28 03:46:48.336 | INFO     | __main__:train:118 - Epoch:  2 | Chunk: 21 | step:  600 | mle_loss: 1.156173 | cl_loss: 0.025588 | loss: 1.284113
2022-07-28 03:47:06.497 | INFO     | __main__:train:118 - Epoch:  2 | Chunk: 21 | step:  650 | mle_loss: 1.136046 | cl_loss: 0.024896 | loss: 1.260525
2022-07-28 03:47:24.880 | INFO     | __main__:train:118 - Epoch:  2 | Chunk: 21 | step:  700 | mle_loss: 1.123455 | cl_loss: 0.025606 | loss: 1.251486
2022-07-28 03:47:42.644 | INFO     | __main__:evaluate:178 - Generating...
2022-07-28 03:49:06.170 | INFO     | __main__:evaluate:188 - Generation finished.
2022-07-28 03:49:06.170 | INFO     | __main__:evaluate:195 - Rouge scores: {'rouge-1': 0.4189, 'rouge-2': 0.2609, 'rouge-l': 0.3726}
2022-07-28 03:49:06.170 | INFO     | __main__:train:137 - Eval loss: 0.0, the best loss: {'loss': 0.0, 'epoch': 0, 'step': 749}
2022-07-28 03:49:06.171 | INFO     | __main__:train:138 - Rouge scores: {'rouge-1': 0.4189, 'rouge-2': 0.2609, 'rouge-l': 0.3726}, the best scores: {'rouge-1': 0.4211, 'rouge-2': 0.2666, 'rouge-l': 0.3766, 'epoch': 2, 'step': 249}
2022-07-28 03:49:06.171 | INFO     | __main__:train:143 - Saving model checkpoint to checkpoints/MoCoBart-2-21-749
2022-07-28 03:49:08.771 | INFO     | __main__:train:118 - Epoch:  2 | Chunk: 21 | step:  750 | mle_loss: 1.127752 | cl_loss: 0.026378 | loss: 1.259639
2022-07-28 03:49:26.818 | INFO     | __main__:train:118 - Epoch:  2 | Chunk: 21 | step:  800 | mle_loss: 1.135608 | cl_loss: 0.026106 | loss: 1.266139
2022-07-28 03:49:44.533 | INFO     | __main__:train:118 - Epoch:  2 | Chunk: 21 | step:  850 | mle_loss: 1.148858 | cl_loss: 0.024999 | loss: 1.273852
2022-07-28 03:50:02.443 | INFO     | __main__:train:118 - Epoch:  2 | Chunk: 21 | step:  900 | mle_loss: 1.141148 | cl_loss: 0.025958 | loss: 1.270937
2022-07-28 03:50:20.476 | INFO     | __main__:train:118 - Epoch:  2 | Chunk: 21 | step:  950 | mle_loss: 1.112562 | cl_loss: 0.025474 | loss: 1.239932
2022-07-28 03:50:40.490 | INFO     | __main__:train:118 - Epoch:  2 | Chunk: 21 | step: 1000 | mle_loss: 1.136891 | cl_loss: 0.025454 | loss: 1.264161
2022-07-28 03:50:58.647 | INFO     | __main__:train:118 - Epoch:  2 | Chunk: 21 | step: 1050 | mle_loss: 1.137973 | cl_loss: 0.026069 | loss: 1.268318
2022-07-28 03:51:16.776 | INFO     | __main__:train:118 - Epoch:  2 | Chunk: 21 | step: 1100 | mle_loss: 1.142309 | cl_loss: 0.025850 | loss: 1.271559
2022-07-28 03:51:34.826 | INFO     | __main__:train:118 - Epoch:  2 | Chunk: 21 | step: 1150 | mle_loss: 1.133586 | cl_loss: 0.026874 | loss: 1.267956
2022-07-28 03:51:52.696 | INFO     | __main__:train:118 - Epoch:  2 | Chunk: 21 | step: 1200 | mle_loss: 1.121780 | cl_loss: 0.025376 | loss: 1.248658
2022-07-28 03:52:10.453 | INFO     | processing.dataset:_load_and_cache_examples:43 - Loading examples from cache file data/cache/train_set/train_22.pkl
2022-07-28 03:52:11.885 | INFO     | __main__:train:118 - Epoch:  2 | Chunk: 22 | step:    0 | mle_loss: 1.121727 | cl_loss: 0.025632 | loss: 1.249888
2022-07-28 03:52:29.708 | INFO     | __main__:train:118 - Epoch:  2 | Chunk: 22 | step:   50 | mle_loss: 1.234338 | cl_loss: 0.026210 | loss: 1.365388
2022-07-28 03:52:47.716 | INFO     | __main__:train:118 - Epoch:  2 | Chunk: 22 | step:  100 | mle_loss: 1.219297 | cl_loss: 0.025710 | loss: 1.347847
2022-07-28 03:53:05.861 | INFO     | __main__:train:118 - Epoch:  2 | Chunk: 22 | step:  150 | mle_loss: 1.188607 | cl_loss: 0.026110 | loss: 1.319158
2022-07-28 03:53:23.569 | INFO     | __main__:train:118 - Epoch:  2 | Chunk: 22 | step:  200 | mle_loss: 1.214679 | cl_loss: 0.027091 | loss: 1.350135
2022-07-28 03:53:41.575 | INFO     | __main__:train:118 - Epoch:  2 | Chunk: 22 | step:  250 | mle_loss: 1.201555 | cl_loss: 0.026684 | loss: 1.334977
2022-07-28 03:53:59.688 | INFO     | __main__:train:118 - Epoch:  2 | Chunk: 22 | step:  300 | mle_loss: 1.185084 | cl_loss: 0.025625 | loss: 1.313210
2022-07-28 03:54:17.724 | INFO     | __main__:train:118 - Epoch:  2 | Chunk: 22 | step:  350 | mle_loss: 1.217501 | cl_loss: 0.026256 | loss: 1.348780
2022-07-28 03:54:35.636 | INFO     | __main__:train:118 - Epoch:  2 | Chunk: 22 | step:  400 | mle_loss: 1.218042 | cl_loss: 0.028178 | loss: 1.358934
2022-07-28 03:54:53.720 | INFO     | __main__:train:118 - Epoch:  2 | Chunk: 22 | step:  450 | mle_loss: 1.230631 | cl_loss: 0.027171 | loss: 1.366487
2022-07-28 03:55:11.997 | INFO     | __main__:train:118 - Epoch:  2 | Chunk: 22 | step:  500 | mle_loss: 1.160590 | cl_loss: 0.024963 | loss: 1.285404
2022-07-28 03:55:30.036 | INFO     | __main__:train:118 - Epoch:  2 | Chunk: 22 | step:  550 | mle_loss: 1.190601 | cl_loss: 0.024894 | loss: 1.315069
2022-07-28 03:55:47.930 | INFO     | __main__:train:118 - Epoch:  2 | Chunk: 22 | step:  600 | mle_loss: 1.209918 | cl_loss: 0.025247 | loss: 1.336151
2022-07-28 03:56:05.803 | INFO     | __main__:train:118 - Epoch:  2 | Chunk: 22 | step:  650 | mle_loss: 1.193973 | cl_loss: 0.027259 | loss: 1.330270
2022-07-28 03:56:23.757 | INFO     | __main__:train:118 - Epoch:  2 | Chunk: 22 | step:  700 | mle_loss: 1.190549 | cl_loss: 0.025719 | loss: 1.319144
2022-07-28 03:56:41.451 | INFO     | __main__:train:118 - Epoch:  2 | Chunk: 22 | step:  750 | mle_loss: 1.188361 | cl_loss: 0.025329 | loss: 1.315004
2022-07-28 03:56:58.983 | INFO     | __main__:train:118 - Epoch:  2 | Chunk: 22 | step:  800 | mle_loss: 1.212954 | cl_loss: 0.026082 | loss: 1.343366
2022-07-28 03:57:16.945 | INFO     | __main__:train:118 - Epoch:  2 | Chunk: 22 | step:  850 | mle_loss: 1.209730 | cl_loss: 0.027001 | loss: 1.344734
2022-07-28 03:57:34.930 | INFO     | __main__:train:118 - Epoch:  2 | Chunk: 22 | step:  900 | mle_loss: 1.216615 | cl_loss: 0.025247 | loss: 1.342850
2022-07-28 03:57:52.940 | INFO     | __main__:train:118 - Epoch:  2 | Chunk: 22 | step:  950 | mle_loss: 1.224622 | cl_loss: 0.025983 | loss: 1.354536
2022-07-28 03:58:11.046 | INFO     | __main__:train:118 - Epoch:  2 | Chunk: 22 | step: 1000 | mle_loss: 1.193766 | cl_loss: 0.025163 | loss: 1.319582
2022-07-28 03:58:28.971 | INFO     | __main__:train:118 - Epoch:  2 | Chunk: 22 | step: 1050 | mle_loss: 1.220961 | cl_loss: 0.025172 | loss: 1.346823
2022-07-28 03:58:47.069 | INFO     | __main__:train:118 - Epoch:  2 | Chunk: 22 | step: 1100 | mle_loss: 1.204286 | cl_loss: 0.025659 | loss: 1.332582
2022-07-28 03:59:05.099 | INFO     | __main__:train:118 - Epoch:  2 | Chunk: 22 | step: 1150 | mle_loss: 1.194627 | cl_loss: 0.025956 | loss: 1.324405
2022-07-28 03:59:23.059 | INFO     | __main__:train:118 - Epoch:  2 | Chunk: 22 | step: 1200 | mle_loss: 1.215512 | cl_loss: 0.025712 | loss: 1.344071
2022-07-28 03:59:40.907 | INFO     | processing.dataset:_load_and_cache_examples:43 - Loading examples from cache file data/cache/train_set/train_23.pkl
2022-07-28 03:59:42.810 | INFO     | __main__:train:118 - Epoch:  2 | Chunk: 23 | step:    0 | mle_loss: 1.194046 | cl_loss: 0.026735 | loss: 1.327722
2022-07-28 04:00:00.684 | INFO     | __main__:train:118 - Epoch:  2 | Chunk: 23 | step:   50 | mle_loss: 1.133136 | cl_loss: 0.025299 | loss: 1.259630
