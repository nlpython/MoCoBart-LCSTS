2022-07-26 21:05:13.472 | INFO     | config:print_args:49 - K = 1024
2022-07-26 21:05:13.475 | INFO     | config:print_args:49 - T = 0.07
2022-07-26 21:05:13.479 | INFO     | config:print_args:49 - adam_epsilon = 1e-08
2022-07-26 21:05:13.481 | INFO     | config:print_args:49 - alpha = 5
2022-07-26 21:05:13.483 | INFO     | config:print_args:49 - bart_lr = 0.0001
2022-07-26 21:05:13.486 | INFO     | config:print_args:49 - batch_size = 4
2022-07-26 21:05:13.486 | INFO     | config:print_args:49 - checkpoint_path = checkpoints/
2022-07-26 21:05:13.492 | INFO     | config:print_args:49 - chunk_nums = 30
2022-07-26 21:05:13.495 | INFO     | config:print_args:49 - content_max_len = 152
2022-07-26 21:05:13.495 | INFO     | config:print_args:49 - data_dir = data/
2022-07-26 21:05:13.495 | INFO     | config:print_args:49 - epochs = 1
2022-07-26 21:05:13.503 | INFO     | config:print_args:49 - eval_interval = 2500
2022-07-26 21:05:13.505 | INFO     | config:print_args:49 - generate_max_len = 70
2022-07-26 21:05:13.505 | INFO     | config:print_args:49 - gradient_accumulation_steps = 4
2022-07-26 21:05:13.510 | INFO     | config:print_args:49 - json_path = bart-base-chinese/config.json
2022-07-26 21:05:13.512 | INFO     | config:print_args:49 - log_interval = 50
2022-07-26 21:05:13.512 | INFO     | config:print_args:49 - log_path = logs/
2022-07-26 21:05:13.512 | INFO     | config:print_args:49 - m = 0.999
2022-07-26 21:05:13.512 | INFO     | config:print_args:49 - max_clip_norm = 1.0
2022-07-26 21:05:13.521 | INFO     | config:print_args:49 - max_len = 184
2022-07-26 21:05:13.524 | INFO     | config:print_args:49 - mlp = False
2022-07-26 21:05:13.525 | INFO     | config:print_args:49 - pooling = last-avg
2022-07-26 21:05:13.529 | INFO     | config:print_args:49 - pretrained_model_path = bart-base-chinese/
2022-07-26 21:05:13.531 | INFO     | config:print_args:49 - repetition_penalty = 1.2
2022-07-26 21:05:13.534 | INFO     | config:print_args:49 - save_settings = <bound method Args.save_settings of {'data_dir': 'data/', 'pretrained_model_path': 'bart-base-chinese/', 'vocab_path': 'bart-base-chinese/', 'json_path': 'bart-base-chinese/config.json', 'checkpoint_path': 'checkpoints/', 'log_path': 'logs/', 'seed': 2020, 'batch_size': 4, 'max_len': 184, 'content_max_len': 152, 'summary_max_len': 32, 'epochs': 1, 'bart_lr': 0.0001, 'warmup_steps': 10000, 'weight_decay': 0.01, 'adam_epsilon': 1e-08, 'max_clip_norm': 1.0, 'gradient_accumulation_steps': 4, 'eval_interval': 2500, 'log_interval': 50, 'alpha': 5, 'K': 1024, 'm': 0.999, 'T': 0.07, 'mlp': False, 'pooling': 'last-avg', 'chunk_nums': 30, 'generate_max_len': 70, 'repetition_penalty': 1.2, 'top_k': 5, 'top_p': 0.95}>
2022-07-26 21:05:13.535 | INFO     | config:print_args:49 - seed = 2020
2022-07-26 21:05:13.535 | INFO     | config:print_args:49 - summary_max_len = 32
2022-07-26 21:05:13.541 | INFO     | config:print_args:49 - top_k = 5
2022-07-26 21:05:13.545 | INFO     | config:print_args:49 - top_p = 0.95
2022-07-26 21:05:13.546 | INFO     | config:print_args:49 - vocab_path = bart-base-chinese/
2022-07-26 21:05:13.546 | INFO     | config:print_args:49 - warmup_steps = 10000
2022-07-26 21:05:13.546 | INFO     | config:print_args:49 - weight_decay = 0.01
2022-07-26 21:05:15.836 | INFO     | __main__:train:65 - 

2022-07-26 21:05:15.838 | INFO     | __main__:train:66 - ***** Running training *****
2022-07-26 21:05:15.840 | INFO     | __main__:train:67 -   Num Epochs = 1
2022-07-26 21:05:15.843 | INFO     | __main__:train:69 -   Total train batch size (w. parallel, distributed & accumulation) = 4
2022-07-26 21:05:15.844 | INFO     | __main__:train:70 -   Type of optimizer = AdamW
2022-07-26 21:05:15.847 | INFO     | __main__:train:72 -   Learning rate = 0.0001
2022-07-26 21:05:15.850 | INFO     | __main__:train:73 - 

2022-07-26 21:05:15.854 | INFO     | processing.dataset:_load_and_cache_examples:43 - Loading examples from cache file data/cache/train_set/train_0.pkl
